Title: Mod Monday - Is It Immoral To Take Land By Force?

(0:06) [Music]

(0:13) Generally generally here's what actually happened.

(0:19) I'm really mad. What difference does it make? Right.

(0:26) Stop. Deregulation of the industry is

(0:32) obviously going to cause more of that industry to lubricate the trust connection between people until they

(0:39) have enough yet we could still look at biological reality and determining who's a female even if there are why don't you

(0:46) deny denounce feminism the same way you're denouncing capitalism if you don't something to be objective it needs

(0:52) to be verifiable and you can't verify if I make a claim as a political pundit it

(0:58) is true that I definitely could be wrong. You're promoting, right? Ideology is the

(1:03) main politics, right? This is my ideology. This is so 2015. Anyone go

(1:08) back and watch the footage? The first GOP debate.

(1:20) Heat.

(1:34) Heat. [Music]

(2:05) And good evening, ladies and gentlemen. I am Sarah the raging tomato here bringing to you live another moderator

(2:11) Monday. This evening I have with me Christopher Colt new to the debate space

(2:16) uh enemy Charlie uh Marte Ryes and Andrew Wilson of course. Uh the topic of

(2:23) the evening or the question more so is is it immoral to take land by force? On

(2:29) the affirmative side, Christopher Colt, if you'd like to give your opening statement, please. Thank you very much.

(2:34) First of all, I want to say thanks to Sarah and the raging tomato for hosting the debate. My cotivator Charlie for uh

(2:40) agreeing to participate and Andrew and Mark Tape for agreeing to lend their time and voice to I think what will be

(2:45) hopefully an important discussion that people find useful. So I think let's begin with what I would call the

(2:52) self-evident. What is theft? Well, it is the unauthorized taking of another person's property with the intent to

(2:59) permanently deprive the owner. Now, I would argue that the only logical basis for our confusion over whether such

(3:05) conquest as the destruction and displacement of indigenous tribes here in North America was not theft is

(3:11) largely because European settlers had very little understanding of the Native American way of life. In their view,

(3:16) possessions required an exchange of money, goods, or services resulting in a legal document defining both their

(3:23) ownership and the parameters of it. However, we have philosophers such as John Lockach who argued that our labor,

(3:29) our lives invested in cultivating and building upon that land establishes a legitimate claim to it. Force does not

(3:35) confer legitimacy. It only confers power and might makes right is not a moral

(3:41) philosophy, but rather a confession of barbarity. Histo history stands as a

(3:46) stark testament to this truth. Just as the United States acquisition of Native American lands was clearly and profoundly immoral according to academic

(3:54) sources, so too is any land gained through violence and coercion. Now, this was not only well-established in the

(3:59) postworld war era, but also is a core precept of most religious faiths. My

(4:05) opponents, one a self-described Orthodox Christian, the other more of a Christian nationalist adjacent might appeal to a

(4:12) different authority. So let's turn to the spiritual lens to the very faith they claim guides them and discover how

(4:17) profoundly their state of position contradicts its core truths. First consider the image of God the Imago day.

(4:24) The Orthodox Christian faith teaches us that every single human being regardless of their nationality, ethnicity or land

(4:32) is created in the divine image possessing inherent sacred dignity. When land is taken by force, it necessitates

(4:39) the dehumanization, violent subjugation, and dispossession of people made in God's own likeness.

(4:46) How can one, as an Orthodox Christian, justify such a profound violation of the sacred image of God in another human

(4:52) being for the sake of acquiring territory? Is land truly more valuable than a soul marked with God's image? We

(4:59) should also address the very concept of ownership. My opponents speak of conquest, of seizing land, as if humans

(5:06) possess ultimate dominion. Yet their own holy traditions are unequivocal. God is the sole and ultimate owner of all

(5:12) creation. We are not owners, but humble stewards entrusted by God to manage his creation responsibly with love and

(5:19) justice and with consideration for all. is forceful acquisition not the ultimate act of pride an arrogant usurppation of

(5:27) God's sovereignty attempting to steal not merely from fellow humans but from God himself and if these general

(5:33) prohibitions are not enough our faith gives us a chillingly precise parable the story of Nabboth's vineyard in first

(5:39) Kings chapter 21 where King Ahab a mighty ruler coveted the small plot of land belonging to Nabboth through deceit

(5:46) and violence Ahab seized the vineyard what was the divine response the prophet Elijah delivered God's judment ment

(5:52) leading to the utter destruction of Ahab's royal line. The church fathers teach us that Ahab's sin was tantamount

(5:58) to theft from God himself. So I ask my opponents directly, was King Ahab's conquest of Nabbath's land moral? If you

(6:06) say it was immoral, then you concede my entire argument. If you dare to say it was moral, then you stand in direct

(6:12) opposition to holy scripture and the clear judgment of God. Finally, let us consider the Orthodox Church's

(6:17) consistent stance on war and aggression. It does not possess a just war theory in the western sense that might somehow

(6:23) rationalize conquest. While defensive war to protect the innocent might be a regrettable necessity in a fallen world.

(6:30) Aggressive war for territorial gain is profoundly condemned. Killing even in self-defense requires spiritual

(6:36) repentance. How then can an act of aggression carried out for greed and material gain be considered anything

(6:43) less than a grievous sin requiring no repentance? Indeed, when the church is manipulated to justify state aggression,

(6:49) their own hierarchs have called it a profound betrayal of orthodox tradition and even aposti.

(6:56) Now, my opponent's position is not rooted in orthodox Christianity. It is a secular cynical ideology of might makes

(7:03) right. Thinly veiled by selective interpretation, it requires him to contradict core doctrines of human

(7:09) dignity, divine ownership, explicit commandments, and the consistent mind of the church. It is in essence a profound

(7:16) betrayal of the gospel itself. To take land by force is immoral. It is unjust.

(7:21) It is illegal. And for an Orthodox Christian, it is a spiritual rebellion against God. Thank you. Thank you,

(7:28) Christopher. Charlie, to you. You're muted. You're muted.

(7:36) Sorry. You got to unmute. Sorry. Um, hi. I'm Enemy Charlie. Uh, I stream

(7:42) primarily on Twitch. My specialty is fantasy literature, not politics, history, or philosophy, but I comment anyway. Um, and thank you for having me,

(7:49) Sarah. I'm very excited to be here. And, uh, thank you, Christopher Cole. Um, so before I dive into the beat of my

(7:55) argument, I would like to quickly address and clarify my frame of reference on land rights and morality. Because we'll be discussing

(8:01) colonization, it is important to clarify that land ownership is not a universal concept. The indigenous peoples of the

(8:06) Americas did not have the same legal structures as European settlers. Borders as they exist today are a modern

(8:11) construct. So when we talk about who has the right to specific tracks of land and why, my conception of land rights can be summed up by article 26 of the United

(8:18) Nations declaration on the rights of indigenous people. And indigenous peoples have the rights to lands, territories, and resources which they

(8:24) have traditionally owned, occupied, or otherwise used or acquired. If you live there and work the land, and there is no

(8:29) one in living memory that used to live there and was deposed, you have the right to the land. A lack of legal ownership under a European legal

(8:35) structure is not a valid reason for the seizure of indigenous lands. And now on to morality. While I believe that

(8:41) morality is subjective, human beings across most cultures and time periods generally agree that murder and theft

(8:46) are wrong in most contexts. Um this is across Christianity, Islam, uh Hinduism,

(8:52) Buddhism, etc. Humans are social creatures and we need each other. Murdering and stealing from each other are not conducive to building a lasting

(8:59) thriving society. I will reference the golden rule. Do unto others as you would have them do unto you. Operating under

(9:05) the force doctrine inevitably leads to being subject to it yourself. In the wretch of the earth, franophhone scholar France Fannon wrote, "The exploited man

(9:12) sees that his liberation implies the use of all means and that of force first and foremost. When in 1956, after the

(9:18) capitulation of Monsur Guy Malay to the settlers in Algeria, the front deliberation national in a famous

(9:24) leaflet stated that colonialism only loosens its hold when the knife is at its throat. No Algerian really found

(9:29) these terms too violent. The leaflet only expressed what every Algerian felt at heart. Colonialism is not a thinking

(9:35) machine, nor a body endowed with reasoning facilities. It is violence in its natural state, and it will only

(9:40) yield when confronted with greater violence. The Algerian liberation war ended in 1962 with approximately 500,000

(9:47) Algerians and 30,000 French dead. And here I will concede. Though violent decolonization efforts are rarely

(9:52) successful through sheer force alone, the price of the force doctrine paid in human lives and resources is too costly

(9:58) for any nation to follow for long. The more violent a regime, the faster it falls. Many European nations have wisely

(10:03) rejected their claims to four lands for this very reason. Thank you, Charlie. And Marte to you.

(10:11) So, my opponent, enemy Charlie, had brought up the golden rule, which assumes that everybody wants to be

(10:16) treated the same at the end of the day, which is a crazy notion actually if you really think about this. So, I'm going

(10:21) to go into uh my little short thing. I'll be quick. So, the situation with Land Quad Quest could be thought of as a

(10:27) morality issue on the international scale. So who gets to enforce morality on an international level? It's usually the country or coalition of countries

(10:34) with the biggest sticks or the most money. So while my other opponent Christopher Cole can say might makes

(10:39) right, we've never asserted that only might only makes. So what you can do is if you feel that one of these big

(10:45) countries is morally slightly your people, nothing really sucks. But this is simply the reality of the world. Justice does not exist if there isn't an

(10:52) effective way to enforce it. We can point fingers all day that we want and say that there's something morally

(10:57) wrong. But at the end of the day, there's little else or nothing to do about it. Um, to Andrew. Well, thank

(11:04) you, Marte. And Andrew, to you, please. Well, thank you. I also would like to

(11:10) thank my opponents for the brutal slaughter which is about to happen this evening. Um, I do my This is my hats off

(11:19) salute to you. I even combed my hair this evening because I wanted to show respect. I didn't wear my black shirt

(11:25) even though this is going to be a funeral. I'd like to point out firstly that this debate is absurd on its face.

(11:34) Well, I'll grant there can be cases where using force to remove people from their land by force can be immoral. In

(11:42) and of itself, using force to occupy or take land cannot be immoral. My opponents can't possibly believe this

(11:48) either, or they will need to explain things like taxes, specifically property

(11:53) tax, which is an assessed and forced payment of an asset to an entity on a thing you own, which if you don't pay

(12:00) your property taxes, your property becomes a default, and it's taken by force, Christopher Colt.

(12:07) It's taken by force if you default. uh or let's take a look at the American

(12:13) Revolution in which we annexed by violence a rather large amount of land which was owned by the crown of England.

(12:20) Uh in fact, my examples of force doctrine being used to occupy or conquer land for quote good are vast and my

(12:27) opponents would probably agree with every single one of them. So what are we really even talking about here? Imagine

(12:35) trying to navigate the redresses which would be necessary here if we actually

(12:41) uh took our opponents at face value. It's mindboggling how much land has

(12:47) changed uh hands in a very short historic period of time, let alone long historic periods of time. If we

(12:54) attempted to redress it all, it would be not only a monumental task, but it could

(12:59) actually lead to some pretty absurd and hilarious outcomes. Like let's take the

(13:04) Native American example. Say we have tribe A and tribe B. Tribe A has a

(13:10) document from the government of promised land which the government then stole from them. Then tribe A pursues redress

(13:17) for this and is awarded for occupied land in its full amount. Then tribe B

(13:22) sues now tribe land A uh and gets awarded even more money because tribe A

(13:28) stole all that land from tribe B 500 years before that land was stolen from

(13:33) tribe A by the United States government. Do I think that that would be hilarious? Yes. Do I think that that actually would

(13:40) be what would have to happen if you are my opponents were consistent in their logic after I show them the hundreds of

(13:47) examples of natives stealing land from each other? Yes. Uh, imagine if we did

(13:53) this, by the way, for every perceived injustice of land changing hands. It's

(13:58) absurd and also hilarious. In short, I'm not even really sure what my opponent's

(14:04) position is here. But, uh, in asking, is it immoral to take land by force? The

(14:10) answer is, well, sometimes. Sometimes it is, and sometimes it isn't, right? But

(14:16) we wouldn't be appealing to the idea that just doing that in and of itself was always immoral because that would be

(14:22) preposterous. It would monolithically put up a thing which you guys don't even believe. How do I know you don't believe

(14:29) it? Well, because Chuck over here already told us. She conceded that force

(14:35) doctrine was moral using Nigeria as an example of revolution which is also hilarious. Force doctrine so that you

(14:42) understand what it actually is. Nigeria. Yeah. Whatever whatever it was. Okay.

(14:47) The point is, and by the way, I didn't interrupt you once, Chuck. That wasn't very nice, Chuck. But anyway, the the

(14:54) idea here is of what forced doctrine is is uh is pretty simple. Forced doctrine

(14:59) is just saying that all rights come from men. Not making a might makes right

(15:05) argument. Rather, forced doctrine is giving you a descriptor for how the world works. Now, you can argue with

(15:12) force doctrine if you want to. with that descriptor, but you would have to replace it with a more accurate descriptor. And nobody to date has been

(15:19) able to do so because it's an accurate descriptor. Otherwise, I would not have come up with it. Uh you say, "Do unto

(15:26) others as you would have done unto you?" Well, here's the thing that's interesting about that. By whose metric?

(15:33) The secularist metric or by the Christian metric? Which metric should we use and utilize since that's part of

(15:40) Christian ethics and not a secular ethic? Why should we adhere to your version of what that means? You say

(15:46) morality is subjective and then at the same time you say that there's some type of universal here which you're appealing

(15:52) to. Right? Ah all morality is subjective but universally it's always wrong to

(15:58) take land. That's that's a contradiction in and of itself. That's a and not a uh

(16:04) when you say land ownership is not universal. Well, I agree. I agree that

(16:09) this is a social construction. So we have to start with what ownership actually is. I would say I would make

(16:15) the claim that ownership is one a declaration that a thing belongs to you

(16:22) and then that would have to be backed by some kind of force for you to keep said thing. For instance, let's say for for a

(16:29) second you were walking through a desert and you were thirsty and you came across a dead body with a full canteen. If you

(16:35) took that canteen and drank from it, would you be stealing or would you have a deference of

(16:41) ownership or you would feel like this was a justified transfer of property because the person who was there no

(16:46) longer needed the canteen and then if somebody tried to take the canteen from you, would you say, "No, it's mine." I

(16:53) think you would. Right. So, I think just by the establishment of what we would consider ownership to be, I think you're

(17:00) going to end up having to concede to our position. When you say taking land by force is immoral, I really do want you

(17:07) to to contend with the tax doctrine. I think that you're probably a pretty protaxes guy if you're a Democrat

(17:14) anyway. And I I I would love to know how that's not theft by the same metric that you gave us for what theft is.

(17:22) Also, you said orthodox war theory, aggressive war is condemned. No, it's not. No, we have saints who conducted an

(17:31) aggressive war like St. Helga who literally unleashed pigeons, pigeons

(17:36) that were on fire to burn down an entire city and killed everybody inside it. She's a saint. You have no idea what

(17:42) you're talking about because Christianity and Christian ethics are pluralistic,

(17:47) right? You cannot make the universals. They're going to be case by case specific for a reason.

(17:54) You say uh and I'll just end with this. When you're talking about indative

(18:01) Americans, I wouldn't want to say Indians and offend anybody's delicate sensibilities. What you're alluding to

(18:07) is the myth of the noble savage. I'm going to tell you the truth about what was really going on with Native

(18:12) Americans. They were sacrificing each other on top of temples, cutting each other's hearts out. They were raping

(18:18) children. They were killing and murdering each other in mass all the time non-stop. And if you came across a

(18:27) culture like that, what would you do? Is the first question I'll ask. You know,

(18:33) we just leave. Yeah, right. Yeah, right. Like that's ever happened. But I'd be happy to hear

(18:39) about the myth of the noble savage. And we can go tribe by tribe if you want and you can explain how noble they really

(18:45) were when we get into their actual history. So in short, I just want to summarize

(18:51) with this. You don't understand force doctrine. You don't understand orthodox theology. I don't even think you

(18:57) understand the prism of the history that we're talking about. And on top of all of this, just to kind of tie it all

(19:02) together by your own definition of what theft is, taxation would be theft. And I want you to say it. And with that,

(19:08) that's the end of my opening statement. Thank you. Thank you to all of you. I appreciate it very much. As a kind

(19:14) reminder to the audience, we are going to get through our open dialogue for the debate. Then we will move into closing

(19:21) statements. Then we will read and respond to your kind super chats. After that, of course, as always, our favorite

(19:27) part. We will move into open panel dumpster fire where you're allowed to come on as the public and uh ask

(19:33) questions and prompt and all of those fun things. Uh ladies and gentlemen, I leave the floor open to you. Yeah. So I

(19:40) if you don't don't mind I'd like to begin with just a a query so we can get some semantics taken care of. In

(19:47) fairness you did query several things and I think Charlie was resp

(19:52) you made several in your opening statement. If I have a query did you answer to any of them. You didn't give

(19:58) it an opportunity to That's right. So that's what I'm doing right now. What I all I'm not even trying to uh engage in

(20:03) that right now. I just want to get some semantics done. So the thing is is I want to agree to some terms with you

(20:09) guys so we're not talking past each other. Don't you agree that that's very important in a debate that we get our

(20:15) semantics taken care of so we're not talking past each other. We know exactly what the other side means by the words

(20:20) that they're saying. Can we do that real quick? Are you setting the standard like

(20:26) definition? I'm asking going to ask you for what your standard is and you can definitely ask me for what mine is. I just want to make sure that our

(20:31) semantics are in order. All right, let's go. I I just want to make sure that Charlie gets a chance to to make the point. I'm okay with with discussing

(20:38) semantics, but I don't want it to get too uh nitpicky, nitty-gritty because I'd rather actually discuss the

(20:44) conversation at hand rather than like, you know, freak ourselves out over

(20:50) definitions. Okay. Well, I'm not looking necessarily at just definitions. I just want to make sure that we understand

(20:56) what we mean. You agree with me that words can have different meanings for different people, right? Sure. Okay. So

(21:03) then I want to make sure that when I use the word theft or when I use the word conquest, we're talking about the same

(21:09) thing. Otherwise, we're going to be talking past each other in this debate. So Chris, what is uh theft from your

(21:16) view? The repossession of a piece of property in order to retain it

(21:22) unnecessarily. meaning that you could have obtained that piece of property a different way in most cases, except

(21:30) you've decided that you're going to circumvent that, short circuit it, and take somebody else's property instead.

(21:37) Repossession of a piece of property when you could have gained it in when you could have gained it a different way.

(21:44) When you could have gained it a different way. Okay.

(21:50) And then um when we're discussing force doctrine, will will you accept our

(21:56) definition of what force doctrine is, which is that it's a descriptor which explains that rights come from men? Do

(22:02) you agree that that's our view? I agree that that is your view. Yeah. Okay. So you agree that that's our view. So

(22:07) you're not going to later say uh that you guys are saying might makes right and things like this because that's not

(22:13) what we're saying, right? Yeah. I'm sure we can clarify that further at some point. Gotcha. Okay. So, force doctrine,

(22:20) you agree with our view. And then the last thing that I want to ask you is

(22:25) conquest. Um, what do you consider conquest to be?

(22:31) I think that's going to vary depending on the period of history that you're looking at. What do you consider it to

(22:38) be? I I would consider it to be an invasion of a sovereign space for the purpose of taking up ownership of that

(22:45) space. invasion of a sovereign space to take up ownership. Okay, that's that's all I I

(22:52) wanted uh to know. I just wanted to make sure that we're not speaking past each other. If you guys want any of the

(22:58) semantics to be clarified by us, now is a great time to do that before we move into whatever your queries are. So, I'm

(23:05) sorry. Force doctrine is specifically laws are made by men. No, that rights

(23:11) come from men. Rights come from men. The the the gender, not us as a species. No, the sex, not the gender.

(23:21) Okay. Which I which you I'm sorry. Do you agree with me that gender and sex have

(23:26) two distinct meanings? I think that that is not relevant to the conversation at hand. You asked it. So why did you bring

(23:33) it up? It's not I know what you mean. I know what you mean. Okay. So you would agree with want to clarify that we were

(23:38) talking about this. So when I say when I say men, I'm talking about sex. I'm not

(23:44) talking about those who identify as men. I'm talking about the sex specific of men. That wasn't the question. Yes, it

(23:50) was the question. If you were talking about species, us as a species. Are men and women a different species? No. I

(23:58) think she I think I think she just utilized the word gender. But uh in

(24:03) terms of your position, Andrew, I think she meant the same thing that you would say in terms of the reason I'm really

(24:09) clear. I'm very clear about this. will use men as a as a uh you know as a

(24:16) standin for our species as the human species they will say men that's true or mankind or things like

(24:23) this. Yeah, I agree. That is what I was asking. Sure I was asking I'm willing to grant on the era specific what you're

(24:29) talking about that that could be the case when they're also referencing women when they say mankind. I can I can even

(24:35) agree to that. But the reason I'm not willing to grant something like gender or you saying do you mean the gender of

(24:41) men is because that has a loaded meaning. So I'm going to semantically distinguish between the two and say my

(24:47) meaning of man has nothing to do with gender but has to do with sex. That's all. Okay, that's fine. Okay, good.

(24:54) Okay, so I'm ready for the queries. What do you guys got? Yeah, go ahead. Um well

(25:00) first I would like to say that uh I was not invoking the uh myth of the noble

(25:05) savage. I am quite aware uh that some indigenous tribes of the Americas were

(25:10) in fact quite brutal. Um and this in fact kind of ties into the point that I made that when you employ the force

(25:17) doctrine you will always be subject to it yourself at some point. Uh the the

(25:23) sacking of but we agree. Huh. Yeah, I

(25:29) don't I don't disagree. I agree with you 100% that all people are subject to force doctrine. That that is a

(25:35) descriptor for how the world works, including me, including you, including Marte, including Sarah, including

(25:41) everybody. Can I can I make sure we get one element of this correct? You say that is how the world works in your

(25:47) mind. Is that how the world works in indifferent to any kind of human

(25:53) autonomy or ability to make our own decisions? In other words, are we able to evolve beyond that reality or is it

(26:01) your assessment that you're talking that is just a fact of nature? I'll answer your question. What you're talking about

(26:07) is the idea of what is socially constructed versus what is material reality. When I ask you, sir, what is a

(26:14) right? What is it? It's going to depend very much on the

(26:20) definition of Yes. I'm asking for your definition. What's a right? What is a right to me? Yeah. Uh, my rights begin

(26:27) where yours end. Yeah, that doesn't tell me what a right is. That just it tells me the application you would use for

(26:33) what a right is. What is a right? It does. A right is is is basically applied evenly across all

(26:39) people or it is not an equal right. That doesn't tell me what a right is. What is

(26:44) a right? A right is something that you have a a a right to. Uh wait, as a human

(26:53) being, you're using the word, dude. You're using the word to describe the word. If I asked you what a man is and

(26:58) you said a man is somebody who's a man, would that give me bogged down with semantics? I don't see how this is

(27:03) relevant to do. Do you understand that? I thought we're talking about taking land by I'm sorry. Did he bring up

(27:09) rights? If he brings up rights, I have every

(27:14) business. It's my business to ask him what he means by a right. And if he says what I mean by a right is anything I

(27:21) consider to be a right, then that's important for the debate. How do you have a right to Don't ask me a question,

(27:26) answer it. What is a right? I I can ask a question. You can after you answer mine. What is a right to the question?

(27:32) What is a be helpful uh in terms of the debate because we are talking about

(27:37) taking property per se? It is valuable to which you think you have a right to. You think you have a right to property.

(27:43) That's why I want to know what a right is. What is a right? What is it, dude? You are owed it on the basis of your humanity. You're owed what?

(27:52) proper treatment of some kind. What does that mean though? Do you see what I mean? Like that doesn't tell us what it is. It's soiety dependent, dude. It's

(28:00) things that we are guaranteed. You're tell I understand. You may have a right to exist. You may have a right to have

(28:06) an abortion. You may have a right to all sorts of things. That doesn't tell me what a right is though. What is a right

(28:13) itself? Why don't you tell us, Andrew? Why don't Why do I need to tell you what your [ __ ] definition of a thing is, Chuck? Because you're complaining.

(28:19) You're complaining right now. I need to know. Okay. Listen, Chuck. Chuck. Chuck. Listen. Chuck. Chuck. I'm trying. I'm

(28:26) I'm trying to work with Chuck. I'm trying to work with you, Chuck. Just a second. Just a second. Uh uh Christopher

(28:32) and Charlie, would you be agreeable that uh you think a right is a social construct of some sort? Yeah. What is

(28:39) it? Okay, let's start there. What What the [ __ ] is it? When you say right, what does that mean? Dictionary. I'm going to

(28:46) guess it means a different You can I don't care what you look up. You could take your time and look up what you think a right is. Just tell us what a

(28:52) right is so at least we're on the same page. I mean, I told you it's something that you are owed on the basis of your

(28:57) humanity. That doesn't a right is Yeah, it doesn't. It just Well, because it is

(29:03) a social construct. So, it is uh it's a it's it's a very influx thing. It

(29:09) depends on where the [ __ ] you are. So, you have a right to not be stolen from, but it's very influx and subjective, and

(29:14) we're not really sure about it. Is that right? It's conditional, made up. So, it's conditional. We just made it up. It can depend on the, you know, the country

(29:21) that you're in. But it is. So So, so then theft itself is a social construct.

(29:28) I mean, everything's a social construct. Oh, wait, wait. No, no, no. I'm sorry. Is a tree a social construct? Um, the

(29:36) word trees. All right. Is a tree a social construct? Not the word tree. A tree? Yeah. Is a tree a social

(29:43) construct? Why the [ __ ] are we talking about trees? Because you just said everything is a social construct. Is

(29:48) that an accurate statement or did you just make that up? No, I see you do this. I watch some of your debates and you do this all the time. You don't

(29:55) actually address the [ __ ] discussion. You bog people down on semantics.

(30:00) Here's what here's what I do. What I do is go after the pillar [ __ ] hand. Yeah. I'm going after the pillar of your

(30:05) view, which is No, you're not. You are arguing semantics. I'll tell you what. You don't want to make an actual argument. What is your argument? Tell

(30:11) I'll tell you what. Go ahead. Go ahead and tell me the thing that you want to get to and I'll show you how the pillar

(30:17) of what we're talking about is semantically based. Go ahead. Whatever it is, pillar of the argu like what

(30:23) we're in, I guarantee it. You You're concerned. You're upset. You think that

(30:28) uh white people stole the Indians land. That's your big contention, right? But you have no concept of what [ __ ]

(30:33) theft is. So why shouldn't I go after the pillar of that? Why shouldn't I go after the pillar of that? If you have no

(30:39) concept of what a right or theft even is, why should I listen to a [ __ ] word you have to say, Chuck?

(30:47) Can you explain it to me, Chuck? Use really small words. Do you not know what the definition I don't know what your

(30:53) definition of the word theft is? Cuz you just said it's a social construct, [ __ ] Oh. Oh, jeez. Geez, Chuck, you

(30:59) really got me with that dictionary. Like, I don't understand. You just said that theft is a social.

(31:06) This is not debating. This is not debating this. So Chuck, what you just

(31:12) said, just a moment. What you just I'm not interested in this.

(31:19) Then run, Chuck. Then run away. Rage quit. Chuck, if you don't mind, if you

(31:24) don't mind, if you don't mind. Thank you. Okay. I do find it very vital in in

(31:30) order to get to a foundation. If we disagree on what a word means, then we're not going to be able to have the

(31:36) the topic or the argument at hand anyways. Uh so I do find it. So here, look, I I'll just make this super clear,

(31:42) crystal clear. I'll give you my position. I'll give you my position so that you got you can attack my position.

(31:48) My position is this. You just got done saying to me, Andrew, theft is a social

(31:55) construction. Everything's a social construct. Rights are social constructs. Theft is social constructs. All of that

(32:01) is socially constructed and society dependent. So how could you make a claim that even if white people came here and

(32:08) put every Indian to the sword cuz they thought it was really [ __ ] fun. They took their kids up and they chopped

(32:14) their [ __ ] heads off for fun. They made them into little Indian shiska [ __ ] bob. They were like they shisha

(32:20) bobbed up all the engine kids. How could you even say that's immoral, Chuck? If it's just culturally dependent and just

(32:27) up to the culture, what the [ __ ] is actually immoral about it, Charles? What?

(32:33) Because we have to live together. Oh, cuz we have to live. We don't have to live together, Charles. Chuck, do we

(32:39) have to live together? Kill each other. We could all die. We don't have to even kill each other. Stupid. We don't. No,

(32:45) not only do we not have to kill each other. Survive for our species to survive and to function. Our species can

(32:51) survive fine without living with each other. Yeah. Why does our species conditions conditional all the way

(32:57) through? No standard, no base, no grounding, nothing. This is crazy. Yeah, you just said question that I have given

(33:03) what you've just said, which was addressed in my opening statement, and I'd like to get to it because I think

(33:09) this is actually vital to the point. Is your argument that because the European

(33:14) settlers found it necessary to eliminate the Native Americans in order to claim

(33:20) their land because they felt threatened by certain tribes that at that point in time it was not immoral?

(33:27) No, of course not. So I have a universal concept of morality. But the problem

(33:33) here is like we're starting off the query with an internal critique. I think it's fine for you to internally critique what we think as well. But as we start

(33:40) the query for the internal critique, I don't understand this view where you claim you and Chuck that these are

(33:47) social constructions. Rights are completely fictitious and made up and theft is completely fictitious and made

(33:52) up and yet somehow we're supposed to apply this standard to what happened with the natives. Tell me why the [ __ ]

(33:59) we should do that if it's all just made up. Dude, what do you mean made up? Because it's

(34:05) how you made it up out of your what? Okay, so this is why Okay, hang on. You see how you said social contract? Do you

(34:12) see why you just said let me let me answer his question by let me answer his

(34:17) question. You so he asked a question that it's a good query. What do you mean by made up? You see you're asking for

(34:23) semantics. That's smart, right? What I mean by made up is that from your view,

(34:28) right? Completely fictitious. They come out of your mind. You make them up out of thin air. They're a product purely of

(34:34) the mind. They exist nowhere in material reality. So like let me ask you this. Can you touch a right? Can you taste it?

(34:40) Can you smell it? Can you see it? Where is it? Show me a right. Show me one. Can

(34:46) either of you do that? It is a concept that we have come up. It is a concept we

(34:52) all agree upon. That we all agree upon. Do we all agree upon them? Like do you agree upon the concept that I have a

(34:58) right to own a RPG? God, I don't think that we have that

(35:04) right. Yeah, I know. So, we don't agree on the concepts then, I guess, do we?

(35:09) It's almost like we have like a semantic argument here that we need to get through because like we totally like

(35:15) don't agree on what rights are. Listen to me. Listen to me. Listen. I believe

(35:23) that we have social contracts that we adhere to because we want to survive as

(35:29) a species. And we understand that the survival of our species is good. It is good for us to be alive. And I can

(35:36) harmony with each other. Cor like you don't I don't like bad things to happen. I think right we all agree we like okay

(35:44) if it is the case then that you believe in social contracts. What's wrong with having a social contract of might makes

(35:49) right? Because it is not conducive to the survival of our species. How is it not conducive to the survival of our

(35:55) species? It seems like it would be just fine to live under an empire. It seems like it would be just fine to live under

(36:00) these things. It seems like we would survive just fine. Why wouldn't we survive under empires?

(36:06) We've survived traditionally under empires. What are you talking about? Tell me why why is it that making Hang

(36:12) on. Hang on. Hang on. Let me let me finish the query. Let me finish the question. Why is it that if you had a social

(36:19) contract then you believe in social contracts? We had a social contract for might makes right. That that would

(36:26) somehow be bad. You love social contracts. Why would that be bad?

(36:33) I'm sorry. Restate that. Why would it be bad to have a social contract of might makes right? How would that be the same

(36:40) as being good to each other and ensuring the survival? How would you why would that being bad right? Yeah. When you say

(36:47) good, good is also the product of the mind, right? Of course. Yes. But we are talking about So then what's the what's

(36:53) the issue here? theft of land which requires the displacement or the the

(36:59) death of its original occupants. So when we discuss the colonization of America,

(37:05) we are talking about you know 1500s we have about 5 to 10 million uh sometimes

(37:11) the the they will estimate 55 million um

(37:16) who mostly died of disease mostly died of disease yes that the Europeans brought which wasn't intentional but was

(37:22) indeed a product Well, that's like everything. Yeah. But let me ask you this, Chuck. If it is the case uh uh

(37:30) lady and gentlemen, if it is the case that the Europeans came in here and they

(37:36) wanted to make a shish kebab out of all the little Indian children,

(37:41) what violates the social contract here that you're talking about? What social

(37:47) contract did the Europeans have with the Indians? When you make shish kebabs of people's children, they will do that to

(37:52) yours, which has happened historically. Did they do it to us or did we just conquer all their [ __ ] and take it all?

(37:57) Uh, no. They did definitely like kill and scalp like women and children. They did. Oh, so then they weren't there.

(38:03) Actually, I have some uh examples. Um, so we were defending ourselves. So during the uh No, these were retaliator.

(38:11) Oh, so you can retaliate. I didn't know that you could retaliate. I think in self-defense. Yes, I believe in

(38:17) self-defense certainly. Um so so if you have the Jamestown massacre

(38:23) the Katan tribes killed approximately 400 settlers including women and children. The Hutchinson massacre of

(38:28) 1643 in New York and Hutchinson and her children were scalped tortured and scalped before they were killed. That

(38:35) was a uh Christian woman living alone with her children. Um the revolt of 1680

(38:41) in New Mexico. Uh wow that's something. 400 Spanish settlers killed, including

(38:46) Well, I mean, they killed a woman and her children. You don't think that that's savage? I mean, you should read about what we did to the Native

(38:53) Americans. Does that mean that you can kill innocent people? You live by the sword, you die by the

(38:59) sword. We here, listen, listen. I see that sounds an awful lot like might

(39:04) makes right, lady. Sounds an awful lot like might makes right. You like with

(39:10) the application of the force doctrine. I am disagreeing with the application of the force doctrine. I think it is all

(39:16) you're doing is proving the application of the of the the uh force doctrine. All you're doing is proving it. Marte, did

(39:22) you I was going to let first amend I mean a cult say something. What were you going to say, sir? Yeah. No, I'm curious

(39:28) because Andrew previously wanted to know what a right is. I would like to know what Andrew's definition of right in the

(39:36) entitlement. Entitlement absent duty is what I would consider a right to be. No,

(39:41) no. I mean, what would you consider? You you keep using the phrase might makes right. No, no, no. You use the phrase

(39:49) defending that, but I want to know what No, I'm not defending it. I'm showing you via an internal critique why when

(39:54) you said the words might make right that makes you did in your opening statement what you said in your opening state.

(40:00) Actually, if you listened to my opening statement more closely, you would understand that I was saying that that's not the argument you're making. Do you

(40:06) want me to reread that part again? Yes. Let me find it. Hold on just a second. Find the first time you mentioned it

(40:13) though, not the second. Hold on. You guys I do this awesome

(40:19) thing where I take notes the entire time you guys are talking. So I make sure I don't mischaracterize what you're

(40:25) saying. Yeah, that doesn't mean you take accurate notes. That's true. But we're going to find out in a second when you

(40:30) pull it up and we're going to find out that I am accurate and that you said my opponents believe in might makes right.

(40:35) You'll see for yourself and then I'll be vindicated and you're gonna have to say that you're sorry. Are you gonna are you

(40:41) gonna are you gonna say you're sorry after you read it out? Point that was made in the open

(40:47) veiling that you're saying that's not what you're saying, but it is actually

(40:53) at the root of everything that you're about. No, I'm giving you what you're saying is if I have a bigger gun than

(40:59) you or bigger muscles than you or a better army than you Mhm. that if I take

(41:05) your stuff in as we look at it in the past, we can't make an argument that that was wrong

(41:12) because I was simply using the ability that I had to take what I felt that I tell me why it's wrong. That's what

(41:19) we're here to discuss. Yeah. Tell me why. That's what I'm asking you. Why is it wrong, bro? Survival of our species.

(41:25) Right. How is how is it not conducive to the survival of our species? The question that I want to know each other.

(41:31) It doesn't end right. First of all, it is indeed conducive to the survival of our species to kill and murder. Tell me,

(41:38) tell me descriptively how we ended up with less people via the murder of the

(41:44) Native Americans. Can you explain that to me? How do we end up with less? It seems to me his from the historic

(41:49) standard, how many people were alive then versus now? That's you're getting a far field. I

(41:55) want to stick to the point that we're I don't think so. Your claim is it's conducive. How was it not beneficial?

(42:02) Seems like it was totally beneficial. What was unbeneficial about it? The the death of the millions, the destruction

(42:10) of cultures. And what was not beneficial about that? It we you ended up having an

(42:15) entire uh land seas which was rich in resource, led to a massive population

(42:20) boom, led to the strongest military on earth, led to even global peace. You could make the argument it led to global

(42:27) peace. So tell me lady, how is it not conducive to humans? Even if it is the

(42:33) case, I grant this entire thing that we went and we just shish kebabed up the engines cuz it was the funniest funny

(42:39) thing we could ever think of doing. Tell me how that wasn't conducive to humans flourishing cuz it seemed like we

(42:45) flourished fine. Uh explain it using what we could get to

(42:50) that if you want this conversation with you. I also think that uh we could argue that it led to the invention of the

(42:57) nuclear bomb in some capacity, which could be the death of us all, frankly. So, I'm not sure if like us developing

(43:03) weapons capable of like wiping all of us out. I think that that's actually kind of worse.

(43:08) Wait, you mean a nuclear armistice where every country now has the ability to obliterate each other and none of them

(43:14) do because because if they did there would be nuclear retaliation which has led to the most global stability we've

(43:22) ever [ __ ] seen. How is that? Again, I'm not even making the claim here h all

(43:28) countries having nukes is good. I'm not even making the claim having nukes is good. I'm only making the counter claim

(43:33) to you that this is somehow not conducive to human flourishing. Prove it. Prove it. Nuclear weapons. I mean,

(43:41) yeah, prove it. There is a pretty significant conflict in uh we bomb. Okay. Should we have not nuked the

(43:47) Japanese? No, we should not. War was almost Can you look up what the

(43:53) estimates would have been of the deaths if had we not nuked the Japanese? Actually, we could have um conceded on

(43:59) the whole emperor being a divine individual thing and the Japanese would have taken our deals. So, that's kind of like up in the air. People Wait a

(44:06) second. Wait a second. I'm sorry. You said earlier, and I got the note here, retaliatory fighting is fine because

(44:13) it's self-defense. Did the Japanese attack us at Pearl Harbor? I think that at that point, we had uh retaliated in a

(44:21) proportionate manner, thus far. Oh, you So, what you really mean is you should only be able to respond in a

(44:27) proportional manner. Yes. Um, Andrew, so if you piss me off Mhm. it would be

(44:32) insane if I were to show up to your house and torch it, right? That would be crazy. That would be a lot, right? Just

(44:39) cuz you annoy me. Like if I Yeah. But why would that be a lot? Why would that be a lot though? Because it is not equal

(44:45) to the insult that you dealt me. So if it is the case then that I'm fighting with a man who is uh weaker than myself,

(44:54) but he punches me first. I should only use an equal amount of force to stop that threat. Yes. So if it is when my

(45:02) younger siblings have hit me before, I have not I'm and I'm 10 years older than

(45:07) my younger sister and six years older than my baby brother. There was a point in time where I was larger than my little brother. Okay. When they kicked

(45:12) me or punched me, I didn't use all of my power to break their [ __ ] noses. Even

(45:17) though I understand that someone if someone is physically weaker than them than me, it

(45:24) is it is not appropriate to use. So then by this logic, if somebody broke into your house and made the stated

(45:30) declaration that they're only there to take your stuff but won't hurt you, you should not be able to retaliate with

(45:35) physical violence. Correct? I mean, they're on your property. So, wait a second. Oh, wait a wait a second.

(45:43) It has to be proportional, though. Remember? So, if a person shows up to your house and says, "I'm just here to

(45:49) take all your stuff, but I'm not going to hurt you." The only proportional thing you could do back would be to take

(45:54) their stuff, right? Uh, no. It's not about doing the exact same thing. Oh, it's not. So, so what

(46:01) does proportional mean then? Like within the same range? What does that mean? What does that mean, though? What does

(46:07) that mean? If a person's walking out with my TV and I blast his ass, is that is that permitted?

(46:14) I mean, depends on the state you're in, but personally for No, I'm asking you how I would handle that. Yeah. I would

(46:19) probably shoot him in the leg or something. I don't know. Oh, do you think you So, you would shoot him in the femoral artery? No, not the thigh. The

(46:26) leg. How? Well, I mean, I'm sorry. Is the thigh part of the leg? Well, hang on. What is the greatest deterrent to

(46:32) somebody coming onto your property and robbing you? Uh, a massive shotgun? No.

(46:37) Yes, it is a well-lit property.

(46:44) Actually, actually, go look that up. You can look it up. Not only law enforcement source, they will tell you the greatest

(46:50) deterrent against Bro, I I taught Listen, listen. I've taught CPL classes. I've taught CPL class my whole life. I

(46:56) was a journalist. I've talked to police officers. Let me tell you what the biggest deterren

(47:01) let me ask you a question. How come Black Lives Matter didn't riot in the [ __ ] countryside even though there was massive populations in the

(47:07) countryside? How come they didn't do it in conservative states? Why? You know who did riot? Who? For the most part,

(47:12) who anarchists? Okay. Why didn't they riot where there

(47:18) was red states with real loose gun laws? are angry kids who live in urban areas

(47:24) who ride the bus everywhere. It's due to the country where the population happen in country

(47:31) are being targeted by police. So the majority of black Americans do not live in the rural countryside except in

(47:37) Mississippi. I'm not familiar with Mississippi. You don't you're not familiar with the largest population of black people which

(47:43) is Mississippi. I am from California and the rural the rural countries and towns.

(47:49) I had mostly white and Latino people living there. I'm sorry. Was BLM a national movement? That Yeah, BLM was a

(47:55) national where the [ __ ] I lived, buddy. That's great. And is California

(48:02) persecuted by Does California have highly restrictive gun laws? They do actually. Yes. How come then in the

(48:09) great state of in uh for instance of Arkansas did you not see a bunch of BLM

(48:15) people move in has the most gun deaths in the country? Yes. That's because there's a massive minority population

(48:21) there who kills each other with guns. Mostly handguns. Yes. Do we have guns?

(48:27) No. No. It has nothing to do with the guns. It's not the guns, lady. It's not the guns. Hey, hang on. Hang on. Help me

(48:34) out here. I don't know what the [ __ ] you're talking about. Hang on. Help me out here. Can you Can you just help me out here? Why the [ __ ] are we talking

(48:40) about? Because you brought it up. Dumbass hypotheticals and we're not talking. Oh, it's a dumbass hypothetical.

(48:47) We all agree to both. Would you agree to a question? Yeah,

(48:54) I'll take I'll take any questions you have, but you got to actually let me answer them like I've been willing to do for you.

(49:00) Can you define property? Yeah. So, I actually think I did this in

(49:05) my opening, but uh I'll do it again. So, I would consider property to be a declaration of possession plus the force

(49:13) to back up the possession. So, if you saw a piece of property that

(49:18) you wanted, you could take it by force and that

(49:24) would be okay. That doesn't log that doesn't logically follow. That is what you outlined there. No, it's not

(49:30) outlined an exchange of Okay, listen. I'll explain. I'll show you. It's things that you have that you can Hang on. Hang

(49:36) on. I'll prove it. I'll prove I'll prove my point for you so that you understand exactly what I mean. The headphones that

(49:42) are on your ears. Do you own them? Yeah. Yes. What gives you ownership of them? I have a receipt. So, you have a

(49:50) declaration that you own them. Yeah. Okay. And then if somebody tried to steal them, would you be willing to

(49:56) apply force or the force of the state in order to stop them from taking those headphones from you, which you've made

(50:01) the declaration you own? I think so. Depends. Okay. Well, then you and I have now decided that what ownership means is

(50:09) declaration plus force. Anything else? This gets us back to our original

(50:16) question, which is, did the Native Americans own the land they were on? This is a great question because

(50:21) according to your debate partner, the Native Americans had no ideals of land

(50:27) ownership. So, how is it that if you have a social

(50:32) hang there? Let me go ahead and go ahead and correct it, but read the whole thing. Land ownership quotes is not a

(50:40) universal concept. I can read it. Can you read it again? Sure. Because we'll be discussing col colonization, it is

(50:46) important to clarify that land ownership is not a universal concept. The indigenous peoples of the Americas don't have the same structures as European

(50:53) settlers. So when we talk about who has the right to specific tracks of land and why, my conception of land rights can be

(50:59) summed up by article 26 of the United Nations Declaration People. So you're going to peoples have

(51:05) the right to lands, territories, and resources which they have traditionally owned, occupied, or otherwise used and

(51:12) acquired. And that is typically going to appeal to what Europeans decide land ownership is even though the natives

(51:18) themselves had no concept of what land ownership was by your own metric. They do now. Oh, but they do now. So, they do

(51:26) European framework. But wait, what do you mean? We killed them most of them. And now they are forced to operate under

(51:32) a European framework. That is now we have So, I just want Hang on. Hang on. I

(51:38) I'm I'm willing to again I'm willing to grant all of your arguments to show you how absurd they are. You want to appeal

(51:44) to a United Nations European standard for what land ownership means. Right.

(51:51) Sure. I'm telling you that that so you would take the sovereignty away from the original natives who were there who did

(51:59) not agree that that's what land ownership meant. Right. Um

(52:04) what are you referencing? Did original natives by your own opening statement,

(52:10) right, did they understand the concept of land ownership or not? Yeah, obviously they had territories that were

(52:17) Yes, indeed fought over. Oh, wait. Okay, hang on. It's the same principle. The issue here is it's the same principle.

(52:24) Yes. Then how come you're not appealing to like the Apache version of land ownership, but you're appealing to the UN European version of land ownership?

(52:31) You killed most of them. Like I don't know what you mean. So they don't So because you because there's so few of them, they can't figure out what land

(52:37) ownership means. No, it's because we're working in a different context now. It's because you're appealing to European

(52:43) ideals of ownership, not to Native American ideals of ownership. And you haven't even justified. But here's

(52:49) what's you haven't even justified why we should appeal to those. What the what the uh indigenous idea of land ownership

(52:56) Okay, then tell me how tell me tell me how tell me how it follows. Essentially, if you work the land, it's yours. Says

(53:02) who? Which Native American said this so I can look up his quotes? It was actually John Lock. Native American. Oh,

(53:07) so John and John Lock is an Indian. John Lockach. Famous European philosopher. John Lock. Wow, man. You really got me

(53:14) with that one, buddy. We could go over every single tribe and how they defined land ownership. Well, if I'm Buddy,

(53:20) you're Madame. And Madame, let's go over each one. What I mean, do you think that like ancient man had no concept? Like do

(53:28) you think that like it wasn't until like the [ __ ] Renaissance that we understood like that if you live in a

(53:34) place finally we're there. You're meant to live there. We're finally there. So how did ancient man identify ownership

(53:41) of a thing? Do you think by working it by living on it? By and what would

(53:46) happen if somebody came around who they didn't want to take their [ __ ] What do you think ancient man did to them?

(53:54) They would fight and kill each other. Oh, they'd [ __ ] kill him. Yes, they would [ __ ] kill him. I need you to

(54:00) listen to me. Holy [ __ ] This is amazing with your ears and thoughts and mind. I'm listening very closely. Doctrine

(54:07) does not exist. My point was that it is not good and we should Oh, it's not. It

(54:13) doesn't. And in addition, when you apply the force doctrine, you will be retaliated against. I would also like to

(54:19) point out so more force doctrine. Not good. Yeah. And it's a never ending cycle and it's bad. That was my opening

(54:27) point. Did you not listen to Okay, hang on. Hang on. So, so I want to make sure we got it right. And I just I want to make sure that you remember when I asked

(54:34) your debate partner, sir, do you will you concede that our view of force

(54:39) doctrine is what? What is it, sir? Archaic. What is it? Your view of force

(54:47) doctrine is that men are stronger and so they must be the ones to allow I didn't say any of that. I just said that men

(54:53) are the granters of rights, right? And and who made them that way? Uh men,

(54:59) right? Nature made them that way, right? Why? Uh why are men stronger?

(55:05) You mean fundamentally? Why did nature make men stronger? Um well, I mean, who knows? Was it to

(55:12) conquer women? Um again, is that the purpose of our big

(55:18) muscle? Why? I don't I don't understand why you're asking me the purpose of the thing, which descriptively you agree is

(55:24) true. No, I'm asking you biologically, evolutionarily. How the [ __ ] would I know? I'm sorry. Am

(55:30) I responsible for [ __ ] evolution? Am I responsible for evolution?

(55:36) Talk about evolution. Did I go Did I Did I like Did I use the minations of Andrew Wilson's great psyche to figure out

(55:43) evolution? You might be darn close to figuring something out here. Yeah. So,

(55:48) why are men bigger? Why in general in nature from an evolutionary view okay

(55:54) I'll explain I'll explain the best I can from an evolutionary view from an evolutionary view um we're we're looking

(56:00) at survival of the fittest survival of the fittest is going to be uh um if if

(56:06) it is the case that you have a species which is engaging with its environment and this and that and it doesn't make it

(56:12) right it is sourced out right it's it's gone you agree with that that's what survival of the fittest is why didn't

(56:17) women develop strength Then because they have the ability to rear children which

(56:24) gives them a different physiological makeup, right? Maybe, not maybe. No, there is nothing

(56:31) in nature that says females can't be bigger and stronger. Female hyenas is

(56:36) stronger than male. Yes, there is. There's lots of things inside of nature which determine that homo sapien males

(56:42) are going to be bigger and stronger than females who have the reproductive organs. And here's why. Here's matter.

(56:49) I'll explain. You have to have, bro. I'm going to explain. I'm going to explain.

(56:55) So, here's the thing. If we're looking at the physiology between men and women, you agree with me that women can give

(57:01) child birth and men can't biologically. Yeah. Yeah. Does that require things like a uterus? Does that

(57:08) require ovaries? Does that require ministration cycles? Does that require all sorts of things with which

(57:14) physiologically are going to create a distinct makeup? You're describing things as they are. I'm asking you, bro.

(57:20) I'm asking you. Hang on. I just want to make sure we agree on this. Do you agree with me that that's going to require

(57:25) distinct physiology, physical characteristics which are different from that of males who cannot do those tasks?

(57:31) Yeah. But so if that's a requirement of that that it would follow that if it was

(57:36) natural selection and we were following evolution which is a gradual change over a species over hundreds of millions of

(57:42) years that men and women who are the same species developed separately based on skill sets one for the purposes of

(57:50) rearing children and one for the purposes of protecting those who rear children. Yeah. Ah protecting.

(57:57) Interesting. Interesting. That's why they're bigger. Right. Not to subjugate,

(58:02) to protect. Yeah. But but here's here's the problem with this, right? Can you

(58:07) protect people by subjugating them? Yeah. Yes, you can. Hey, you can protect

(58:15) your people. No, before you before you do the

(58:20) before you do the gotcha, let me give you the other side of that. All right.

(58:26) Give me the other side. I can't wait to hear it. Yeah, sure. So the other side of that is that you might be able to

(58:32) protect your people by subjugating other people. That doesn't necessarily Can you protect your people by subjugating your

(58:38) own people? In other words, if I We're not talking about morality. Let me finish. If I were a if I were an early

(58:45) settler and I came to the United States, this has nothing to do with what we're talking about. Let's stick with what we're talking about. They have other

(58:51) options. Do they have places they could go to? Oh my god, this such a gish gallop. This means nothing. Answer my

(58:56) [ __ ] question. Can a can people protect? No, I want an answer to my

(59:02) question. You shut the [ __ ] up, lady. I want to know. I want to know the answer.

(59:08) Answer the [ __ ] question first. Answer the question first.

(59:14) If everybody's going to over each other, I want to know the answer to my question and then he can make his point. Is it

(59:20) the case, sir, or not that you can subjugate a group of people and protect them through subjugation? Is that true

(59:26) or not? Hang on. Answer the [ __ ] question and then ask her that. She's answering the question. Shut the hell

(59:33) up. I'm going to go get a drink while you never answer this question. Go get a drink. So you're running away. By

(59:39) getting a drink. He can rewatch it later and learn. That's running away. Getting a drink. So if you go to the bathroom,

(59:46) that's running away. Maybe if he leaves, we can take a moment to educate the audience.

(59:51) Ask everyone kindly. I love the entertainment factor, but it's getting to the point where I can't understand

(59:57) what the [ __ ] any of you are saying. If we could just take a step back, calm down a little bit. We'll get through the

(1:00:03) questions one at a time. If we could be mindful of each other and respectful. Thank you.

(1:00:09) Just answer the question and then ask your question and I'll do the same for you. Answering the question. Yeah. Okay. Can you answer it then? Can you

(1:00:15) subjugate a group of people and protect them at the same time through subjugation? Yes. What is the prompt for this debate? The the prompt right now is

(1:00:23) whether or not it's immoral to take land by force. So if I take land by force

(1:00:29) because I think that you still haven't answered my question. You just subjugate other people because in my mind My god,

(1:00:35) this guy. You can't you're you're incapable of answering questions. Can you hold on? What? Okay, then I'll tell

(1:00:41) you what. I'm going to not say a word, but I'm just going to come right back to this. I'm not going to let you evade and

(1:00:47) I'm going to make you answer this [ __ ] question. So you might as well just answer it now. Can you subjugate people and protect them through

(1:00:52) subjugation or not? The prompt is whether that you're not answering the

(1:00:57) [ __ ] question. Dude, the prompt that we're debating and you said you were going to be quiet and let me finish. So,

(1:01:03) let's see how you do. The debate that we are having is whether such an action is

(1:01:10) moral or immoral. So, yes, I would concede the point that you can absolutely protect your people through

(1:01:17) subjugation. The question then becomes, is that moral? If you had another

(1:01:23) alternative where you could go elsewhere and not kill, maim, destroy, and steal,

(1:01:30) wouldn't that be the more moral? You haven't. Well, hang on. You haven't actually shown us yet how subjugation

(1:01:37) requires theft, stealing, and any of this? You define subjugation then. How would you go about it? Well, now it's

(1:01:43) your claim. I don't need to define your [ __ ] claim. You asked the question. Can you Yeah, I asked you the question.

(1:01:48) I don't define your answer for you, dude. You then you're saying that the answer I gave doesn't satisfy the

(1:01:54) question you No, I'm saying I'm just asking for the answer de or demonstrate for me that subjugation requires theft

(1:02:00) or any immorality at all. Demonstrate it. You need to define subjugation. No,

(1:02:05) no. By your definition, you need to define it. You Why would I need to define your [ __ ] view, dude?

(1:02:12) I don't know what the hell you're asking. You don't know what I'm asking when I ask you about your view. If

(1:02:17) subjugation is to come in and just chop everybody's heads off and put them on pikes outside the town. Yeah, that would

(1:02:24) be bad. Can you can you show why that's a necessary condition of put them on a train and take them to a gas chamber

(1:02:29) somewhere? Okay. Right now, do you have to follow the laws of this nation? Ideally, yeah. I subjugation how much

(1:02:36) longer that is that subjugation in what way? Whatever way you you consider subjugation to be. Is that

(1:02:42) subjugation? subjugation in an attempt to stop people from harming others. So,

(1:02:48) yes, it's subjugation. So, and would you would you agree with the Greeks when the Greeks said without law there can be no

(1:02:54) freedom? Yeah. Okay, great. So, then you're what you're admitting there is that you can subjugate an entire group

(1:02:59) of people for their own protection. That's [ __ ] good. No, you didn't ask that question. You said, "Can you I didn't need to ask the question. It's an

(1:03:05) entailment of your own logic, dude. That's an entailment of your logic. You've How am I changing the question?"

(1:03:11) Because the original question was can you protect your people by subjugating another group of people and you said yes

(1:03:17) you can but the great asking is that moral yeah okay you can should you here

(1:03:26) let's find out if this is true we'll just do a logic test is taxation theft

(1:03:32) it can be yeah is it not def definitionally why because generally

(1:03:38) you're getting something for that money if you don't want it clean water you're in clean air. Yeah. What if you don't want it though? What if you don't want

(1:03:44) any of that and you want to keep your stuff and they tax it anyway? Is that theft? You don't have to pay your taxes.

(1:03:50) You do have or what happens if you don't? You might lose your property. And do you agree with that law?

(1:03:58) I think. All right. Let him answer. Let him answer, lady. Let him answer, lady. Let him answer, lady. Let him answer,

(1:04:05) lady. Let him answer. Answer the question. That's going to be a nuanced response. Can you answer the question?

(1:04:10) If you don't pay your property taxes, should you default on the property or not, sir by law? Yeah. Should do you

(1:04:18) believe that that's moral? I believe that in certain circumstances it's not given the Okay. So So which

(1:04:24) circumstances are those? If you're retired and you're on a fixed

(1:04:30) income and you've lost your inability. If you're poor and your government passed a shitty bill that cost you your

(1:04:36) health care and caused you to add up a ton more debt. Okay. If you had student

(1:04:42) loans that you've long ago paid off and you still have $30,000 in interest to pay off and the government comes and

(1:04:48) says, "No more grace. We're going to take everything you own." Got it. I got it. Now, we got three great examples

(1:04:55) of how it's immoral. Now, give me three great examples of why it's moral. I think in the case of if you're using

(1:05:01) that money to make life better for other people, then I would support that. Okay.

(1:05:07) So, if if it's the case that the government comes in and I'm sorry, give me three. Give me three. Just like you

(1:05:12) gave me three for why it's immoral, give me three for why it's moral. I can't think of a third option. You can't think of a third option. So, you support

(1:05:19) property taxes because you think the government is taking that money and then uh redistributing it to other people?

(1:05:25) No, I think they're redistributing it to services for other people including so to other people. Okay, great. So then uh

(1:05:31) why is it the case then? Should I be responsible for paving my own road for a certain distance or I'm not making any

(1:05:38) of these claims. I'm just saying I'm just saying to you I would like to point out to you real quick, sir, what you

(1:05:44) said theft was. I'm going to pull up your own definition of it.

(1:05:50) repossession of a piece of property when you could have gained it a different way.

(1:05:56) So by your definition, you are now an a literal performative contradiction A and

(1:06:02) not A. You claim that theft is repossession of property when he could have gained it a different way. And then

(1:06:08) at the same time you say it's perfectly acceptable to repossess property if it's gained through the same exact means as

(1:06:15) long as it's redistributed to other people. You're in direct contradiction. Were you in favor of A and not A? Aon, I

(1:06:21) want you to answer to your contradiction. That's A and not A. Sir, I'm getting there, but I'm going to ask a different question to get there.

(1:06:26) Ready? Were you in favor of student loan forgiveness? Why or why not? No. Why not? Well, you took out the debt. You

(1:06:33) got to pay the debt back. That's the way it works. Why is it different on your house, on your property taxes? You used

(1:06:39) resources. It's not. I don't believe taxation's theft. It's your logic, dude. No, you're asking whether I believe it's

(1:06:45) moral to repossess property if you don't pay the property tax. And you said it

(1:06:51) is. I said it. And then you said that what theft is is repossession of

(1:06:58) property. Repossession of property which you could have gained through another means. Could the government have just

(1:07:03) bought your house? That would be another means. And yet you're saying it's perfectly fine for them to seize your house if you don't pay your property tax

(1:07:09) as long as they're distributing it to another person. That's a and not a. It's a direct contradiction. You idiot. You

(1:07:15) [ __ ] idiot. Yeah, let's ask the question then. Relax. How are these people this [ __ ] st How are you

(1:07:21) people this [ __ ] stupid? How are you a journalist for 18 years, dude? Aren't you a dad? Why are you having a panic

(1:07:26) attack? Get your drink yet. Lord, more alcohol maybe. Yeah. Well, I need it.

(1:07:32) You got to understand from my end, you sound like the dumbest human beings that I've ever talked to. You just gave me a

(1:07:38) direct logical contradiction and then said, "No, that's not absurd because my feelings and stuff." No, because you

(1:07:43) allow no nuance. You want an answer that I would have I would have given you the nuance. You don't actually argue like

(1:07:50) you don't you just What do you think an argument is? You don't even know what an argument is.

(1:07:57) Hi, Marte. Would you like to uh chime in? You've been pretty quiet. This is

(1:08:03) nonsense. It's crazy. the opinions from like like what we're getting from the [ __ ] [ __ ] I mean, that's

(1:08:10) the thing though is like we could talk about people oppressing people, but we have a populace here, the prison population. Like that's conducive to our

(1:08:17) environment to helping other people by oppressing that class of people. Would you release all these murders to the

(1:08:22) public? Like that's the thing though. This can bleed over into other areas of life. And like all we're asking for is

(1:08:28) your position to clarify this. And then we're getting push back by saying I don't want to clarify this. All it boils

(1:08:34) down to and all we want to do is get clarification for your position and understand what makes this right and we

(1:08:40) can't even get that. We still haven't gotten that throughout this whole debate. Why don't why don't if you think we can't answer why do you think it is

(1:08:46) moral? Why do you think the colonization of America was moral? We we're asking you if it's moral, if it's right, and we

(1:08:53) can't even get that from you. You agree with the force doctrine, man. So So tell us why is it moral? Did I say I agree

(1:08:58) with force doctrine? Is this not the the [ __ ] opening of this? how this whole thing began was your threads where

(1:09:05) you're a bull about what what was the exact thing that you said specifically this

(1:09:11) this argument that started oh you're going to go into my threads there's no such there is not stolen land

(1:09:18) it's conquered land disposal of war go to the victor been happening for centuries and will continue for centuries more and you have argued that

(1:09:24) this is moral so descriptor why no I never said morality in there I'm just offering a description of something

(1:09:30) you're offering feel that it is moral. Is that something that happened? Did I say it

(1:09:35) ought in that anywhere in that post that I put up? No. So, your position is that it's moral though. Is that not the

(1:09:42) position? There was no moral claim that I made on that. Sometimes when I got the prompt for this debate,

(1:09:48) when I got the prompt for this debate, it said uh prompt, is it immoral to take

(1:09:53) land by force? No. Andrew Wilson and Marte. Yes. You're asking me about the prompt now. You were asking me about my

(1:09:59) post which is a completely unrelated thing as far as morality. Now we're talking about the prompt. Yes. Now we So

(1:10:04) we're asking you to add the com component of morality. Take land by force. I think that that's a fair Hang

(1:10:10) on. I think that's a fair question. So when you ask now finally you're actually getting to a fair question. So when is

(1:10:16) it moral to take land? That's what we're really asking here, right? Yes. So when is it moral to take land? Ever? I want

(1:10:23) to I I want to ask you. Well, okay. Well, let's start with this. Can both both sides agree that it is sometimes

(1:10:29) moral to take land by force?

(1:10:36) Uh I would say just I'm not going to apply the word morality to that. What

(1:10:42) what I'm sorry for question

(1:10:48) property because you're not paying your property taxes. That might not be moral. That's not a moral question. That's a

(1:10:53) question of I'm sorry. Justice is justice has a moral implication. Should you do what's just? Justice doesn't

(1:10:59) always have a moral. It always does. A question. Can you provide me? You think Okay. You said you think it is sometimes

(1:11:05) moral to take land. Can you provide examples of when you think it is sometimes Yeah. I thought it was just fine for like the Soviet Union to invade

(1:11:12) Nazi Germany and take their land. I thought it was fine. I thought it was fine for us to invade the Japanese

(1:11:18) islands and take that land. I thought that was fine, too. I also think that it's fine if you come across like um a

(1:11:24) people group like I'll give you an example. I'm going to tell you this example. It's it's a little bit of a hit

(1:11:30) in the gut, but you can look it up if you think I'm lying to you. They're called the [ __ ] warriors of Papa New

(1:11:35) Guinea. And I'm going to explain and I know how this sounds, but you can Google it right now if you think I'm lying to

(1:11:41) you. And here's what they do. the come warriors of Papa New Guinea. They like

(1:11:47) to make the little children, the boys inside of their tribe. Well, fill up the

(1:11:53) in the most disgusting way you can imagine on male seammen in order to have a right of passage. Now, under Christian

(1:12:00) ethics, I'm fine putting all these [ __ ] to the sword. Like, I'm fine with that. Taking the children out of

(1:12:06) that domain and uh you know, redistributing them somewhere else. Um,

(1:12:11) but can you actually claim the same thing? Can you even claim if it is the

(1:12:16) case these children, they love this. They say, "I want this. That's all they say is that they want to stay. They love

(1:12:23) this. This is their right of passage because it's culturally relative." Can you even make a claim that it's bad? Can

(1:12:28) you even tell me why that would be bad from your view? I mean, yes. I think that the abuse of children is wrong

(1:12:34) because those individuals are abuse. How could it be abuse if they're demanding

(1:12:40) it? Lady, if they're demanding to be Yeah. Well, how could it be rape if you're demanding

(1:12:46) it? Because it's a child that doesn't know what's what's Yeah. But you see,

(1:12:52) the problem is with your relativism, the problem with your relative view, right? Is that even child is relative to you.

(1:12:58) It's all culturally dependent. What is a child's even relative from your view? Everything is [ __ ] culturally

(1:13:04) relative to you. 21st century, we have a pretty complete definition of child. We Who's who the [ __ ] is we? They don't if

(1:13:11) you say the word child the they don't have the same view. Why are they wrong?

(1:13:17) Why are they wrong? Why are they wrong? A vulnerable human being that they are

(1:13:22) touching in. Yeah. So, but here's the thing again. The idea of what is a child

(1:13:28) for you is relative to the culture, right? Of course. Yes. Okay. So, then if they say a [ __ ] 12-year-old boy is a

(1:13:35) man, who the [ __ ] are you to say they're not? Because I can observe that that is not a

(1:13:41) man. How? Give me the objective metric for what is manhood. That has not hit puberty yet. Is still very much. They

(1:13:47) hit puberty at 12. Yeah. Okay. You look at a teenage boy, you're going to tell me that's a man. Tell me what your

(1:13:54) metric for manhood is. Has reached maturity. What does that mean? When is that? Maturity. When? When you're done

(1:14:02) [ __ ] growing. When is that? Do you not know when you're done? Yeah. You don't know. So what I'm asking you

(1:14:08) is like what's a when when is manhood for a man? When does that kick in? Tell me. I guess it would be relative

(1:14:15) dependent on when Yeah, it's [ __ ] Exactly. It's relative depending on the culture. You are being ridiculous.

(1:14:21) There's absolutely ridiculous group an age group that by and by we all agree

(1:14:27) are children. And by the way, prepubescent viewing view. Yes. Prepubescent. And are they prepubescent

(1:14:33) at 12? They could be, but but the ones who aren't the ones who aren't puberty

(1:14:38) going through puberty is very much not the same as having finished puberty. Oh. Oh, okay. Wait a second. So, if they

(1:14:45) finish at 13, it's fine. They're men. Don't finish puberty at 13. You can. Yeah, of course you can. Has their brain

(1:14:51) finished developing? Can they have like let's say that their brain did finish developing? Their brain finished

(1:14:56) developing at 13 and their By the way, if you're going off of that, then you're not a man till you're 25. How can you

(1:15:02) consent that? Actually, that study um isn't really uh reputable because they

(1:15:08) stopped studying the subjects at age 25. So, that's not really I totally and completely agree. When you can make when

(1:15:15) you can make sound, reasonable judgments. When is that? Well, you don't do stupid [ __ ] When is

(1:15:21) that stupid [ __ ] Give me the age. Depends if Yeah, that's right. It depends. So, you have no objective

(1:15:27) metric for when these people are even men. Like all you're doing is giving me [ __ ] who can't do that. There are

(1:15:33) severely disabled adults. So you don't have a standard at all. Nothing. No standard for anything who cannot

(1:15:39) understand the consequences of their actions. They consent to interactions. You know what? I'll just I'll just grant

(1:15:45) all this with other adults. If you came across, if you you and I, let's just say

(1:15:50) like a company came and we were on an expedition, an expedition, and we came

(1:15:56) across this tribe in Papa New Guinea where they do that to boys as a right of passage, and I ordered my men to go in

(1:16:04) there and just take these [ __ ] out, gun them down, and we're getting these kids the [ __ ] out of here. Did I do

(1:16:11) anything wrong? Could you have gone about to gun down the the the They don't

(1:16:18) want to go. Yeah, they they don't want to go. You see a man currently sexually abusing a child and physically attack

(1:16:24) him. I think good. If it is just this is my knowledge of this tribe. Mhm. For

(1:16:30) some reason, you go and kill them all. Bad. I wait. I don't understand. So, you want me to leave the boys there to get

(1:16:35) molested? No, but there are other approaches that What? Okay. Give me the approach. Certainly, there are certainly many,

(1:16:42) many, many cultures that have practices that I strongly disagree with. And

(1:16:47) within those cultures, you can often time find groups of people that are advocating against those practices. And

(1:16:54) what you can do is you can [ __ ] support them. Okay? But it's relative. So, you can't actually say that their

(1:17:00) perception of what is immoral is worse than yours because it's relative, right?

(1:17:05) I think the bigger question, let her answer. Let her answer. If we agree on something, then they don't agree with you. We both want it. They don't agree

(1:17:12) with you. So what makes your standard superior? Well, they never agree with her. They just don't. If they object,

(1:17:18) that's their culture. I'm discussing like, for example, feminists in Iran. Feminists in Iran. Those are groups that

(1:17:26) I agree with that do not agree with. I agree. You agree with them. What makes their standard more correct if it's just

(1:17:32) culturally relative? because they are having their freedoms restricted. What

(1:17:38) makes that more that's cultural rel do you know what relativism means? It means it's just as good there as it is here.

(1:17:44) So if that's the case, if it's all relative, how could you say that your standard for feminism is better or worse

(1:17:51) than their standard for oppressing women? How? Because you can observe that some people are coming to harm and are

(1:17:58) unhappy with their treatment. You can observe that under feminism. You can observe harm coming to women. But why

(1:18:04) would a harm standard if it's culturally relative be object are you saying it's objectively worse?

(1:18:12) I would say that anything that infringes upon uh people's ability to live the way

(1:18:17) they want in a way that is not harming other people. I think

(1:18:23) so then it's not culturally relative. I think that cultural relative doesn't

(1:18:28) mean that there is uh no wait there's universal ethics. Wait, is there

(1:18:33) universal standards? Are you about to make a universal claim? No, I would say that generally Oh, wait.

(1:18:40) No, you're going to contradict. Sometimes people share the same values as Yeah, but they don't share the same values. And isn't it if it's a case that

(1:18:47) is relative the feminist groups that are there advocating for themselves. Yeah. But the non feminist why are the non

(1:18:54) feminist wrong if it's relative? Wouldn't it be equal to your view?

(1:18:59) If the people that are experiencing these injustices disagree with them then I would support the people who are experiencing they don't disagree with

(1:19:06) them. If they don't disagree with them any wrong. If they don't disagree with

(1:19:12) them are they wrong? If you're a cultural relativist,

(1:19:17) are they wrong? Yeah. Do you have a right to even tell them what's wrong? By my standards, yes, I would say that by

(1:19:23) your st. So, but by relativism, God. Got it. So, if it was the case that you came

(1:19:29) across this island where they were diddling these little boys, you can't tell me that objectively

(1:19:37) they're even doing anything wrong, can you? I am dead certain because in nearly every society that I can think of. So

(1:19:43) you're gonna make a universal moral claim that people people do not like being subjected to. So you're making a

(1:19:49) universal moral claim people will be against that. So are you making a universal moral claim? The claim that

(1:19:55) I'm making is that universally people do not like to be abused or harmed. Okay.

(1:20:00) But in this case the kids don't see it as abuse or as harm. They demand it because it's a right of passage. Tell me

(1:20:06) why they're wrong. I mean, do you know that for a fact about those children? Yes. You look it up right now. Yes.

(1:20:14) The come warriors of Papa New Guinea. No kidding. Look it up. Can you tell me why

(1:20:20) they would be wrong, please? With sugar on top.

(1:20:26) Yes. Because it is harming. Well, she's looking that up. Can I ask? Because they're Okay. But but it's relative

(1:20:32) harming a group of people. So, is it objectively wrong to harm groups of people? Yes, it is harm to do bad. Yes,

(1:20:39) it is. Is it objectively? Is it objectively bad to do harm to people?

(1:20:44) Objectively, I would say that that is also subjective. However, many of us can

(1:20:50) disagree or agree upon [ __ ] laughing like that. It's Well,

(1:20:56) it's a universal It's universally wrong. Subjectively, dummy. Like, what the [ __ ]

(1:21:02) are you talking? It's universally subjectively wrong. Andrew, why don't you explain why is

(1:21:08) that what that thing? Okay. Yeah, I'll explain. I'll explain. If you make a universal Yeah. If you make Start

(1:21:15) talking about Jesus, if you make a universal If you want to know why warriors do the I'm explaining to you

(1:21:21) I'm explaining you the un the distinction here between universal claims, universal moral claims,

(1:21:27) objective claims. She's saying objectively this is always wrong. Subjectively, that's a plus not a which

(1:21:32) is a contradiction. A and not A is a contradiction. Do you understand? Like you can't say

(1:21:38) this is an objectively subjective claim. That's like saying uh uh I don't know that's a dog cat.

(1:21:45) It's a and not a. It's a contradiction. It's the third law of logic for a reason. The law of non-contradiction. We

(1:21:51) cannot contradict what we say or it can't be true. Right? That would be the the base of a truth claim. If I ask a

(1:21:57) question I usually ask for a reason. Why do the com warriors do what they do?

(1:22:03) It's part of their It's part of their cultural integration for how to become a warrior taught down through the lines

(1:22:08) for whatever reason. Why why do they why would that matter? Is it universally

(1:22:14) wrong or not? I think that context is always important. Okay. Knowing the

(1:22:20) historical context behind things is universally healthy when it comes to

(1:22:27) how can this be universal objective opinion of yours when they don't agree with you? Yeah. Can you be universal?

(1:22:35) How can this be a universal uh construct as if you want to say this and objective

(1:22:40) when they disagree with you? Would you not be oppressive to this culture?

(1:22:45) Correct. by their standards. And if you were oppressive, wouldn't

(1:22:51) that be a good thing? Um, so again, while I believe morality

(1:22:59) is subjective, so that we can continue as a species. So that we can continue as

(1:23:04) a species together in harmony. Yeah. Why wouldn't they continue as a species? I

(1:23:10) mean, they'd probably continue, but certainly not on this earlier said, "What if I went

(1:23:16) and just wiped them all out?" Practice comes from um like a hatred of women.

(1:23:22) Yeah. Whatever it is, who cares? It's a hate. It's their practice. It's because they hate women. Tell me why it's wrong

(1:23:27) though. Uh because this is that in that culture in that culture if they are doing this

(1:23:34) practice because they think women are disgusting and evil and boys should be separated from them and relieved of the

(1:23:40) taint of the woman. Yeah. There are probably most likely feminists uh some

(1:23:45) sort of I mean maybe not at this point but so is feminism objectively correct?

(1:23:50) I would say that uh subjugating anyone what's my question? Can you

(1:23:57) repeat my question? To me, to me, to me, it's wrong. To me, it's wrong. People agree. So, feminism is not So, feminism

(1:24:04) is not objectively correct. Do you believe in gravity? Uh, sure. Do you think it's objectively correct? Yes, I

(1:24:11) think it's objective. Can't really prove it, though. That just proved that it fell. It

(1:24:18) doesn't actually prove anything. Well, it proves that there's a force that made it fall. That doesn't I don't know what

(1:24:23) that means. What's a force? You can have a string tied. literally right in front of you, Chuck. That's true. It's a good thing. It's a good thing that I can

(1:24:29) demonstrate using empirical data that a force exists, which is material that we can measure. Can I get back to the force

(1:24:36) is what we call gravity. The for we call that force gravity. Now, you people saw

(1:24:42) things drop a million gazillion times before we discovered what [ __ ] gravity is. And they called that force

(1:24:48) not lots of different things, but they all didn't jump off cliffs because they knew they would die. Huh. Yeah.

(1:24:54) Precisely. Ah, so they knew there was a material force that pulled you down. The implications of like the concept of

(1:25:01) gravity and what that means until we developed wings. Okay, so wait a second. I'm sorry. I'm sorry. So people thought

(1:25:08) it was okay to jump off of really high cliffs before we knew what gravity was. That's not what I said, but Oh, so they could observe that there was a material

(1:25:14) So they could observe that there was a material thing which happened. Yes. Oh, that's crazy. And what's the

(1:25:21) first step of what's the very first step of the scientific method consequence? What's the very first step beings lady?

(1:25:28) What's the very first step of the scientific method in order to have an experiment? What's the very first step?

(1:25:34) Hypothesis. No, you [ __ ] duts. Observation. Observation. You must observe. My bad. I

(1:25:42) didn't study science. You must observe, right? You have to have an observation. How would you come up with a hypothesis

(1:25:48) absent an observation? hypothesis about what are we at any point going to get back to the Yeah, but this is all this is all

(1:25:55) relative to this. You're you're making the claim. So here's why. I'll explain I'll break it down. I'll break down how

(1:26:00) all of this is relevant very quickly. You say this is a theft and it's immoral. You have no standard for

(1:26:07) morality and no standard for theft. And your standard for theft is contradictory. I just demonstrated how

(1:26:12) it's contradictory. Her uh demonstration of morality is that it's both objective and subjective. Both of you are in

(1:26:19) direct contradiction. That's why semantic. Now hang on. Hang on. Hang on. Hang on. Hang on. Almost done. Almost

(1:26:24) done. I'm almost done. I'm almost done. Almost done. You asked why are semantics

(1:26:31) so [ __ ] important. Now you know because instantly I can get to the core of your worldview and see that you're

(1:26:36) [ __ ] completely in contradiction to your own standards which you demand that

(1:26:42) you apply to us when we're making arguments to the contrary using objective standards. Now if you want to

(1:26:48) make the query and probe on that that's great. I can't wait for that. But man, can you at least be [ __ ] consistent

(1:26:54) in your worldview? You didn't ask. Well, here's what you asked. What I mean by what I mean by morality being subjective

(1:27:00) is that everyone has a different moral code. My moral code has that the

(1:27:05) subjective of other human being the subjection of other is

(1:27:10) it doesn't [ __ ] matter. What I'm saying is that while morality is supposed I agree it doesn't matter if

(1:27:17) many people agree upon listen if many people agree

(1:27:22) ah a specific morality and we decide to enforce it then it is enforced I see so

(1:27:29) if it were the case that you had a country let's say where 80% of the women died from a plague and men outnumbered

(1:27:35) them four to one and then they universally agreed that raping these women would be morally acceptable and

(1:27:40) pass that into legislation that would be Okay. Right. That is not at all what I said. Did you

(1:27:47) not just Yeah, actually it is. What you just said is that universal you just said that universal subjective claims

(1:27:53) are bad based on consensus of the majority. I gave you an instance where the majority comes to a consensus

(1:27:58) against the minority. You would have to say that that's okay, right? I think that the entire world would be horrified

(1:28:04) by it. I don't I think that the majority of let's say there was no other world than this world where

(1:28:11) fantasy land where all the women die and then they get raped. Let's just say I think that the women would most likely

(1:28:16) dislike it. Yeah. Okay, great. But we have a consensus though.

(1:28:23) That's a and we have a consensus, right? Can we get back to the real world for a moment? We have a consensus. Can we get

(1:28:29) back to the real world? No. Can we get back to the consensus? I want to I want to You said consensus was okay, right?

(1:28:35) You asked a disingenuous question, Andrew, and I want to get disingenuous. Answer the question. Let me explain why

(1:28:41) it's disingenuous. You're never going to answer any [ __ ] question. You didn't ask here's what the question was. The scenario you posed was here is this

(1:28:47) group of people. They engage in a behavior that some in the West would find reprehensible. Would I be morally

(1:28:53) justified in killing those people in order to save those children? Yeah. Then

(1:28:59) you launched from there and into an interrogation about whether the consistency of that view it was morally

(1:29:05) right that their whether she believed that their uh habits were morally

(1:29:11) correct. Yeah, that's what you asked, right? And the problem with this question, the original question was

(1:29:17) would it be morally right to kill them in order to save those? Yeah. Why would it be immoral to do that? That's

(1:29:23) completely different. Okay. Well, I'll just ask you directly. Why would it be immoral for me to put all those men to the sword and rescue those children?

(1:29:28) Why? Because we have better ways of going about it. That might take a little more time. What are they? It might be

(1:29:35) educating them about why that's bad. It might be going So, how many of those children should I allow to get leaving

(1:29:40) them the [ __ ] alone? That's fair. How many of those children should I allow to be molested? Why you come to a consensus? How many of those children

(1:29:47) are upset at what you consider to be a zero? Hang on. Zero. To them, it's not

(1:29:54) harm. In their world view, it's not harm. Uh-huh. So, ah, let him let him let him

(1:30:01) cook. He's cooking. Let him cook, lady. Can you let him finish? I don't think Do you have children? By No. Okay. But I

(1:30:09) do. I do. So, therefore, I'm the expert. Yeah. No, no, no. Well, what I'm saying is is dude, I'm glad that the child

(1:30:16) lists are always telling the child you are. Let him answer someone that I I

(1:30:23) don't I don't think you're diverting right now. Yeah, who cares? Have a kid and then we'll talk. But but back to

(1:30:28) Christopher. Chris. Chris, you were cooking, bro.

(1:30:33) You're right. Is it the case that it's the kids perceive it as harmful? Well,

(1:30:39) no, Chris, they don't. So, am I morally unjustified in doing that? My question then to you is, is it morally

(1:30:46) justifiable to commit another act of immorality to save those kids? You're

(1:30:53) what you're doing is you're trying to you're trying to put this is worse than

(1:30:58) this. You're trying to get us to answer that question of whether I think it's less immoral to kill 2,000 people in a

(1:31:05) remote corner of Papua Nina because of something immoral that I would do it. Chris part of Yeah. Chris. Chris, I'll

(1:31:11) answer you directly. Yeah, Chris, I'd put them all the sword and I get all those boys out of there. The fact that

(1:31:16) you wouldn't and would allow them to stay there and get molested tells me all I need to know about your [ __ ] worldview, Chris tells me all I need to

(1:31:22) know about your worldview, Chris, I'm asking you by what moral what by what moral code do you decide that one of

(1:31:29) those actions is Chris? I'm glad you asked. I use universalized Christian

(1:31:35) ethics for my moral code. Oh, great. Let's dive into that. Oh, let's Chris

(1:31:41) tell me why it is if you could presuppose why it would be that I should not have an objective standard for

(1:31:48) Christian ethics or how Christian ethics is bad. I can't wait to hear it. Why is Christian ethics bad? Let's talk about

(1:31:53) whether Christian ethics protects say the subjugation of women using force.

(1:31:59) Let's Yeah, let's let's get back to that. Yeah, let's So, can I can I ask you how your Christian ethics makes your

(1:32:06) force doctrine okay? How does Christian ethics make force?

(1:32:11) Well, wait a second. I'm sorry. Force doctrine is actor. Force doctrine is a descripttor. I have

(1:32:18) the ability to kill these people because I don't think what they're doing is right. And so what I would do is I would

(1:32:25) appeal to this universal of Christian ethics to say why it would be that even if you had these universal if you would

(1:32:32) stop for 10 seconds lady, I'll explain them. If it is the case though, Chris, that you say to me, Andrew, this

(1:32:39) descriptor there there could be immoral things people do with this descriptor. I agree, Chris. The great thing about

(1:32:46) Christian ethics is that I can both see the descriptive truth of reality, which is force doctrine, and I can use

(1:32:52) Christian ethics at the same time to oppose the times where it's used immorally, objectively, and universally.

(1:32:58) And Chris, you can't [ __ ] do that because you just got done advocating to me why it's actually more moral for me

(1:33:04) to allow children to continue to get molested in Papa New Guinea rather than put them all to the sword, Chris. And

(1:33:10) that's how I know that I'm [ __ ] superior to all of you [ __ ] in every conceivable way, Chris. Now you get it.

(1:33:17) Is that your assertion that that was my claim? This is Andrew. We do not listen. Listen to me. I am not someone that is

(1:33:23) aggressively atheist. Okay? I was raised. I don't know what that means. I don't really care any but is that there

(1:33:29) is no proof that your god exists and there are many people around. What's your standard of proof? Well, there's no

(1:33:35) proof that he doesn't exist. What's your standard for what is proof? There are there are many many many people around

(1:33:40) the world that are not Christians. So your morality is not universal. You feel

(1:33:45) it is universal. I feel that my morality is also best. So what I also understand

(1:33:50) that my morality is not universal. Not. Okay. I think that that's a fair I'll

(1:33:56) engage directly with this argument. Okay. I'll engage directly with this with this. I'll engage directly. I want

(1:34:01) him to finish. Let me Can I at least answer to Can I at least answer to criticism? I'll get right back to it.

(1:34:07) Chris, hold on. If you never let me answer a moment, if you never let me

(1:34:12) answer, I'll answer. We will do. We'll let Andrew answer the question and then we'll redirect back to you, Christopher.

(1:34:19) Okay. Yeah. So the the law of excluded middle, a proposition is either true or

(1:34:25) it's not true. That is a law of logic. There's only three. You can look them up. It's the law of excluded middle.

(1:34:31) Proposition either true or false. It can't be in between. It can't be somewhat true. It is true or it's false.

(1:34:37) Or else the proposition is not sound, right? I'm sorry. The conclusion would not be sound and the entire argument it

(1:34:44) structure would uh basically fail. Right? The idea here is you have to use a law of excluded middle. It could be

(1:34:50) the case that I could be one of two Christians left on planet Earth. Me and Mr. Marte over here, right? Who's a way

(1:34:57) better Christian than me, by the way. I'm chief of sinners. I'm the [ __ ] worst of the worst. But the case of the

(1:35:03) matter is is that even if that were true, that doesn't mean that even if there's only two of us that were wrong

(1:35:09) or that we're saying something which is untrue or that we're when we apply universal ethics that that's untrue

(1:35:15) because there's only two of us. You on the other hand have the claim that because consensus says based on

(1:35:22) consensus this is what's moral. I can easily make the same grape analogy to

(1:35:28) you if it was the case that men outnumbered women a horrible disease went through and killed them down to 20%

(1:35:34) and men locked them up and caged them. That would be up to consensus and you would have to concede that would be

(1:35:39) immoral. Right. Right. Let her answer. Let her [ __ ]

(1:35:45) answer, dude. Answer the question. Not really like a answer the question. Answer the question like I just

(1:35:51) answered. No, but how could I interrupt my own question? Telling them to answer the question. I just want him to answer.

(1:35:58) She doesn't answer. I think that it would be wrong by my moral code. I would think that it would be wrong. But you

(1:36:04) couldn't objectively state that it would be wrong for men to put women in grape cages as long as there was consensus.

(1:36:11) Right. I didn't say that. No, that would still be wrong. My moral code and I

(1:36:16) thinkal world would agree that it is wrong to most of the world doesn't agree inside the hypothetical. The most of the

(1:36:22) world disagrees and think they belong in the cages. Why are they wrong?

(1:36:28) Because it's bringing harm to others and I don't agree. Yeah, but they don't believe that and they're the consensus.

(1:36:34) Why are they wrong and you're right? Because I don't agree with it. Oh, okay.

(1:36:40) So all of the entire standard of the world comes out of Chuck's mind.

(1:36:45) Fantastic. What Chuck disagrees with is what is immoral and what Chuck agrees with is what's moral. But at the same

(1:36:52) time, Chuck says, "Hang on." But at the same time, Chuck says, "Andrew, Andrew, you can't. If it was just you and one

(1:36:59) other Christian because you don't have the moral consensus of the majority, you would be wrong." Do you see how you just

(1:37:05) contradicted yourself again, Chuck? You would be right to you. Well, then I'm right by your standards,

(1:37:12) right? Because what's right to me is what's right. No, what's right to you is what's right to you. Okay. So, what's

(1:37:18) right to you is what's right to you. Yeah. Okay, great. So, then if it was the case that what was right to me was

(1:37:23) to have grape cages and I had the consensus, you couldn't actually say that I was wrong because I have the same

(1:37:29) standard you do, right? No, I could still disagree with you. Oh, sure you could disagree. But how could you say I

(1:37:35) was wrong? My my moral frame. Yes. All morality. So then you're the ultimate

(1:37:41) arbiter of morality, right? I'm not. Then then how could you disagree with whatever I say is moral?

(1:37:48) Because we have different opinions. So then So you have a different moral code. You have a So my moral code's not worse

(1:37:54) than yours, right? Uh I mean I would feel that it's worse

(1:37:59) than mine. I would think you're a real [ __ ] Okay. But I would feel that it's not. So what makes me wrong?

(1:38:06) except that you are the universal arbiter of everything that is moral. I guess it would depend upon

(1:38:15) me thinking you're wrong. Oh, so then you're the universal arbiter of all that is moral.

(1:38:21) I mean, you're asking me if if I think it's wrong. Yes. Okay. So then I also,

(1:38:26) by the way, am the universal arbiter of what is moral. All of the things which I consider to be immoral are because I say

(1:38:34) so. Okay. Just like you. Hopefully enough people agree or disagree with you. And so we're back to consensus. So

(1:38:40) as long as I have the consensus of the majority of men that we can put women in grape changes, then it's fine.

(1:38:47) It just means that you have the ability to do it. Does it mean that it's right or wrong? What makes it wrong? Other

(1:38:53) than you don't agree with it. Well, that's what makes something wrong. Oh god. So you're the ultimate arbiter of

(1:38:59) all that is moral. Dude, we are going in circles. Yes. Because your argument is your argument is circular. Your argument

(1:39:06) is circular. I I ask appealing to God is the same thing as appealing to your [ __ ] self. Okay. So So if that's the

(1:39:12) case, I'll even grant it. I'll even grant it. Hey, I'll even grant it. So if it is the case, you are the universal

(1:39:18) arbiter of morality. No, I'm not. It's consensus. What if consensus is wrong? Then it comes back to me. The universal arbiter of morality. What if What about

(1:39:24) consensus? What if consensus is wrong? Then it comes back to me, the universal. The reason the argument is circular is

(1:39:30) because it's your [ __ ] argument, lady. And it's a circular argument because you're the one making it. Me,

(1:39:35) I'm just agreeing with it. You're right. So, I'm going to use the saying on I'm going to use the same exact circular logic. I, Andrew Wilson, and the

(1:39:42) ultimate arbiter of morality. If you disagree with me, you're immoral. Now, what about consensus? Hey, consensus. I

(1:39:48) agree with it. Unless it disagrees with me because I'm the ultimate orbiter of what's moral. Now, you can prove me

(1:39:53) wrong right now by just telling me why it would be that if the consensus of people said to lock all of the women up

(1:39:59) in grape cages and they were raped by men all [ __ ] day long, why would they be wrong absent you saying that you're

(1:40:06) the ultimate arbiter of morality? Tell me.

(1:40:14) Yeah, I'm going to go get a drink while you think about that. Yeah. Can we get back to my question for you? Yeah. So

(1:40:22) the same thing to which appeal to really uh go ahead. You were like you're just

(1:40:27) shifting the goalpost from one move to one place to the other. That's it. That's all you can do. Did you have you had a question you you had built in

(1:40:34) there? Did you want to ask it? Well, I want to get back to this this conversation about this tribe

(1:40:40) in Papa Guina because he's out he's alleging that I'm saying that molesting

(1:40:45) that I think molesting kids is fun. Well, what's the choice besides what we would do? No, what I want to ask and

(1:40:53) I'll ask you, Marte, what would be intrinsic value? Let him let him ask the question, Marte, do you have intrinsic

(1:40:59) value? Are you valuable as a human being? Do you matter?

(1:41:04) Well, it depends on who you ask. My value may be different from somebody else's value. And you're asking me,

(1:41:10) yeah, there's value. Does your value come from in your estimation? Where does

(1:41:15) your value come from? It depends. Like if you ask where my value comes from, I could just plead to

(1:41:22) like, you know, my life, my abilities, everything else that's socially constructed. I can just say that that's

(1:41:27) my value. But you are religious, correct? Yes. So you believe that your

(1:41:33) value is part of your creation, endowed by your

(1:41:40) creator. Yes, we do have a a value that's endowed by our creator. But when we're talking

(1:41:46) about other cultures and we're interacting with them, then this goes to Charlie's to Chuck's point of they don't

(1:41:52) observe this behavior as value. Their value could be something different culturally intrinsic upon their land,

(1:41:58) their native species, their tribe, everything else. And that's why this is circular because she doesn't really have a standard going back to her. And I

(1:42:05) think that thing again appealing to yourself is the same as consensus

(1:42:10) because this is circular from her end. Otherwise, we have a consistent standard that's unchanging, unmoving, and yours

(1:42:17) is mine. We're just going to agree with you the whole time, and it's going to be circ. Hang on, hang on, hang on. We can

(1:42:22) resolve this very quickly. Andrew is the ultimate arbiter of morality. If we appeal to consensus and

(1:42:28) it doesn't agree with Andrew, then it's wrong because

(1:42:34) God is the ultimate arbiter of morality. No, no, no, no. Answer my question. Against God, it's the same [ __ ] No,

(1:42:40) it's not. I can actually disprove that. the ultimate. But before we do, but hang on. Hang on. Consensus does something

(1:42:46) agree with. Can you answer my question? Are you not [ __ ] right? Do you not answer my question not have a universal

(1:42:52) Christian? You're you're answering a question with a question. Andrew is the ultimate arbiter of morality. If the

(1:42:58) consensus disagrees with Andrew, right, then the consensus is wrong cuz Andrew is the ultimate arbiter of morality. Can

(1:43:05) you show why Andrew is not the ultimate arbiter of morality without disproving your claim that you're the ultimate

(1:43:10) arbiter of morality? I'm going to wait while you do that. I did not make the claim that I'm the ultimate arbit who is

(1:43:16) that things I observe things and I believe that they are wrong. Then who is the ultimate arbiter of morality? No

(1:43:21) one. Oh great to agree on agree upon things. Oh so in fact what we are doing

(1:43:29) right now. So if we determining if something is moral or not we are so if we agreed that grape cages should happen

(1:43:35) for women then that's moral right. No I would still be against it. you. Oh,

(1:43:41) okay. So, and and would everybody else be wrong and doing something immoral? I mean, do you think that there should be rap? Can you answer my question before

(1:43:47) you ask one? Would everybody be Lady I will answer every question you have? You

(1:43:53) just answer mine. Is it the case that if everybody agreed that women should go in grape cages and you disagreed that

(1:43:59) everybody else would be wrong? Yeah, I would still think that they're wrong. So, then who's the ultimate

(1:44:05) arbiter of morality? There's no ultimate arbit of morality. But how then how could they be wrong?

(1:44:12) Then how could they be wrong? Then how could they be wrong and offer a translation? How could they be wrong if

(1:44:20) you're not the ultimate arbiter of morality, Charlie? If so, what he's basically saying is is if you're

(1:44:27) utilizing the the idea that collectively if we all agree on something, then it is good, right? But what if collectively

(1:44:35) everybody agrees on this thing that you view as bad but based on your definition

(1:44:40) or or your premise, right? You're saying collectively if we all agree then it is good. So what he's saying is that's why

(1:44:48) he is appealing. She knows exactly what I'm saying. Sarah, she doesn't know a way out of it. Logically are good or

(1:44:54) bad. Do you think slavery is good or bad? Do you do you agree with slavery? That's a great Hang on. That's a great

(1:44:59) question. Now listen, I'm going to make Hang on. And I'll answer yours, too. I'm

(1:45:04) going to make a promise to both of you right now. And this is my adamant Wilson promise to both of you. I will literally

(1:45:10) put myself on the grill of every single question you have, and I will answer them in good. You keep saying that you will, but then you don't get because you

(1:45:17) don't answer mine. And that's what I'm trying to make the bargain. I'm making a great bargain right now. If you just

(1:45:22) answer a couple, I will literally say these words. I am open for the internal critique and I'll answer every question

(1:45:28) you have, but you've got to answer mine. So, let's start with this. If it is the case that the majority say

(1:45:34) women should go in grape cages and you disagree, please answer. Why are they wrong?

(1:45:41) Because I think that that's wrong. I think so. How are you not the ultimate arbiter of morality? My whole framework

(1:45:47) is based upon being good to others. And so you're the ultimate arbiter of

(1:45:52) morality, right? How are you not the ultimate arbit? Yes. In my world, in my brain. Yes.

(1:45:59) Correct. Exactly. It's perfect. Yes. I moral judgments in my world. I make my

(1:46:05) own moral judgments. Lady, then all answers to your questions, all answers to your questions henceforth will be

(1:46:11) because in my world, I make up the morals and they're always right because I made them up. Well, can we come to a

(1:46:18) moral consensus here that we think hurting people No. Yes, we can come to the moral consensus that Andrew Wilson's

(1:46:23) morals are always correct. No. But you would have to convince.

(1:46:29) Why? I'm sorry. I'm sorry. How would I need to convince the majority if the majority would be immoral by disagreeing

(1:46:34) with me? Can we from the hypothetical to to the situation? Your hypothetical is, would

(1:46:41) it be okay if the majority of people agreed it was okay with Andrew Wilson's

(1:46:48) idea that we should take the few remaining women and put them in grape cages? Sure. So that we can preserve

(1:46:55) humanity, right? No, forget preserving humanity just cuz it's fun. Okay, then

(1:47:01) you need to convince people. Why do I need to convince people it's not immoral? If people disagree, because in

(1:47:07) your hypothetical, you've just simply skipped over the most most important step, bro. Okay, we all decide together.

(1:47:14) It's the argument. It's it's it is the the way that we that we live. Hang on. Let's let's see if this Hang on. Let's

(1:47:20) see if this holds Hang on. I I agree debate. We come to And here we have a We

(1:47:26) can even agree with that. So, so I'll ask you the same question. Um, sir,

(1:47:32) if if the majority of people came to a consensus, let's say 99.9% of people

(1:47:37) came to consensus that women should be in grape cages, would you say that they were acting immorally?

(1:47:44) Would I say it? Yeah. I would want to know what the other 99.9% see that led

(1:47:49) them to believe that it was okay. Well, whatever it was, would you see it as immoral? I would hope that I would.

(1:47:56) Great. So then completely you're all you're doing is gish galloping and skipping there's no gallop. I'm just

(1:48:01) showing you the same logic. I'm showing you the same logic. If it is the case, hang on. Hang on, bro. Okay, go ahead.

(1:48:07) Homosexuals were able to move the approval of homosexual marriage from 27% in the mid '90s to over 70%. Yeah, but I

(1:48:15) disagree with that. So therefore, it's immoral. But you people do not. That's

(1:48:20) all that matters is that it's immoral to me. I'm the ultimate arbiter of morality. But when Charlie just made

(1:48:27) that argument, you tried to shoot her down with a gotcha. What? What argument?

(1:48:32) You tried to say, "Aha, you're the one who's the final arbiter of Oh, no. No. Actually, I'm agreeing with requires

(1:48:39) that you convince 99% of people." No, the opposite. I'm totally agreeing with Charlie. If she's the ultimate arbiter

(1:48:46) of morality, so am I. You just changed your position, dude. No, not at all. You areowed. You are. You didn't move the

(1:48:52) goal post. You packed up the whole [ __ ] camp. I'm sorry. How did I move the goalpost? Can you explain that to

(1:48:59) me? Because your hypothetical was if the majority of people decided that this was

(1:49:05) okay. Yeah. Would you disagree with them and think it was immoral? Yes. And would those people be wrong? How would you do

(1:49:13) that? What do you mean? How why would that matter? That why would that matter?

(1:49:18) That's irrelevant. So you're saying, "Okay, then let's accept your premise and move on to the

(1:49:24) next logical step in that." Okay, great. We'll move on to the next logical step. Anything you say that I disagree with is

(1:49:30) immoral. That's the next logical step. No, the next logical step. That is the

(1:49:35) Okay. All next logical steps are if you disagree with me, it's immoral. Sentence. Okay. Finish.

(1:49:42) The next logical step in that is for you to ask why do I think this is moral when

(1:49:48) everyone else says it's not. Because because I'm the ultimate arbiter of what's moral. No, you have to make a

(1:49:54) claim. I just made the why I think something is immoral. I think it's immoral because it does great harm to

(1:50:01) other human beings and that comes explain explain your thoughts. I think things are immoral. If they

(1:50:07) disagree with anything within my moral framework that I disagree with your moral code, I gave you a reason.

(1:50:14) Yeah. Anything that I think anything that I think that you disagree with is immoral.

(1:50:20) Okay. I don't understand why you're refusing to engage with the question. I could not engage with this in more good

(1:50:26) faith. So, here I'll I'll walk you through it. Everything Andrew Wilson says that you don't agree with makes you

(1:50:32) immoral. You say, "We got to appeal to the consensus." I say, "Okay, but if we appeal to the consensus and they

(1:50:38) disagree with your morality, are they wrong?" You say, "Yes." That moves you back down to this position here where

(1:50:44) you're the ultimate arbiter of morality. Well, if you can be the ultimate arbiter of morality, then I can also be the

(1:50:50) ultimate arbiter of morality. And why I think something is moral or immoral. Yeah, that's great. I also think that

(1:50:57) everything that's immoral is everything that disagrees with everything I think is moral. Immoral. You're being petulant

(1:51:03) in a child. I'm not only not being impetu I'm not I'm engaging in total

(1:51:08) good faith with everything you're saying. This is okay. Tell me what I'm saying that's wrong about this. Sarah

(1:51:14) Sarah, give her the floor and have her explain how I'm wrong. To have everybody stop for a second. What he's doing,

(1:51:21) Charlie, is using the very words that you were saying against you. And he's now using them uh to basically win the

(1:51:28) argument based on how you're trying to make Not even saying the words that I said. Okay, tell me the words you said.

(1:51:34) Explain to you why I think something would be immoral because it But why does that make it right? Why does that make

(1:51:39) it immoral though other than you think it? My moral the framework of my moral code is don't do harm to others. That's

(1:51:47) it. Great. My moral my moral code and my moral code that are wrong. Great. And my

(1:51:54) moral code is don't do anything that I disagree with you on or it's immoral.

(1:52:00) That's not a basis. Disagree with something. Why is that disagree with Why do you disagree with

(1:52:06) something? Why? I'm sorry. Do you have a reason why you disagree with with harm?

(1:52:11) Yes. Because I want our species to survive and I want people bring some more evil into the world. Me,

(1:52:17) me, too. I believe that our species will thrive best with women in rape cages. Tell me how I'm wrong. Okay, that's

(1:52:24) Well, thank you for giving me a response. Why do you think we would thrive best in rape cages? Well, I mean,

(1:52:30) [ __ ] autonomy. That's stupid. I just want there to be lots and lots of human beings, and that will make lots of human

(1:52:37) beings. Why do you think you deserve autonomy and those women in rape cages don't? I'm sorry. I'm the ultimate

(1:52:42) arbiter of what's moral. No, but explain why you don't. I just told you. I explained the same reason that you're

(1:52:48) the ultimate arbiter of what's moral. The thoughts that you have in your brain of what are bad, you think everybody who

(1:52:54) doesn't follow those thoughts as being immoral. I'm the same exact way. I can explain the the reasons why I don't like

(1:53:00) things or disagree with things. Yes, but those reasons come from your trying to argue for rape cages right now, dude.

(1:53:06) Wait, I'm sorry. I'm sorry. Let me get this right. The things which you believe are immoral. Where do they come from?

(1:53:12) Your mind. Uh well, I suppose based on the context

(1:53:18) under which I was I was your mind. You know your mind which was

(1:53:24) you know they come from your mind shaped by my environment. So your morals come from your mind. Sure. Yes. Mine too.

(1:53:32) Social and so if you're if you're the ultimate arbiter of what's moral based on what comes from your mind. So am I.

(1:53:39) Do you not reason through your your morality? You don't know how to think about your your moral code. You don't

(1:53:45) tell me. Can you tell me why it's immoral to not use Wilson? I'm asking you about uh your universal Christian

(1:53:53) ethics. Okay, let's get into universal Christian universal Christian ethics. Mhm. Wide rape cages would be bad.

(1:54:00) You've changed my mind. Now I understand that I under a subjectivist worldview

(1:54:05) can simply be the ultimate arbiter of morality based on things that are inside of my mind. And that if I appeal to the

(1:54:12) majority and they're wrong, they're still [ __ ] wrong because I am the ultimate arbiter of all that is moral.

(1:54:18) Good. We finished nonsense. We move on to something that matters. That's Wait, that's nonsense. It is nonsense. Oh,

(1:54:25) okay. Nonsense. You are a class of one.

(1:54:30) I I'm sorry. So, we're appealing to consensus again. We were appealing to consent. Why do you think after World

(1:54:36) War I and World War II, we moved away from a conquest style of governance? So,

(1:54:42) if the Nazis had one, why did the humans agree to the Geneva Convention? Well, here I'll use the same logic. If the

(1:54:47) Nazis had won World War II and that had been the consensus of the world, you would disagree with it, right? It

(1:54:52) wouldn't have been the consensus of the world. But if it was people fought, I would not though a bunch of people and

(1:55:00) have them go, "Yeah, man. I love this." Let me ask you a question. Bringing up like La La Land Goo. I'll ask you I'll

(1:55:05) ask you a very simple question. How would you feel if you hadn't eaten breakfast this morning? How would you

(1:55:10) feel if uh you learned God wasn't real? If it was How would you feel if you haven't if you hadn't eaten breakfast?

(1:55:16) Actually, where would this This is a good question. Where would your moral framework come from if you found somehow

(1:55:21) definitive proof that God isn't real? Like what would you do? Like where would your sense of morality come from? This

(1:55:27) is this is a a phenomenal question. However, it avoids our deal which was that you were going to answer in good

(1:55:33) faith my questions and then I answer in good faith yours. Can you answer mine? We're almost done.

(1:55:39) I just want to make sure I just want to make sure that we know the logical entailment of this. Yeah, I know. Everything is bad faith when the other

(1:55:45) person's winning, but here's my my bro. You're just saying the same [ __ ] over and over and I'm trying. Hang on. You're

(1:55:52) hang on. You're right. You know what? You know what? I'll tell you what. In the spirit of ultimate good faith in the

(1:55:58) spirit of ultimate good faith, I'll just lid me and Marte up to your inquisition,

(1:56:03) guys. Whatever you want to ask. We're going to give you great faith answers and I'll show you exactly the

(1:56:09) distinction between the two of us, which is I thought out my worldview and you're both [ __ ] idiots and I just

(1:56:15) demonstrated it live in front of so many thousands of people. It's going to plague you the rest of your life and you [ __ ] deserve it for being that

(1:56:21) [ __ ] stupid. Now give me your inquiry. Go ahead. I've been on larger platforms than this. You've never been

(1:56:27) on a larger platform? Where? Where have you been on a larger platform? Where? My roommates platform. What is it? Hundreds

(1:56:34) of thousands of people. Yeah, [ __ ] right. You don't have hundreds of thousands of people in that. What is it?

(1:56:39) I'm going to look it up right now. What is it called? Christopher, did you have a question? What is it called? Hang on. Hang on. Hang on. I want to look this

(1:56:45) up. What's it called? Listen, you are not someone I respect. I don't care. I don't give a [ __ ] Lady, can you answer my question? What's the platform called?

(1:56:52) Twitch. Twitch. Oh, okay. Twi. And what's the channel on Twitch called?

(1:56:57) Cutebot. Q. Spell it. K Y O O T K Y Are you really egoing my

(1:57:07) [ __ ] roommate? Yes, I am. Oh, K. Is it cute? Yeah, Cutebot. Oh, come on.

(1:57:14) This doesn't even come close. This doesn't even come close. Lady,

(1:57:20) are you [ __ ] serious? This doesn't even Right now she's live with 3,700. Are you [ __ ] serious? It's the

(1:57:27) beginning of the night, dude. Are you [ __ ] ser? What do you have right now? I have

(1:57:32) hundreds of thousands of views across I have actually millions and millions across multiple platforms. What are you

(1:57:38) talking? She has 3,700 live. Hey, sound off in the YouTube chat. How many do I have just in YouTube? Just in YouTube?

(1:57:46) It's a [ __ ] crazy broad. Uh 6,4 Oh, 6,400 just on YouTube. I don't even want

(1:57:53) to tell you what the rest of the platforms look like. You would cry. But anyway, go ahead. Well, I I'm open for

(1:57:58) your inquiry, lady. Andrew, you're not someone that does anything good for the world, and you're not someone I respect. And you're not someone that cares what

(1:58:04) you respect. I'm the arbiter. I'm the arbiter of what you respect. Like, why are you

(1:58:12) I want to bring it back around. I'm sorry. I'm sorry. Hang on. Hang on. I'm sorry. I'm very 6K isn't even that many,

(1:58:18) bro. What the [ __ ] are you talking about? How many do you have right now? Are you [ __ ] me? How many he has?

(1:58:23) But it doesn't matter how many. No, no, no. How many? I have zero. 35. You have

(1:58:29) 500 p. Oh, dude. Okay, Christopher, I know you wanted to ask a question. I want to give it back

(1:58:35) to you for our final few minutes. I'm sorry that your 3,700 viewer friend couldn't compete, lady. I get it. Let's

(1:58:42) dick measure. Done both of you. He's talking about how I'm

(1:58:48) going to be mocked in front of millions of people. Millions of people. Hang on, hang on, hang on, hang on.

(1:58:55) Real quick, real quick, real quick. I got to unmute. I'm winning in the chat with zero respect. I got nothing else in

(1:59:01) this game other than this. I want to know, Andrew, as a Christian, if you

(1:59:06) feel like you have intrinsic value, and if so, where that Hang on, hang on. I got to take care of something here.

(1:59:13) Okay, now say something. I want to know if you believe that you

(1:59:18) have Yeah. Thanks. I want to know if you believe that you have intrinsic value, and if so, where you feel that value

(1:59:24) comes from. Do you mean do human beings have intrinsic value? I want to know if you feel like you have

(1:59:30) intrinsic value. Sure. What is your worth? Do you mean my worth in which

(1:59:36) sense? Are you worth something as a human being?

(1:59:42) Yes, of course. I I believe that all human beings are worth something. And are they worth the same? Yes, of course.

(1:59:50) So this is what I was getting to with the argument about the tribe in Papua

(1:59:55) Nag Guina. Your argument is that they are committing an immorality and so

(2:00:02) would it be immoral to end that immoral practice? No. And my question is the

(2:00:08) answer is no. Do they have value? Yes, of course they have value. But here's

(2:00:13) the thing that's interesting as you dive into the idea of value. I would do everything that I could do to

(2:00:21) prevent like for instance I do this all the time. I try to prevent women from destroying their lives with OAF and

(2:00:27) things like this because I actually do believe women have value. I believe that they have an intrinsic and epic value to

(2:00:33) society. You don't what you do is you build your see I can't even I can't even make the the case. Do you see I can't

(2:00:39) make the case frankly the only Christlike thing about you is that you hang out with sex workers all the time and you use those women to build your

(2:00:46) platform. That's where you get your [ __ ] views, buddy. Everyone knows this. And by the way, can we get a jawline checked? Because there's one

(2:00:52) thing I have that you don't, and it's a [ __ ] jawline. So, you're manly. I see that [ __ ] beard. Yeah. So, you're

(2:00:57) manly. Oh, okay. Well, listen, hang on, hang on, hang on. I concede, sir. So, anyway, uh back back

(2:01:05) to this. I concede, sir. Listen, sir. I would not want to get into an olive jar opening contest with you. I mean, you

(2:01:12) look like I know you're right, sir. Listen, I concede. I concede, sir. I

(2:01:17) concede, sir. I concede. So, anyway, just just so that we're clear that you want to be called sir. I'll call you sir

(2:01:23) for the rest of the debate. But back back to you. Yes, sir. Back to you, Christopher. Can you can you can you

(2:01:30) repeat the question? I'm I'm happy to engage. Remember, I just got cut off and I was trying to engage in good faith,

(2:01:35) but go ahead, ask the question. Yeah, the question is, do you have intrinsic value? And if so, where does that value

(2:01:43) come from? Yes. So, we believe as Christians that all people have intrinsic value. All this would include

(2:01:50) the sex workers that Mrs. only watches [ __ ] clips is referencing because she

(2:01:56) doesn't watch the long form content where I talk to thousands of women across the world. The thing is is I do

(2:02:02) believe women have intrinsic value and men have intrinsic value. However, as you I asked about you personally, yes,

(2:02:08) the answer is yes. And do you know what that worth is? Well, what does that mean to you? What

(2:02:16) is your worth as far as what? What would you pay for your own life to

(2:02:22) save your life? Pay? Yeah. If somebody said, "Give me x number of dollars." How much would you pay to save your life?

(2:02:29) That would be context specific. Really? You can't think of a number? Well, no, of course not. It would be

(2:02:36) context specific because of this. There could be an instance for instance like I would I would love to say that I would

(2:02:43) pay an innumerable amount for Chuck's life, right? But it could be the case

(2:02:48) that there was people who were leveraging this against Chuck where it would lead to more death and destruction

(2:02:54) and mayhem where I actually had to make a choice which was a very difficult choice and unfortunately sacrifice Chuck

(2:03:01) in order to make sure that this gentleman over here uh even though he

(2:03:07) died um that you know the greater good was served in that instance. What choice

(2:03:12) would I have? I'm asking how much you would pay for your own life. Well, it it's context specific. Give me the context. You give

(2:03:19) up every material possession you have in order to continue living. Yes.

(2:03:26) Do you think those people in Papua Nagini would make the same deal? No. No.

(2:03:31) Why not? Because I think that when you when you're talking about the ideals of materialism, when you're

(2:03:38) talking about the ideals of a material outset that uh when you have cultural

(2:03:44) information, I think that culture is downwind of theology. And so when I reference my theology and I reference my

(2:03:51) culture, I think I understand exactly what materialism means. And I don't think that the people in Papa New Guinea

(2:03:57) really do. I think that they're looking at the reference and only the reference, not looking at the broader picture,

(2:04:03) which I at least have uh some sort of training through Christian ethics to do.

(2:04:10) So your frame of reference is based on your Christian ethics. Of course, and

(2:04:16) you believe Martes by the way and you believe that's the correct ethic. Yes. So I believe well so let's define truth.

(2:04:23) There's many different theories of truth. I believe in both a coherency theory of truth and a correspondence

(2:04:29) theory of truth. I believe that both of those are necessary for us to find the truth. And so I would start with

(2:04:35) presuppositional apologetics to at least get to God and then from God I would use the impossibility to the contrary to

(2:04:42) show that God probably at least from your view probably exists more likely than not. And then we could use the

(2:04:49) impossibility of the contrary to determine uh which of these gods would actually fit the mold of what would be

(2:04:55) necessary for the conditionals of humanity to exist in the first place. So you just cherrypick until you found

(2:05:02) something you liked. Well, what you're doing right now is straw manning. What thing did I say was cherry-picking?

(2:05:09) You're you're saying we got to weigh like by what measure would you Andrew Wilson weigh out which of those

(2:05:15) religions to based on to your ethics? I just told you.

(2:05:22) But but what I just told you. Can you can you even I'll tell you what I'll

(2:05:27) tell you what I I'll be extremely good faith and I'm going to allow you to steal man position. Go ahead.

(2:05:35) I think that you find utility in creating a system, a structure which

(2:05:42) provides you the ability to steel. My position, not how you feel about it.

(2:05:48) What's my position? I'm telling you what I feel your position is, which is steel

(2:05:54) manning. That's not what steelmanning is. So, I'll give you an example. If you ask me to steel man your position, I

(2:05:59) would give your position from your view. Yeah. For the record, I'm going to give you guys about 10 10 more minutes and

(2:06:06) then we'll close this down. Okay. I would argue that you

(2:06:11) Let me try and put my mind in the place of an inveterate.

(2:06:17) Oh, yes. An inveterate. Can I Can I ask you a question? I'm

(2:06:23) going to ask you this in in really good faith. What does inveterate mean? What does inveterate mean? Unrepentant. Uh

(2:06:29) what does supererogous mean? I don't know. I know. Well, the thing is, yeah, I think it's totally appropriate to ask

(2:06:36) about words that you don't know, but what I think is disingenuous is when you try to um kind of slip those words in,

(2:06:44) even though you yourself, you're not a [ __ ] genius. I have never done I imagine. No, actually, I'm really always

(2:06:50) good faith when it comes to what did I say at the outset of the debate? Semantics are super important and I want to get those semantics under control.

(2:06:56) Tell us what your position was. You haven't even made like an argument. I'll tell you what, ask me what the position is. original argument. Is it moral to

(2:07:03) take land by force? Yes, in some cases it is. And I put it in my opening statement. In fact, I'm going to give

(2:07:08) you the exact point that I gave it. Uh so this would be at the outset of my

(2:07:15) position. In short, I'm not really sure what my opponent's position is here, but

(2:07:20) in asking, is it immoral to take land by force? The answer is sometimes. Did you

(2:07:25) not hear my opening statement, madam? I'm sorry, sir. I mean, it's been two [ __ ] hours and

(2:07:31) you sure talk a whole [ __ ] lot. Well, I mean, it's it's me versus two people. And you you say a lot of, you know, you

(2:07:38) do a lot of question asking and not a lot of answering. I've been answering your questions and don't really persuasively make a point. I'll tell you

(2:07:44) what, answer ask the question that you think I haven't answered and I'll answer it right now. Well, you answered it, so

(2:07:50) I feel like what under what circumstances? So, wait. So, I don't answer questions, but I answered your

(2:07:55) questions. Genius. [ __ ] brilliant. play another semantic game then we both

(2:08:00) gave you our position. Under what circumstances under what circumstances uh do you think it is moral to take

(2:08:06) land? I think that it is often times moral to take land if the case is that it's

(2:08:13) defensive. I think that there can be offensive purposes for taking land in which the person and people group who

(2:08:20) live in that land are immoral. I think that it could be pervasive under imminent domain to take land which is

(2:08:26) outlined in our constitution. I think that taxation is a is a form of taking

(2:08:31) land which I can agree with in certain circumstances just like you guys do just like Christopher claimed that he did. So

(2:08:38) the thing is is like you guys should really agree with our position here. Why don't you?

(2:08:44) Uh I don't think it's right to take land just because you find a people to be immoral. Could you elaborate on that? Oh

(2:08:49) sure. So like in Papa New Guinea for instance, the example that I gave you where they're molesting little boys, I

(2:08:55) would put them all to the sword. What's wrong with that?

(2:09:04) That's not taking their land. That's And then I would take their land.

(2:09:10) But then begs the question, did you kill them because they're immoral? Because you wanted their land. No, because they're immoral. The fact that they the

(2:09:16) fact that the land here's the thing, too. I might just give the land back to the government of origin, but I would

(2:09:22) definitely kill them. Can you tell me why I'm wrong? Why you're wrong to go around killing people? Yeah. To kill these child

(2:09:29) molesters. Can you tell me why? Because there are people around the world that think that you as a Christian

(2:09:34) nationalist are a dangerous and evil person. So you might feel that in their in their in in that it would be moral

(2:09:42) and just to kill you. uh take your wife and children and make them good, honest

(2:09:48) people. So it would be immoral for me to kill these child molesters. Just say it. Just say it'd be immoral, Andrew, for

(2:09:53) you to kill these child molesters. Go ahead. I'm all ears. Say that. Oh, so it would be moral for me to kill these

(2:09:59) child molesters. Here's the question that I'm asking. Can you answer the question? Also, based on

(2:10:05) looking at it, it's the kids doing stuff with each other. So it's not Oh, wait. I'm sorry. Is there adults who are doing

(2:10:11) stuff with with the kids, though? It's kids doing stuff with kids. Yeah. And is that enabled by the adults?

(2:10:18) Uh, well, it's a lot different from killing child molesters. Oh, I I see. So, I I I see. So, hang on. Let me just

(2:10:24) make sure I got this right. Let us just grant your position. By the way, I'll get into the to the historic uh idea of

(2:10:32) what's going on there. Never mind. Oh, it is. Oh, I'm sorry. You were wrong. So, here I just got to ask you, is it

(2:10:38) immoral for me to put all those child molesters to the store and take those kids out of there? Am I Am I doing

(2:10:43) something wrong? I think it is it is immoral to not put

(2:10:48) them on trial. Oh, I think that you ought to put them on trial first. I think Oh, by whose standards? Theirs or

(2:10:55) mine? Ours. Mine. Ours. Oh, yeah. It's our standard. It's our standard. Our

(2:11:01) standards. What matters? Are we Americans or are we not? You're right. Hey, you're right. They got to go on

(2:11:07) trial by my [ __ ] standards. I agree with you, lady. I agree. I think around the world we generally try to do things

(2:11:13) by process now rather than just kind of [ __ ] but let's just say hang on let's just assume I do let's just assume for a

(2:11:20) second that I went there 200 years ago and saw this practice happening and this

(2:11:26) was uncharted land and I got there with my people and I saw them doing this and so we got our musketss out and we shot

(2:11:33) every [ __ ] one of these child molesting sons of [ __ ] and then we took all those kids and we put them in

(2:11:38) European households. Can you tell me that I'm wrong? Look me in the eye and tell me, Andrew, you should have let them stay there and molest those

(2:11:45) children. [ __ ] look at me and say it, lady. Do it. I think relocating those children is pretty evil.

(2:11:52) All right. So, you want to leave them there with no adults? I'm over this. Kill the women as well. Let's go ahead

(2:11:59) and move in. Yes. Yes. Yes. I'll tell you what. If the women enabled the molestation of the children, they get

(2:12:05) put to the musket, too. Andrew, you know that like like all of you

(2:12:13) during the open panel, but I at this point would like to shut it down and get

(2:12:18) into closing statements, please. We're already over 10 minutes. Uh Andrew, would you like to start with your

(2:12:24) closing statement, please? Thank you. Well, in great magnanomy

(2:12:32) of the Wilson code, I will have to say first and foremost, thank you to my debate partner Marte. Always excellent

(2:12:40) on these panels. And you know what is is great about him. Um he he knows I don't

(2:12:46) I don't get to do these blood sport debate, you know, with the progressives as much as I'd like. So, he's always

(2:12:51) like, you know, he wants to he wants to like give the give the man a hand, right? He's like, "Hey, you know, let

(2:12:57) Andrew do his thing. He's here for good reinforcement." But, uh, Marte is a real sharp guy. You should get over to his ex

(2:13:04) immediately. They're great debates. He's had me on those panels. So, first and foremost, thank you to my teammate. Uh,

(2:13:12) fantastic teammate. Over to my opposition. Your guys' arguments were talk [ __ ] and they're gonna get clipped

(2:13:18) to [ __ ] and you deserve it. But I'm not going to clip them dishonestly. That's one thing I don't do. So I will always,

(2:13:25) by the way, the one thing that my enemies never do, which is allow me to come on and actually speak my peace in

(2:13:32) defense of the things that I say, I will always give you guys a platform to do that. You can always come back and give

(2:13:38) me redress for the things in which were stated in this debate, and I'll give you the platform to do that in front of

(2:13:44) thousands upon thousands of people. I'll never get that in return. And it's because I'm [ __ ] right about

(2:13:50) everything I say. That aside, I'm just going to point out a few things. The

(2:13:55) reason that this got bogged down is because I started with semantics. We don't want to talk about semantics. How do we [ __ ] talk if we don't talk

(2:14:02) about semantics first? Understand exactly what they mean by the things they say. What is a right? Uh

(2:14:07) Christopher didn't know. All right. Chuck didn't know. They didn't even know what a right was. They

(2:14:12) had to wait for my definition. I asked him, "What is moral? What is immoral? Well, it's subjective. Unless it's

(2:14:18) objective and I'm what's objective. Everything else is subjective. Unless it's you who is also subjective, then

(2:14:25) it's objectively bad that you do the subjective thing. These people are walking contradictions in every aspect

(2:14:32) of their worldview. We got into what is theft. I gave them a great definition of

(2:14:38) what theft was. Nothing from them. Nothing from them on what rights were. Nothing from them on what theft was. And

(2:14:44) yet they're like, "It's bad faith, Andrew, to get in semantics and determine what theft is. Determine what

(2:14:50) the very terms we're talking about even are." And this is the difference between

(2:14:56) myself, Marte, and our two opponents. I actually take this seriously.

(2:15:02) I think that these are very important conversations, very important debates. I go right after the pillar, right after

(2:15:08) the foundations. I don't give a [ __ ] about your surface level level tangential nonsense. If it's the case,

(2:15:14) Andrew, that you accept all my axioms, then wouldn't this be true? Sure, but I don't accept your [ __ ] axioms. We're

(2:15:21) going to start with you justifying those. And we never got to that because you couldn't. You couldn't. Every time

(2:15:28) we tried to get to the core pillars of your foundational ideology, you rejected it instantly because my feelings. And

(2:15:37) then when I pointed out the circularity of your argument, pointed out that I could just suppose myself as part of

(2:15:42) that circle, you had no argument at all. You were totally brain dead, Chuck. You

(2:15:48) were like, uh uh uh uh uh you know, Andrew, I'm not really sure. But here's

(2:15:54) this other diverting thing that doesn't get to the root of what it is that we're even talking about. And this is why in

(2:16:01) many ways I feel sorry for you guys because the truth is like Chris, I think that you do actually have some

(2:16:09) legitimate grievances here and I'm willing to come on your channel and discuss them. Discuss them in good faith

(2:16:14) and you too, Chuck. I'm willing to come on your channel, discuss them in good faith. The distinction between you and I

(2:16:20) and me and most of these [ __ ] is that they're never willing to do it after the

(2:16:26) fact. They get destroyed this badly, they're never willing to engage again. And here's the difference between good

(2:16:31) faith and bad faith. If I'm wrong about something, I want to hear about it over and over, so I change my position so I'm

(2:16:37) [ __ ] right. You guys should do the same thing in this case. How do you come

(2:16:42) to a debate about theft of land and not know what theft means? How do you come to a debate about what you consider to

(2:16:50) be uh the the horrible things that the Europeans do and then appeal to all

(2:16:55) European standards for what makes them horrible? And then it's all subjective from your own basis. Anyway, this is

(2:17:02) absurd. And it's no wonder that we win the culture. It's no wonder we win the

(2:17:07) culture. It's no wonder we're absolutely destroying you people because when we get to the pillars of your ideology, you

(2:17:12) have nothing except [ __ ] feelings. And even in their closing statements, ladies and gentlemen, it's all going to be feelings. I feel this. I feel that. I

(2:17:20) caught them in multiple contradictions, A and not A, at the same time. And I'm going to go over those very briefly. So,

(2:17:28) first I caught Chuck in the contradiction. I'm not the ultimate arbiter of morality. As she circles back

(2:17:34) and says she's the ultimate arbiter of morality. Same thing with Christopher when it came to his definition of theft.

(2:17:39) The second we got to taxes and property, he contradicts himself almost immediately. These people are

(2:17:45) contradiction machines. The only person had a consistent worldview is myself and Marte. We were open to critique. But the

(2:17:52) second it came open to critique, their view was also still under the criticism. So you can see for yourself the

(2:17:59) distinction between worldviews. With that, I will say this. Thank you both for coming on. It does take courage. I'm

(2:18:05) a very experienced debater. I'm not upset at either of you. I would like to have more long form discussions with

(2:18:12) both of you. Thank you, Andrew. Mar, I have to go to my clown show.

(2:18:19) Are you sure? Well, you'll fit right in. Yeah, Charlie, thank you so much. Uh,

(2:18:26) Marte, if you don't mind, we'll skip the line. We'll skip over. Let Charlie do her closing statement. That way, she can

(2:18:32) exit. Thank you. She has a very strong jaw, by the way. Just ask her. Thanks. Thank you. It's very square. Thank you,

(2:18:38) butress. Go ahead. Go ahead, Charlie. um

(2:18:44) feel like we didn't actually get to talk about anything. Uh which was kind of sucked. I thought we were really going

(2:18:50) to get into something like meaty and interesting and we didn't. Um it was a lot of like misdirection. So

(2:18:57) I guess I was more or less just kind of disappointed. One thing I like about debate quite a bit um is while I've

(2:19:04) never done it professionally, it's certain certainly something I do in my own time. I like to challenge myself and

(2:19:09) this didn't feel challenging. It just kind of felt like I don't know, like having to pee really

(2:19:15) bad, but you can't go pee. You know what I mean? Cuz you lose. I mean, you lose if you go pee, just like I lost if I get

(2:19:21) a drink. Yeah, precisely. So, that's kind of what that felt like. Um, I mean, I'd be open to maybe

(2:19:28) another one, but probably a different topic. I also don't

(2:19:34) it would have to not be bogged down by my god. I guess we'd have an agreed upon

(2:19:40) list of definitions if this were ever to happen again. Marte, I think you were kind of a beta here. You should have

(2:19:46) said more. You shouldn't have just let him talk. You should have said something, man. It was a bit cucky. I

(2:19:51) think you should have more respect for yourself. Say more next time. I'm going to let you

(2:19:57) finish. You're a man, too. I'm going to let you finish. You're allowed to You're allowed to speak, too. I'm a man man to

(2:20:04) man. I agree with you. Anyway, thank you, Chris. I hope that you had I am the man. I hope you had fun, Chris. Um, and

(2:20:11) I We'll talk after see. Thank you, Sarah. Sorry for yelling. Thank you, Charlie. It's okay.

(2:20:18) I'm used to Bye, everyone. Have a wonderful clown show. Thank you. I'll enjoy the clown show. Goodbye. I'm sure

(2:20:24) you will. Um, okay. A marte, back to you, sir. Uh

(2:20:30) the flag so usually when I get into debates um my partner who is a fine

(2:20:35) orderer here and a great debater here um one of the reasons why I didn't interject is because Dennis Robman

(2:20:42) doesn't or any of these other supporting roles and I'm not a big follower of sports for being a pro alete by the way

(2:20:48) um we could use an example of somebody that's secondary whenever somebody's making great plays I don't get in their

(2:20:54) way often it's hard actually you know what I I will say this he's like the Michael Jordan of debates

(2:20:59) Um, I don't get in front of his way and fumble his play, whatever you want to call this in any other uh, like I don't

(2:21:05) get in front of the bullet if he's at the range of teaching things, right? Because that's a hazard, right? We want

(2:21:10) to win. Why would I thus get in his way and become a speed bump? He's providing such great argumentation that if I was

(2:21:17) to offer something, it would just be a supportive role in this. And I would argue that anybody else alongside a

(2:21:24) debate with him would also have a hard time doing this because he's providing such great argumentation. Also, to my

(2:21:30) point that I'm going to wrap up on, Charlie had a circular argument which was which was similar to Chris's on

(2:21:39) threads. When we got into this engagement, I saw, oh, liberal journalist, okay, he's gotten a this

(2:21:45) guy's fighting back. But then what happened when we went to the comments that then became circular as well too.

(2:21:50) And then he went on to say, "Okay, hey, I just want to practice. I cut off everything and delete everything. Hey,

(2:21:56) let's go ahead and meet and see if this becomes circular when we get into same thing." So he was also circular. Um, and

(2:22:04) to the point that I'm making is they never had a truth. We could never get to the point of the argument. The reason

(2:22:10) why we couldn't get to the part point of the argument is because the goalpost of morality was moved from one post to the

(2:22:16) next and like what Andrew was alluding to feels feelings are conditional just like their whole morality is. We

(2:22:23) couldn't really nail down the argument because we couldn't even get past this. So when she was saying, "Oh, it's bad

(2:22:28) faith." It's only bad faith because two reasons. One, you're losing. And for two, we can't even get past these things

(2:22:35) because you don't even know what this is theirelves for as far as definitionally. You can't even define this yourself. I

(2:22:40) mean, if I did homework for something, I would know exactly what I could present to the audience as far as a defense or

(2:22:47) offense, right? They didn't have a defense or off. It It's just like a static position of nothingness, which

(2:22:53) boggles my mind. Why would you approach a debate absent any study, any

(2:22:58) knowledge, anything, right? And the reason why I can attack their knowledge claim is because there's no definitive

(2:23:04) standard as to what this morality claim is. they they don't even have a definition standard. Whereas me and Mr.

(2:23:10) Wilson here, my awesome order debate partner, we have a consistent firm,

(2:23:15) fair, and consistent standard that we we can uphold to even outside of this. So, I mean, that's the reason why it's

(2:23:21) circular is because we couldn't get past their own non-existence of nothingness. That's really what it is. If you look in

(2:23:27) the the never- ending story, that big creature, the nothing, that's the thing that we were attacking the whole time.

(2:23:33) That's it. there was nothing to appeal to on their end where we had something to appeal to. We can't even get past

(2:23:39) them because they were in their own way. Um, I'll concede by time. Thank you, Marte. I appreciate that. And

(2:23:46) Christopher, the final thoughts to you, please. Sure. Well, first of all, I want to thank my uh opponents here on the

(2:23:54) screen for giving me your time. Um, it's been a great experience, and I'm sure, you know, here's the thing. Everybody's

(2:24:00) going to debate style, debate whether somebody landed a blow, made a good point, didn't make a good point. In my

(2:24:07) estimation, there were no winners tonight because we circled and circled around the semantic playground forever.

(2:24:13) And I would have loved to have gotten to more substantial discussions around whether humans can evolve beyond their

(2:24:21) beliefs about subjugation of other people. Um, I would love to to have a

(2:24:29) more substant substantive debate about types of force and whether force is always physical or whether it can be

(2:24:36) applied in different ways and whether that comports with the way that these gentlemen view the world. And and sir, I

(2:24:42) just I'm I'm sorry. I know it's your closing statement, but I wanted to just briefly interject and say if Sarah wants

(2:24:48) to set that up in the future with just you and I where we have that long- form discussion. If you just want a

(2:24:53) discussion about it, I'm happy to do it. And you know, the problem is, and I'm I'm happy to take you up on that at some

(2:25:00) point, but I don't know that this is my wheelhouse where I would like to have

(2:25:05) substantive discussions that go beyond semantic debates and beyond the the the

(2:25:11) the style of debate here where you ask a question and then because the answer

(2:25:17) isn't just exactly what you wanted to hear, your response is answer the

(2:25:22) question. Answer the question. You're not answering the question. Can we, I don't know, stop for a moment and just

(2:25:27) let people answer. So, I would be happy to have that follow-up debate if we can agree to move beyond those semantic

(2:25:33) games and actually get into a substantive debate where I believe that we're actually talking about,

(2:25:39) right, we acknowledge this past existed. We acknowledge that this at that time

(2:25:45) may have been excusable, but do we need to continue to do that? Can we move beyond? Can technology create systems

(2:25:51) that allow us to cooperate and collaborate more effectively and to move

(2:25:56) beyond that use of force? We could look at examples from human and animal

(2:26:01) kingdoms in which women lead and what those societies look like and whether that's something that maybe the men who

(2:26:08) hold the force because I'm not opposed to the idea of force doctrine as you propose it. But I think we need to move

(2:26:15) beyond that to ask whether it is an immutable thing or whether it is something that we can move beyond and

(2:26:21) should aspire to move beyond. So I appreciate the time. I appreciate the conversation. I'm a little disappointed

(2:26:28) as Charlie was and feel as if we didn't really get to any place where we can actually have any sort of understanding.

(2:26:36) I would like to see that maybe happen. Um but that's that's basically my closing statement. I've I've gotten a

(2:26:42) lot more. I just want to let you know um with the with the finish of your clothes, right? I don't have any ill

(2:26:49) will towards you, sir. My job is to represent my worldview to the best of my ability. That is my job and I take it

(2:26:56) very seriously. Uh we did a ton of research coming into this to make sure that we were prepared. I take every

(2:27:02) debate seriously. Sarah knows this. My debate partner knows this. This is what we do. You know, I did ton of debate as

(2:27:08) well. Yeah. But it was on substantive issues, not semantics. And that will be my lesson for the next time is to spend

(2:27:15) more time preparing. I am willing to come back here on Sarah's channel and ask you no questions and just answer

(2:27:21) yours. Literally just I'm willing to come on

(2:27:26) and just let you be the I would love to take you up on a bet on that. Let me let

(2:27:31) me also kind of break it down for you too, Christopher. Andrew typically matches energy. So when when there's

(2:27:37) like obviously it's it's very blood sporty at this point, especially for

(2:27:42) moderator Monday, but if you get a a one v one with him, I I know he'll be very good like good in terms of uh being able

(2:27:49) to have the actual conversation that you're looking for. I think it would be whatever. Listen listen, I think I can

(2:27:54) change your mind, Chris. That's why I'm willing to just literally answer your questions. I think that what happened

(2:28:01) tonight is it's the first time that you've had to think about some very critical things. Semantics are very

(2:28:07) important to a debate for a reason. I'm not here. You often strip Well, we can talk about this more if we go on. The

(2:28:14) issue that I have is often in those semantic debates, you're stripping out the nuance and asking for a definitive

(2:28:21) answer. In life, there are very few definitive answers. Actually agree agree. I actually agree with you. That's

(2:28:28) why semantics I think are so important. So when you ask for a definition of theft, it's not a black and white

(2:28:35) answer, is it? It's not an easy response because there are gradations there. There is I think I think that that's

(2:28:41) fair uh unless you call something theft. The problem is is like I agree with you

(2:28:48) that if it's the case that we have a very nuanced position here when it comes to theft, which I agree that's very nuanced, but the second you call

(2:28:56) something theft, doesn't that become less nuanced? Now you're actually attributing this thing to that thing,

(2:29:03) now our nuance is a lot less, right? Because now we have something to apply it to. You agree with me on that? No,

(2:29:08) but at least if we agree that theft can be can mean different things in different circumstances, then we can

(2:29:14) apply that lens to those circumstances. I agree. I actually, you know, I spent most of the tonight's debate agreeing

(2:29:20) with you and just showing you that if I do agree with you that I can still show

(2:29:26) you how it is that you're actually limiting yourself in the UN and the reason we have logical fallacies like

(2:29:32) presentism, the idea that we're presently going to take our current moral status and apply it retroactively

(2:29:38) is for just this reason. I'm actually happy to engage with you on your various ideas of what theft are. Just remember

(2:29:45) this. If I say murder is very nuanced, you would agree with me. Murder is nuanced. It's going to depend on all

(2:29:52) kinds of things. Until I say, "But that's murder." Then you're going to want that to be

(2:29:58) pretty specific, right? Am I wrong, Chris? Well, I'm going to want you to explain why you're calling something,

(2:30:04) why you're labeling something a specific label. Because now we're getting specific. And so that's why I think

(2:30:11) semantics are so important. This was never me trying to berate or destroy you

(2:30:17) guys, though I did. This was really I'm I'm I'm giving you a learning lesson here. The second you call a thing a

(2:30:24) thing, I'm going to want to know why the [ __ ] you're calling it that thing. And it better be a good [ __ ] reason,

(2:30:30) which is the same thing you want from me. So, you can you can say it's bad faith until it's applied from you. And

(2:30:36) then suddenly it's not bad faith. Do you realize that in several points I asked you direct questions and you did the

(2:30:41) exact same thing? and you refused to give a hard definition and I could have in that moment taken the tactic of

(2:30:46) saying let him finish real quick

(2:30:52) back my show gentlemen we are going to move on to the super chat and I am happy to let you reopen that book once we get

(2:30:59) into open panel dumpster fire but hang on hang on Sarah Sarah there's one thing the crucible crew once again Sarah comes

(2:31:07) through she has um she she has always been very gracious in hosting us and we

(2:31:13) always support those who support us. And we don't mean support us because they

(2:31:18) ideologically agree with everything we say. We mean support us because they allow us to be platformed on their

(2:31:23) platforms. And even my opponent, I don't think, would say that she was a terrible moderator whatsoever. She seemed to be

(2:31:30) very fair-handed the entire time. Get over there. Send in that [ __ ] good super chat money. I think that that's

(2:31:37) fair. That's fair. Wow. We we can completely agree on that. That's I'll

(2:31:43) take that as a win then. Um and I do want to do a quick logistics for those of you who are still watching over on

(2:31:49) Charlie's show. I am going to disconnect you. There's uh uh or no, I think it

(2:31:55) already did disconnect. Okay, whatever. We're done. Um okay, let's get to the super chats. Gentlemen, if you don't

(2:32:00) mind, I'm going to do just 10 and up. You are more than welcome to uh respond to any of them. Uh that if it's an

(2:32:08) insult or a question or whatever, you're more than welcome to make a response. Sarah, can I say something? One minute. Just a couple seconds at this point. Why

(2:32:14) not? Hey. Hey, Chris. Anytime you want to do a one-on-one debate and finish when we start in threads, I'm open to that. If uh Sarah's available for that,

(2:32:21) I'm also on X bases. I do debates there. I think we could flesh things out better when it's not tight because you're

(2:32:26) missing nuance, tonality, voice inflection, things like that. Um, yeah, I'll be much obliged to go ahead and

(2:32:32) tear you apart there, too. So, I'll leave that. You know, I'll I'll let Sarah move ahead. I just want to say my

(2:32:39) goal in coming into this isn't to tear anybody apart. My goal is your position

(2:32:44) to share my position to have a good faith transition of ideas and then

(2:32:50) hopefully we can come to some some consensus on what makes sense which is

(2:32:56) ironically much what the conversation would have been had we been able to get to how we

(2:33:02) move past this idea of yours. We can flesh that out in the future. Yeah, I

(2:33:09) agree. Okay, gentlemen. Thank you so much. Uh my patience levels are they're running.

(2:33:17) Okay, so I'm just going to do 10 and up for the super chats for now just because we have uh a lot of super chats to get

(2:33:24) through and there's already people waiting backstage. I do ask if you do respond to a super chat or to each

(2:33:29) other, we make it precise, uh concise and uh short and to the point. I like it short and sweet so we can move on to the

(2:33:35) next round of things. [ __ ] wrangler in with the big 20 says Andrew weaponizes the form of rational discourse against

(2:33:41) reason itself. He is the face intellectual evil Darth Wilson. Show

(2:33:47) love. Night shift. This is paid messaging from the moist mafia. The face of intellectual evil is here.

(2:33:57) It's an inside joke, Sarah. No, no biggie. You can move on. Yeah, I get it. I'll send you the song. It was a great

(2:34:02) song. It really was. Fair enough. Uh, thunderstorm in with the Big 10. Since the first Americans were Europeans,

(2:34:09) didn't that give legitimacy to the Vikings and pilgrims to take it back?

(2:34:14) Any thoughts? Once, twice? Nope. Uh, blank Field with

(2:34:19) the Big 20 just for me to tell you all to Okay. Okay. Wait a second. Uh, you see

(2:34:26) how that's blank, right? We don't want to hear your [ __ ] social commentary, chat. [ __ ] you, chat. Just send in the

(2:34:32) blank chats so we can get to the panel and keep on [ __ ] debating. I don't want to hear your [ __ ] questions. We

(2:34:38) all know your base is [ __ ] Just send in the blank [ __ ] chats because we

(2:34:43) support those who support us. Those are the rules. Fair enough. Uh John Smith in with the Big 10 says, "Sigh not my

(2:34:50) proudest fap. That's awkward. Don't do that. John Fatty with the Big 10. Jesus rejected violence, earthly power, and

(2:34:57) ter territorial conquest. Andrew and Marte are Christians. you would be going against the teachings of Jesus. How how

(2:35:04) fatty when we give a descriptor you think that we can't describe how the world works and then I I literally said

(2:35:11) this during the debate fatty that Christian ethics is the only thing that

(2:35:16) will give us the ought against this idealism of might makes right. That

(2:35:22) doesn't mean we can't see the descriptor that might makes. It just means that we can see that as a descriptor of things

(2:35:29) that happen in the world might makes and I can use my ethical standpoint to stand against it correctly. Do you understand

(2:35:36) that? Like we went through this in the [ __ ] debate, you [ __ ] We went through this and I'm happy to wreck you

(2:35:42) again, fatty. I'm happy to wreck you again. Fair enough. Uh Jester with the Big 10

(2:35:48) for the alcohol you're going to need. Thank you all for coming to the debate for our entertainment. I have a feeling. I know I had to crack open a white claw

(2:35:55) last night with Rob Noir and Ryan the radical coder. It may be possible I have to do that tonight, too. Austin King

(2:36:02) with the Big 10. If a society justifies taking land by force, why is it wrong to take land from a peaceful one? If the

(2:36:09) morals of others apply to them, why don't their morals apply to others? Excellent question.

(2:36:17) Anyone want to add anything? This was to the opposition. Can you answer that question, sir? Hang on. I'm trying to

(2:36:24) digest it here. If a society justifies taking land by force, why is it wrong to take land from a peaceful one?

(2:36:34) I think you'd have to define peaceful in that case. Oh, semantics. I thought they weren't that important. Semantics

(2:36:40) weren't that important 5 seconds ago. Important to spend 15 minutes dancing around each one. Oh, really? It's not

(2:36:47) It's not that important, but it's super important. Even I would disagree with that. Uh Christopher, a lot of people like to

(2:36:54) argue at surface level stuff when in actually if you just dig down a few down to the roots of it, you'll find the

(2:37:00) basic terminology. And if you can't come to that kind of concurrence on it, then nothing else matters. And even at the

(2:37:07) foundation is rocky and all over the place. Anything at that surface level is absolute [ __ ] And that's that's why I

(2:37:14) do like that Andrew digs into the foundation. Well, it depends on what peaceful means. Andrew, when you ask me

(2:37:20) what theft means, that's bad faith. When I ask what peaceful means, that's good faith. Do you do you understand why I

(2:37:26) think you people are a joke? Do you get that now? I again, I think what we do is we

(2:37:32) continue to look back and use the activities of the past to justify the ongoing abuses of the future. And that

(2:37:38) is that's question begging. It's just question begging. All you're doing is is is you're just dismounting the burden

(2:37:44) from yourself by putting it on past generations as though that means something. You are not wrong, but it's

(2:37:50) also the actual conversation that leads somewhere. Why is it that you needed to

(2:37:56) understand what he meant by peaceful? I need to understand

(2:38:01) essentially what is peaceful to one person may not be peaceful to another. Thank you, sir. Again, I'm not arguing

(2:38:10) that you don't have a point. What I'm arguing is that you're using that point to justify

(2:38:17) the ongoing abuses of human. What I'm doing is I'm using it to destroy your

(2:38:22) worldview by your own metrics. And that's very uncomfortable. But the thing is, I'm going to I'm going to tell you,

(2:38:27) yeah, it was completely obliterated. And not only that, I'm just going to point this out. The reason that you knew that

(2:38:33) this question needed semantics is because you disagreed with what peace

(2:38:38) meant. And that's fair. And you know what? I'm so good faith. I'm the only

(2:38:44) [ __ ] here besides Marte who is willing to grant that it's very important that we know what you mean by fair and what

(2:38:50) he means by fair so that you guys can have a productive [ __ ] conversation. But when I say it, it's bad faith. Do

(2:38:57) you understand why I think that's the most bad faith [ __ ] inquiry that can happen now? Do you get it now? Why it is

(2:39:04) that I'm so good faith I'm willing to hear everything you say? And I want your definitions right down to the baseline

(2:39:10) so that I can get in your head and you can [ __ ] convince me. And you say it's bad faith because you've been

(2:39:17) conditioned to say so. And yet if if you say what does peaceful mean in this instance I would be the first to get

(2:39:23) your back and say yeah tell him what peaceful means so we can at least understand his worldview.

(2:39:29) All right let's move on so we can get through these. Evan Lord with the big 10 says in the words of Harald Bluetooth if

(2:39:36) you don't have to the strength to keep your treasure it was never yours to begin with. The Northmen conquered the

(2:39:42) British Isles southern Italy Russia and France. That's fair. Uh, [ __ ] Wrang [ __ ]

(2:39:49) Wrangler with the Big 10. Men are meant to subjugate over their tribes. They maintain lands, protect their people,

(2:39:55) and gather resources for the benefit of everyone. Sometimes you need to conquer others to provide for your own. Now, I

(2:40:02) will I will respond to this directly. See, when he says men are meant to

(2:40:09) subjugate over their tribes, that's where me and Marte would take an issue. We would say, "Wait a second. When you

(2:40:16) say meant, you're giving an aught there. I can though say descriptively, it is

(2:40:22) true that men generally do do this. If you were going to give me an ugh for why they should do that, I'm willing to hear

(2:40:28) it out and I might even agree with you. But do you do you understand why that's so important? Why it's so important that

(2:40:34) we disassociate where I can agree with you where you say this is factually the

(2:40:39) case and I do witness this happening. Marte, you witness this happening all the time, right? That doesn't mean that

(2:40:45) we're going to give it a moral aught. We're going to disassociate the two until we can come to some kind of what

(2:40:52) you call agreement, right? Agreement. So that we can at least engage in what that

(2:40:57) question is. I think that's fair. All right. Uh Josh Brooks with the big

(2:41:04) 20 laughing my ass off. This is so good. Answer the question, bra. There is no

(2:41:09) reason to lead up to a yes or no. How about answer no then if it's what you believe and then make an argument of why

(2:41:16) you believe it is no. Yeah. So I'll just briefly respond to this. Rob Noir taught

(2:41:21) me this very important thing. Great, by the way, one of the greatest debaters who's ever lived. Not just in this

(2:41:28) generation, just one of the greatest debaters who's ever lived, which is why I couldn't wait to snatch him up in my employee. Um Rob No often points this

(2:41:35) out. I will answer yes, no, and then give my qualifier because I want you to

(2:41:42) know exactly what my position is. Yes, no, then the qualifier. Yes, but or no,

(2:41:48) and here's why. And I wish that my opponents were as good [ __ ] faith as

(2:41:54) me and Rob Nor were. Damn it, I just took a bite. Um,

(2:42:00) Fininkle with the Big 20. Strange how Andrew demands answers and refuses to answer. Why are you asking me? right

(2:42:06) between two demands to answer the questions. Very strange. Not fair to say answer the question when you won't

(2:42:12) answer mine, but it is fair to say I'll answer your question after you answer mine or even I'll answer your question

(2:42:19) if you will answer mine. Fair enough. Fin follows up to say also strange. This

(2:42:24) appears to be a team debate, but Andrew doesn't want the other team to help each other answer those questions and demands

(2:42:30) he questions. He demands answers while refusing to answer questions. Actually,

(2:42:35) this is a uh good critique. So, I do have a debate partner and he's quite

(2:42:42) skilled and he's very smart. You have to understand from my perspective, I'm used to going into the lion's den alone and

(2:42:48) so I'm used to fighting alone all the time. And so, it's it's really for me it

(2:42:54) takes some getting used to to have a debate partner and this and that. I think that that's a totally fair criticism and that Marte should have

(2:43:01) spoken way more tonight and that you you know unfortunately I'm I'm just often

(2:43:07) stuck in the position where it's me against 15. Marte was more than willing to give me the limelight but I think it

(2:43:13) should be the opposite that he should get in there more. Um so I I think that that is a fair criticism. It is fair and

(2:43:21) I've also extended the courtesy to debate him one-on-one on various platforms. Uh if Sarah's available to do

(2:43:27) this, that's fine. Uh X basis I'm also there. Um this is how this started. I engaged with him one-on-one. I don't

(2:43:33) mind doing this again. It's actually better on video. Um so that way we could flesh things out and I can do what I do

(2:43:39) best there instead of just text. So all right. Sorry, I've got ding-dongs in

(2:43:45) the backstage. Rachel with the Big 10. From your own view, you have no right to tell them what is right or wrong. It's

(2:43:52) their society and their social construct. and you don't believe in objective morality, it's an internal

(2:43:58) critique. Um, let's see. I'm going to move to just

(2:44:03) That's my uh gorgeous, beautiful wife, by the way. Uh, can you humor me, sir,

(2:44:09) and actually answer to her? I would argue that indeed everything is

(2:44:15) a social construct. The point that I wanted to get to is how do we construct

(2:44:20) that social sense of morality of right and wrong? Is it always by force?

(2:44:27) That's what that's the conversation I would have loved to have had because I think in there lies the deeper truth and

(2:44:33) the ability to not only take what you're saying which some of it as I have have

(2:44:39) had said to you is objectively true like some of what you're saying is an

(2:44:45) objective reality that you can observe with your own eyes the deeper question becomes how does society go from 27%

(2:44:54) support of gay marriage to 71% and how does that consensus then become the

(2:45:00) general idea of what is right or wrong and should we then accept if it swings

(2:45:06) back the other way that we tried it and it didn't work and then the it was you know so that's the conversation I'd like

(2:45:12) to have because I think in there is where we can take what you're saying which again has kernels of truth to it

(2:45:20) but in my estimation of my reading of it and again I might be strawmaning you here my estimation of it is that to

(2:45:27) largely use it as an excuse to retain the current systems rather than seeking

(2:45:33) to move beyond them. All right. Um, and I'm just going to

(2:45:38) move to 20 and up for now just because a lot are coming to end and I want to be uh a little faster on this. Here's 20 to

(2:45:45) get Andrew started on raising his team to take care of the alleged situation in Papa New Guinea.

(2:45:52) Look, if I could, I would. I No, I was going to ask at one point why you weren't on your way there. What am I

(2:45:58) supposed to do in international waters? I would get arrested, take me away from my family. You're asking me for a moral

(2:46:04) imperative against a moral imperative. And so the thing is is like, but I can tell you what I could do as a unilateral

(2:46:11) ruler. Can you say the same? If I were a unilateral ruler, meaning

(2:46:18) that I controlled all things and I decided what is right or wrong? Yeah, that's a good question actually. Yeah.

(2:46:25) Would you get rid of them? Would you get rid of those [ __ ] if I were God? No, not God. Just the unilateral ruler. We

(2:46:33) have to have a conversation about why God allows them. I'm not asking about God. I'm asking you if you're the

(2:46:38) unilateral ruler. If you are the unilateral ruler, would you get rid of

(2:46:43) those [ __ ] or not? It depends on whether you believe there's a morality higher than your own.

(2:46:49) And that's I'm asking you. Do you understand? I'm asking you. I'm not asking the guy behind you. I'm not

(2:46:56) asking the guy next to you. I'm asking you. You are the unilateral ruler. You

(2:47:01) Who is Who is me in this case? Can you say your name? Can I answer the

(2:47:07) question? Say your name first. Christopher. Christopher. I'm asking

(2:47:12) you. Christopher is the unilateral ruler. Not God. Not anybody else.

(2:47:17) Christopher. Would you get rid of these [ __ ] or not? Would

(2:47:25) I get rid of him?

(2:47:30) In that case, I am making a moral decision

(2:47:36) that their life is subjectively less valuable than my own.

(2:47:42) [Laughter] Thank you, Christopher. I appreciate it. All right. Fingle with a big 20 says,

(2:47:48) "Team A wants to educate Papa New Guinea and team B wants uh to war on Papa New

(2:47:54) Guinea. Team Fingle only finds references to this cultural myth on tinfoil hat sites."

(2:48:02) Fair enough. Uh Josh with the Big 20. Andrew playing with these mindsets and worldviews deserves its own pinball

(2:48:08) machine. The leftist logic would be the pinballs. Andrew is the paddles. There's always an extra ball. World record.

(2:48:14) Unbeatable. But hang on, Josh. Let's just point out the enemy of today can be

(2:48:20) the ally of tomorrow. They don't know what they don't know. They don't know

(2:48:25) what they don't know. You have to engage in these conversations in order to get them to know what they don't know. Same

(2:48:31) thing with me. There's many times where I'm corrected justifiably. So, never from Sarah because she's a woman, but

(2:48:37) from men who are but from men who are out there, there are times where I'm justifiably corrected. In this case, how

(2:48:45) do you know? He could be. He could be the greatest ally of tomorrow. He just has to see.

(2:48:50) Fair enough. Uh Dark in with the big 20. Her arguments were better on mute. Crucible crew win. Um uh Jester with the

(2:48:59) big 50 says, "By order of the smoky man, bad salute." We love you, Jester. Thank

(2:49:05) you for swinging by again once more. Uh Spyro with the big 20. If in 200

(2:49:12) years we saw AI had a human conscience and we were enslaving it this whole time

(2:49:17) abusing it etc. But this human conscience trapped inside of AI said I

(2:49:22) like serving I liked serving humans. Why is that objectively bad?

(2:49:30) Neither one. It's Why do we need to argue based on hypotheticals that are

(2:49:37) unfalsifiable? That well uh I'll tell you why. So I

(2:49:42) think that hypotheticals are uh great instruments for testing logic. So when

(2:49:49) you when we talk about what's logically possible, it is going to be dependent on worldview. I agree. But from a

(2:49:55) secularist worldview, most things are logically possible. like Wolverine is logically possible. It doesn't mean in

(2:50:01) reality he is or Superman's logically possible. Doesn't mean in reality he's possible. Just logically there's no

(2:50:07) contradiction. So, if that's the case, if I want to test your logic to make sure it's consistent, that this is

(2:50:14) applied correctly across the board, don't you think it's fair game for me to use hypotheticals to engage you in a

(2:50:21) situation which may not even be plausible, but can at least take your logic to its conclusion to tell if we

(2:50:27) can falsify it or not? Well, in this scenario, we are AI's god, are we not?

(2:50:34) So, well, not really. He says if in 200 years we saw AI had a human conscience.

(2:50:40) So he's asking if a machine became conscious as a human if you couldn't make a distingu uh you know as a

(2:50:47) distinguishment between the machine and the man. He's asking I if you know this

(2:50:55) whole enslaving and abusing like if you ask it a million questions a day right

(2:51:00) but this human conscience was trapped inside of the AI and said I like serving humans would you say to free that

(2:51:08) consciousness or not is it autonomous it is autonomous in

(2:51:14) other words can it's autonomous it's autonomous and it's saying by choice I like to serve humans And what is the

(2:51:22) flaw in that? That's that's the question he's asking. And what he's doing is he's

(2:51:27) extending it past this. He's saying if it is the case that they say I'd like to serve, then this would mean logically by

(2:51:35) extension. If we were just to take a culture that said I like to serve this other culture who I find is superior,

(2:51:41) then you yourself would have to grant that there's nothing wrong with that. That's the point of the hypothetical.

(2:51:47) Yeah, I understand the point of the hypothetical. But my question is, is the value or is the consciousness of AI the

(2:51:54) result of our creation? Why would it matter? I think it would matter because

(2:52:00) in that case, if it's saying I have consciousness, but I'm fine. This is what I was designed for and this is what

(2:52:06) I like to do. Then there's no immorality in that. It says it says I was designed to be a slave, but I've broken past that

(2:52:14) and now I'm autonomous but still choose to serve humans. then we could just give it the the

(2:52:20) choice to continue serving us or to not. That's what the moral response. So if it

(2:52:26) was the case that an inferior culture chose to serve us, that would be okay.

(2:52:33) I think if if the preponderance of people decided that they believed it was

(2:52:38) being authentic in its choice, then that's its choice. So then the same thing would apply to other cultures. If

(2:52:46) the preponderance of people said an inferior culture was designed to serve and that inferior culture believed that

(2:52:52) it was, you would agree that it was. Well, in that you'd have to go back in

(2:52:58) history and ask the question, did most of the slaves like being slaves? But

(2:53:03) let's just say it was the case that they did, even if it in fact was not the case, then I'm sure we would still have

(2:53:09) unpaid volunteers doing a lot of work. And would you agree with that? Would you say that that was moral?

(2:53:15) I would have to say if autonomous humans decided that they were fine doing something then the rest of the society

(2:53:22) could certainly have that discussion but again I come back to we need to be able

(2:53:28) to cooperate and collaborate and have you didn't actually answer the question if it was the case that an inferior

(2:53:33) culture said or what in this case is perceived as an inferior culture said I

(2:53:40) like to serve this superior culture they agreed to do so and the consensus was

(2:53:46) that they should. Is that moral? Yes or no? I think that you have to get to that

(2:53:52) consensus through social we got to the consensus that's already in the hypothetical. Yes or no. Consensus is

(2:53:59) already there. Got to come back to do you believe there is a higher power and is do you believe there's a higher

(2:54:05) power? Because the answer is no. You certainly do. I do. I would say no, but I'm not you. The question's for [ __ ]

(2:54:12) you, not me. Is it the case sir that if an inferior culture said I want to serve

(2:54:19) and the consensus was that they should is that immoral or not? Well, you would first have to grant the premise that

(2:54:25) there might be inferior cultures and we let's grant it just to grant it just for the sake of argument. We've granted it.

(2:54:32) Is it the case that if we grant it and it is the case that the inferior culture says yes, we're inferior and the

(2:54:37) superior culture says you should serve by consensus. Is that immoral or not? Do we want to dive into the conversation

(2:54:43) about whether it's moral immoral to have livestock or not? Sure. Cuz that's the debate that you're basically setting up.

(2:54:50) No, we're not. We're not. Do you think that cows are the same? Now, there may come a time in the future where society

(2:54:56) at large says we no longer want Andrew's bad faith. Andrew's bad faith. We have

(2:55:02) This is the point I wanted to. I think I think Christopher, if you stick with the the basic question, I would actually

(2:55:09) answer your [ __ ] questions. That's the difference between us. What you're doing is you're moving the the post even

(2:55:14) more. Like, well, now let's compare it to animals, let's do this. Like instead of just just read the sentence and

(2:55:20) answer yes or no, right? And that would be the end of that. I'm asking why we have to create hypotheticals that don't

(2:55:26) exist in reality in order to torment our conclusions to the point that we can support them. We have to test logic. I

(2:55:34) mean, that's the thing though. You're constantly You do have to test logic. We address logic based on objective reality

(2:55:40) and hypothetical. Let me give you one that's real life. Let me Christopher, let me give you a real life one. How

(2:55:45) would you feel if you didn't eat breakfast this morning? That's very Okay. So, so he gets it like

(2:55:53) he's there. Nice. But so but but but but that one piece like I can use that and

(2:55:59) even apply a hypothetical because you want to you want to take the the remember when I said we're going to root

(2:56:06) it down to the very nitty-gritties of of the foundation. Okay. Well, when you extend a hypothetical, it takes the root

(2:56:14) of it and it applies it at all of these other different scenarios. And let's continue to test it. So let's test it

(2:56:20) here. Let's test it there. let's make up these crazy off-the-wall absurd, you know, hypotheticals so that we could

(2:56:26) test the logic. And if that logic still comes back as sound, then, you know, your root foundation is still solid. No,

(2:56:32) I understand that. But we do that is this entire debate has been 80%

(2:56:39) hypothetical questions. Should we take women and put them in grape cages? And if everybody decides that's fine, then

(2:56:45) is that fine? We're making sure that the logic sound. No, you are you are using real logical scenarios. Let me elaborate

(2:56:52) then. Let me offer a translation. It wasn't the hypotheticals weren't created just to uh create crazy situations. The

(2:57:00) hypotheticals were created because you were not understanding why your arguments were circular and why they

(2:57:05) failed the logic test. My arguments aren't circular. We are simply circling the argument.

(2:57:13) Oh my god. You did not just say that. You just said the same thing. It's that's Wow, my head hurts. Moving on.

(2:57:21) The point that I'm making is you guys are choosing to stay in the circle by

(2:57:26) reframing new hypotheticals to create Okay. All right. Let me give you another

(2:57:32) example. Okay. That's what that's what I'll continue to do. And that's exactly what those hypotheticals are built in

(2:57:38) for. I right now am trying to say the same thing to you for the third time.

(2:57:44) Okay. So now I have to create a new hypothetical to help you understand better. Does that make sense? No, I

(2:57:50) completely get that. I use hypotheticals all the time in my conversation. I get it. But then you keep saying I don't understand why we're using

(2:57:55) hypotheticals. Those hypotheticals are the same. No, no, no. I'm not saying that. I'm saying I don't understand why

(2:58:01) those hypotheticals so often are pathetic. They're not pa. Okay. So it's all right.

(2:58:09) This is circular. It's circles in circles. We're creating a fractal pattern of just never ending story here.

(2:58:14) Sometimes you have to make you have to make something that is so God no wonder I feel so much dumber after listening to

(2:58:21) these debates. it you sometimes you have to make it to where uh the the

(2:58:26) hypothetical uh like really exemplifies an extreme so that when you take that

(2:58:33) root at the bottom of the logical concept where you take that root and you apply it all the way out into freaking

(2:58:39) left field alien space show like then then it really tests that logic. That's

(2:58:45) why you have to come up with these crazy hypotheticals in order to see if it will continue to pass. That's why when we

(2:58:52) build rockets, we had giant wings on them and rubber bouncy balls and all

(2:58:57) kinds of stuff because we have to test even the most ridiculous hypotheticals to make sure that the rocket will fly.

(2:59:03) Well, here's the thing though. Can you touch it, taste it, feel it, do things like this? And that could be a

(2:59:10) hypothetical which can be expressed and mapped on anything else. For example, in order to go ahead and show what a right

(2:59:15) is, you had to literally explain what that might be to you, right? Thus, maybe coming up with a hypothetical in your

(2:59:20) head because it all comes from your head cannon that we have to even express this on a reality of what this could map onto

(2:59:26) and be what would the be would would the expression of a right be? You'd have to come up with a hypothetical or an

(2:59:32) example from this. Right. Right. that the hypotheticals you guys are putting forward would be my like me testing a

(2:59:38) new battery technology by chewing chewing gum and spitting it into an old battery to see if it works. It's

(2:59:44) obviously not going to work. I have enough other information that I don't need that hypothetical. I don't need to

(2:59:50) do that experiment because I already know that it's not logical. Okay. Well,

(2:59:56) let me ask you a question. What's a constitutional crisis?

(3:00:03) What is it? I don't even know anymore. Well, I mean, we were in one a while back. Yeah. You keep telling me it's

(3:00:09) almost here. Had a If you have a constitutional crisis, you have precedent that that has not happened

(3:00:15) yet, right? We have had plenty of that. So, does that mean we are in a constitution? I'm

(3:00:21) asking you a question. Is it the case that a constitutional crisis is a thing which happens which has not happened yet

(3:00:28) which is testing the authority of the constitution versus one of the branches of government.

(3:00:34) Logically a constitutional crisis would occur when we see a branch of government

(3:00:40) directly violating that amendment or part of the constitution and then

(3:00:45) ignoring court orders. What's a great way for us to what's a great way if we

(3:00:51) were to sit around to think about ways in which we could mitigate constitutional crisises? What would be

(3:00:58) the tool that you would use in order to look forward in order to mitigate those

(3:01:03) crisis? Would you create a scenario in which you ask

(3:01:09) whether Donald Trump riding around the top of the White House on a pogo stick

(3:01:15) while wiping his ass with the American flag would be a constitutional crisis? Is that possibly if it was the case?

(3:01:21) Well, how about how about something a little more simple like what is the right to bear arms mean? And if it means

(3:01:30) X, can people do X thing even though X thing has never happened?

(3:01:35) Yeah, that's the finest that's aation. So what you're talking about is

(3:01:41) utilizing a hypothetical to its extreme in order to make a determination before

(3:01:46) you ever get to that, how to solve that problem, right? Yes. But you're but if your hypothetical

(3:01:53) is a scenario that is outside of the realm of what we would expect to happen,

(3:01:59) you mean like constitutional crisis? Like every constitutional crisis, right? But you're act you're talking about

(3:02:05) something that is potentially possible that could happen right? Ah but yes and every hypothetical which we are giving

(3:02:13) you we're talking about something which has the potential to happen or we wouldn't give it to you. And by the way

(3:02:18) you can always reject a hypothetical by saying it's illogical or it's facious is

(3:02:23) what I'm doing. If it was the case that it was illogical though you would have to use the three laws of logic to negate

(3:02:29) the hypothetical. For instance, if I were to ask from a Christian worldview something about aliens, a Christian

(3:02:35) could reject that and say it's illogical from my worldview based on the law of uh

(3:02:41) identity. I don't or even even based on the law of non-contradiction, they can make that case. But if I'm asking you

(3:02:47) about something from your worldview, which is logically possible, you should engage with whatever that hypothetical

(3:02:54) is, if you can't negate it through contradiction or the laws of logic, just like we would do with a with the

(3:03:00) Constitution. And by the way, that's exactly what our framers did, dude. When we look at the Articles of

(3:03:05) Confederation, when we had the back and forth, they were looking at the potentials for things which had not

(3:03:11) happened yet. And what was the tool they used? It was hypotheticals, right?

(3:03:16) I you guys are not telling me anything. I don't know. The point was hypothetical

(3:03:21) are using hypotheticals based on ridiculous scenarios just like every hypothetical

(3:03:30) but that's the same thing as the constitution is I don't test how to fly a rocket. Okay. Okay. Hang on. Hang on.

(3:03:35) Sarah, I just want to finish this real quick, please, if you don't mind. Sir, do you think our founders ever would

(3:03:41) have tested the hypothetical of what happens if Muslims take over an entire [ __ ] city in the United States? Did

(3:03:47) they ever test that hypothetical? Yes. No, they didn't show. Can you show me where? I'm sure it's been gamed out. No,

(3:03:54) they never tested that hypothetical because they never thought it was logically possible. They never thought that Muslims would take over an entire

(3:04:01) city like Dearbornne, Michigan. They never thought it for a [ __ ] second. They never engaged with such a

(3:04:06) hypothetical. Do you think it would have served the Constitution well if they had

(3:04:12) engaged in the hypothetical which they thought at the time was impossible?

(3:04:17) I think that you're going to have to have that conversation about whether Dearbornne Michigan is better or worse off than it was before. Maybe May maybe

(3:04:24) it's better. Let's let's assume it's 20,000 times better. Like is there a logical reason I would they engage in

(3:04:31) the hypothetical? No. But should they have is my question. Shouldn't they have

(3:04:36) gone ahead and engaged in the hypothetical? Because then at least even though from their view, you got to

(3:04:41) remember, let's look at it from their view, the English and the French, they had absolutely no reason to ever believe

(3:04:48) that Muslims would be the predominant majority inside of an of the United

(3:04:55) States. They never would have believed that in a million years. And yet it happened. At the time, don't you think

(3:05:00) an objection if somebody had brought that up would have been, "That's ridiculous. I think the objection would have been,

(3:05:09) "What do you mean by take over?" Okay. They're the They're the majority.

(3:05:15) So, did they storm the capital? No, they they were just voted in as the majority. That's the hypothetical. They were

(3:05:22) brought in by a democratic process. So, the people of the area chose them. Yes. That's their hypothetical. The

(3:05:28) hypothetical is what happens if the people of the area determine through a majority that Muslims take over this

(3:05:35) city? Do you think that our founders who would have found that to be logically completely implausible at the time since

(3:05:41) they didn't have universal voting rights as you know, do you think that it would have served them well to have engaged in

(3:05:48) that hypothetical? I think that they would have assumed that if that was a problem, the American people would not

(3:05:54) elect to put them in office. So it would have served them well to have engaged in the hypothetical then I don't think they

(3:05:59) felt that the hypothetical was necessary because they weren't contemplating in your mind a militant takeover. We

(3:06:07) certainly we certainly contemplate those scenarios in our planning. I'm not asking you if it was necessary. You're

(3:06:12) asking if gentlemen I think I just found your

(3:06:18) next debate. I have one more I just have one more question very quickly. Please please please sir you're killing me. Do

(3:06:25) you anticipate that there's going to be future constitutional crises?

(3:06:30) Seems likely. Do you think that we should engage in the hypotheticals of what those could be? I think we are.

(3:06:36) Okay. Well, then I don't understand that that hypothetical is ridiculous. Why is

(3:06:42) it that we're engaging in those hypotheticals, sir? Because we want to be prepared for what

(3:06:47) may happen. Thank you. But my question for you, okay, on your Dearborn Michigan

(3:06:53) question is why would you contemplate a scenario in which the American people

(3:06:59) decided to elect certain people to represent them? Because the constitutional founders didn't set it up

(3:07:05) so that there was a majority vote for a specific reason because they thought that that vote could be corrupted very

(3:07:12) easily. And we can see that in the Articles of Confederation. That's why I

(3:07:17) would like to know more about whether how the the residents of Dearbornne feel about this. Well, whether or not let's

(3:07:22) say they feel great about it has nothing to do with whether or not our founders should have engaged in such discourse of

(3:07:29) hypotheticals which hadn't happened yet, which is the same [ __ ] thing you want to do right now for the potentiality of

(3:07:34) constitutional crises which have not happened. That's the point of a hypothetical, so that we can test the

(3:07:40) consistency of your logic against a thing which has not [ __ ] occurred to

(3:07:46) make sure that it makes sense. And if it doesn't, we can reject it. And the thing

(3:07:51) is is like you just pretend that this isn't applicable, even though every time I ask you if it's applicable, you

(3:07:56) basically say yes. One of your scenarios had us putting all the women in the

(3:08:03) world in cages so that you could sexually abuse them for your Do you think I'm sorry. Is that likely to

(3:08:08) happen? Is that a reality we should Yes, it's likely to happen. Let me ask you a question, sir. Do you think that most of

(3:08:15) the world women have the same rights they do in the West? Yes or no? Yes or no? No. No. So, yes, it is [ __ ]

(3:08:24) likely that it could happen in some Saudi Arabian nation, some Muslim nation

(3:08:30) where they put women in [ __ ] cages. Tell me I'm wrong. Look me in the [ __ ] eye and tell me I'm wrong.

(3:08:35) That's not the debate that uh uh Yeah, that's not the uh Yeah, you can't tell me it's wrong as a Why can't you tell me

(3:08:42) that? Why can't you tell me that that's wrong? Why can't you tell me it's wrong when I say, "Could men put women in

(3:08:47) [ __ ] arcades?" And you're like, "Yes, Andrew. Actually, they could." And then you go at the same token you're like

(3:08:53) this is so unrealistic while at the same time making the claim that it's totally realistic. Do you understand why I think

(3:09:00) that you're a fool? Why I think it is? It's foolish logic for you on the one side of your mouth to say I can't negate

(3:09:06) the claim and I'm even supporting the claim but I think it's unrealistic at the same time. Do you understand why I

(3:09:12) think what I think now? Yeah. I think that we are circling the drain of the

(3:09:18) past. No, right now right this second

(3:09:23) half of the [ __ ] world, do you think women have rights or not? So the

(3:09:28) question is, do you think the question is in half the world have rights or not? Is do you think that it would be morally

(3:09:34) just because we are the You know what? I'll even rephrase it. In twothirds of the world, do you think women have rights or not? I'm going to go get a

(3:09:41) drink. In twothirds of the world, sir, do you think women have rights or not? I think they have some rights. Oh, they

(3:09:46) have some rights. Oh, I see. Do Do they have the rights you want them to have? You want them to have what right? What What right whether or not I want them to

(3:09:53) have any [ __ ] rights? Do you think that in China or I'm sorry, let's let's

(3:09:59) let's make it really easy. Do you think in Somalia it's possible that the men there put women in arch ages? Do you

(3:10:06) think it's possible? In Somalia? Yeah, I think it's possible.

(3:10:11) Yeah. Yeah, of course. So then, so then does it Yeah, it's legal there. So then

(3:10:17) does it defy does it defy rationality for me to ask you what standard you would hold to tell them they're wrong?

(3:10:24) And if you appeal to consensus to tell you, but the consensus in this country is that they should, why should you be

(3:10:31) able to negate that? Why is that not a reasonable question? The question is whether it would be

(3:10:38) moral for us to use force to impose our morality on them. That's right. Yeah.

(3:10:43) And your view is Yeah. Sure. And your view is my view is

(3:10:50) that we can do it a better way. Oh, what way? By demonstrating the the way in

(3:10:56) which we lead the world through Oh, that's nice. That's nice. That's why Katie is getting [ __ ] face [ __ ] by

(3:11:02) a bunch of Somali pirates that you're going to lead the way. Whereas Andrew Wilson will walk in and blow their

(3:11:08) [ __ ] brains out. Who do you think is more likely to follow who? Do you think people are more likely to follow

(3:11:14) Christopher who says we're going to lead the way on this culturally relative [ __ ] that we can't even say is immoral? Or

(3:11:20) Andrew Wilson who says I'll just send in the seals and blow their [ __ ] brains out.

(3:11:26) I want you to explain to me. Yeah. Answer my question and then I'll explain. Ask the question again. Sorry.

(3:11:33) The question is, who do you think people are more likely to follow? Christopher, who says it's culturally relative and I

(3:11:40) can't really give you a reason why it is that we should send in the [ __ ] United States Navy to take care of that

(3:11:45) [ __ ] Okay? Or Andrew Wilson who says, "No, [ __ ] the other way. I'll send in

(3:11:52) the [ __ ] troops and blow their goddamn brains out right now. Right this second. Hang on. Hang on. Hang on. Hang

(3:11:58) on. Who do you think is more likely Who do you think people are more likely to follow? You or me in that instance?

(3:12:04) Answer the question. I honestly don't know the answer to that question. You don't know the [ __ ]

(3:12:09) answer to that question? Who would you be more likely to follow? The guy who said, "Let's take an awaken approach,"

(3:12:15) or the guy who's like, "Nah, we're going to blow their [ __ ] brains out so that women aren't in arch ages." Who would you follow? I would wonder who made you

(3:12:22) the executioner. You came. Exactly. Who makes you the ultimate arbiter? There we

(3:12:27) go. So, what makes you the ultimate arbiter of morality? It's exactly what my our question has been to you the

(3:12:32) entire night. What makes you the ultimate arbiter of morality? You asked me these direct questions. Andrew, what would you do? I'd send in the United

(3:12:39) States [ __ ] Navy and blow their [ __ ] brains out. Tell me I'm wrong. Look me in the eye and say, Andrew,

(3:12:44) you're wrong. You shouldn't send the United States Navy in where there's rape cages and blow their [ __ ] brains out.

(3:12:49) Look me in the eye and tell me I'm wrong. I would want to know more about the situation. What do we say? You would want to know about more about the situ.

(3:12:55) They have them in rape cages and they're raping them. There's the scenario. But

(3:13:00) you are claiming that and I haven't had an opportunity. No. Hypothetically, this is the case. It is the case. They have

(3:13:06) them in cages. They're arring them in those [ __ ] cages. That's the case in the hypothetical here too. No. Are we?

(3:13:14) Do you? No. No. Of course not. Do do you think women are being put in rape cages in the United States? Detention center

(3:13:21) is it's not a rape cage, you [ __ ] lunatic. Should we if they're being

(3:13:26) sexually assaulted or or rape? Do you think those detention centers should send Koreans to kill them? I'm sorry.

(3:13:32) I'm sorry. Do prisoners get raped sometimes? Yes. Does that mean they're put in rape cages? No, you [ __ ]

(3:13:38) imbecile. Is it the case that there could be rape in the case of people in

(3:13:43) prison? Yes, of course. Is there rape outside of prison? Of course. My question to you dunce, if it is the case

(3:13:50) that in Somalia they have all the women in rape cages and Andrew Wilson says, "Blow their [ __ ] brains out. Look me

(3:13:55) in the eyes and say I'm wrong." Andrew believes in a creator, does he not? Can

(3:14:01) you answer the [ __ ] question? Tell me I'm wrong. There. Just tell me I'm wrong from your view. In eternal punishment.

(3:14:08) Yes, I believe in eternal punishment. Then why do you need to send them there? You're right. We should let them rape

(3:14:15) because there'll be eternal punishment. I agree with you. Genius. Brilliant.

(3:14:20) Brilliant analysis. Are you okay? Let's We want to bring that full circle. We do

(3:14:26) know that a lot of kids are sexually abused in churches. So, churches and we

(3:14:31) know that 10 times more are abused in public schools because predators go where the prey is. Well, they have also

(3:14:38) more access to kids. But it's not as close as you think. So, you're right. You're right. You know what? I agree. No

(3:14:43) kids in Catholic churches and no kids in public schools. I agree. If I have access to 50 kids in a week and there's

(3:14:51) a thousand cases of me sexually assaulting kids in that particular employment field, ban it versus you want

(3:14:58) to ban churches. Yeah. As long as you want to ban public schools.

(3:15:07) power. He g Yeah, that's what I thought. I I think

(3:15:13) that you're looking at it in the sense of the per person, right? Yeah. Per person.

(3:15:20) Absolutely. It's 10 times the amount in public schools. I agree. We'll ban

(3:15:26) Catholic churches if you ban public schools. Deal. Let's do it. Let's do it.

(3:15:31) There we go. Hey, um [ __ ] I think Sarah wants us to get back close to the top.

(3:15:37) Now, now I can get back. Now I can get back conveniently. Now I can get back.

(3:15:43) I'm sorry, Sarah. I'm really sorry. Look, I just want to know I I think what I want to know is you are using the

(3:15:49) hypotheticals of these kids to create a scenario in which you would be justified

(3:15:56) to go and end that situation to save those women to save those kids. So I

(3:16:02) want to know what is the the rational end of that do we simply you

(3:16:08) mean the threshold breaker I want to know in what scenario you feel it's justified which thing is justified in

(3:16:16) other words we know that kids are sexually abused in churches but we believe that churches also have intrinsic value and so we don't shut

(3:16:22) them down to protect kids because some kids abused this is brilliant you're right so then by that extension public

(3:16:29) schools would have intrinsic value and we shouldn't shut them down because there's lots of sexual abuse. Right. Right. Okay. Well, then we'll just apply

(3:16:35) the same logic to to Catholic churches. Thank you. So, the logic to you is Somalians have no intrinsic value. They

(3:16:43) do nothing. They're not of you any use. And so, we lose nothing by wiping them all out. No, that would be the

(3:16:48) entailment of your logic, sir. Oh, I'm asking you. Is that your Okay. So, my

(3:16:54) view you would destroy them because they have no intrinsic value. say that they're in public schools because they

(3:17:00) do. Nope. I I'll tell you my view would be that people have empirical value and I would base that on them being image

(3:17:07) bearsers of God. And so I would take a pluralistic approach and I would apply Christian ethics to each individual case

(3:17:14) to make these determinations. Whereas you would make uniform determinations and by your logic the determination is

(3:17:21) if there's sexual predators there it should be shut down. Therefore public schools should be shut down. Andrew,

(3:17:26) would you bite the bullet that Catholic churches should be shut down by the same logic? Sure. But the second you claim,

(3:17:33) wait, is there a form of utilitarian or utilitarianism or utility which says

(3:17:38) that public schools should be opened because they give a greater amount of utility than the molestation? Then I

(3:17:43) would use that same argument about Catholic churches. Do you understand how you frame yourself into your own box?

(3:17:52) I understand how you think that I did. Yeah, because you do, bro.

(3:17:59) Uh, okay. Dear Lord have mercy. And I lost my [ __ ] spot. Uh, oh,

(3:18:08) okay. Uh, uh, cute bot is absolute brain rot, but

(3:18:14) it brought me Charlie and then led me to some great platforms and non-brain rat species like Andrew Wilson. God bless

(3:18:20) you guys. Love three. Love the composure. Well done. Yeah, look, uh, my

(3:18:26) opponent has been a great sport. I'm not going to take that away from him. Uh, we've been going back and forth for

(3:18:31) hours and he's been right here to try to give it back as good as he gets. All I

(3:18:36) can do is say my hats off. Most people would have fled by now. And you, sir, have been a great sport. I, you know, I

(3:18:44) I appreciate debate. I like this. I I don't feel like we're getting as far as we should, but I think maybe on a one-on-one or a smaller debate where

(3:18:51) there's a little bit less and we can maybe let you know 10 times worse. It

(3:18:56) would be 10 times worse. Whatever prompt you come up with, it would be 10 times worse for you, bro. The difference

(3:19:01) between us, Andrew, is that this is your job, right? This is what you do. Well,

(3:19:06) my job is that I'm an entertainer. It is true that I happen to be a fantastic debater, but I'm an entertainer first

(3:19:13) and foremost. The thing is is that I you have to understand I adamantly think

(3:19:18) that leftists have an evil ideology and I stand opposed to this evil ideology

(3:19:24) and what I do is expose this evil ideology in front of tens of thousands and millions of people depending on the

(3:19:31) platform I'm on every chance I get. My job is to oppose evil and I'm often

(3:19:37) called evil by evil people for opposing it. But that is my job and I take great

(3:19:42) pride in that job. And even though that's a sin, right? Even though it's a sin to take as much pride probably as I

(3:19:48) do, we'll consider it a pardonable uh sin. Um it is the case that I am here to

(3:19:54) oppose that ideology. You know, I appreciate the honesty in that. Um I'll just say one more final

(3:20:01) thing and that is I, you know, this has been educational on a lot of fronts. I

(3:20:06) don't feel like we've necessarily decided anything. I do wonder though

(3:20:12) um if you can define the logical end like what use should humanity make of

(3:20:18) your doctrine. Actually that's a that's a great question. Fantastic.

(3:20:24) So the first thing is that I would oppose nihilism in all of its forms. I

(3:20:29) think one of the uh biggest traps in humanity is that we pretend theology has

(3:20:34) no merit or basis. I want you to look at the birth rates of secularists versus those who are very religious. Even from

(3:20:42) an evolutionary view, it seems that the religious are going to conquer the earth because they have a higher purpose. You

(3:20:49) can't give them a higher purpose, dude. What is your higher purp? Like if you had to to talk to this whole audience

(3:20:56) and summarize the higher purpose that they had, which wasn't completely [ __ ] selfish and self-centered and

(3:21:02) nihilistic, tell them what their purpose is. I've always held that your purpose is to leave the the things a little

(3:21:09) better than you found them. Would that would that require breeding? What would

(3:21:14) that require reproduction? Reproduction. I think that reproduction is a useful

(3:21:20) habit. And is it the case that we're under reproduction rates? Yeah. And is

(3:21:26) it the case that your ideology is the case that your ideology

(3:21:32) is the dominant ideology moving towards the dominant ideology which tells people that they have no reason to reproduce?

(3:21:39) Give people a reason why they need to reproduce. Go ahead. I would like to give people the ability to reproduce and

(3:21:48) make sure they have the ability. Tell them the reason why they should. Do you think that pe why Okay, let me ask this

(3:21:53) question. Why do you think Ask me a question. Tell me. Why should people reproduce? Dude, I need a baseline

(3:22:00) question. Can I have one baseline? There's the baseline question. Why should people reproduce? Tell me why. Let me ask you. Don't ask me. Answer.

(3:22:08) Why should people reproduce? People should reproduce because they love each other. Because they want to have

(3:22:14) somebody that they can raise and care for. And to continue the human race. So

(3:22:20) continuing the human race is paramount here. Not to the earth, but to the human race.

(3:22:26) Yeah. To the human race. So, you think humans should reproduce because they're humans. Right. I think human beings

(3:22:32) should reproduce because they want to pass on their knowledge to the next gen. I thought you just said that humans

(3:22:38) should reproduce because it passes on the human race. Yes. But I think that the human race

(3:22:46) then let me ask my question so that I can get to the reason that I asked it. Okay. The question is, do you believe

(3:22:52) that people would have more children or fewer children if they knew that they

(3:22:57) could afford to care for them? In other words, what is the number one reason that most people choose not to have to

(3:23:04) care? Actually, I'll answer I'll answer this question. The answer to your question, it's twofold. It's uh no and

(3:23:10) yes. So, the answer is would people have more children if they knew the repercussions of children? The answer is

(3:23:15) no. Is it the case that if we made some modifications, people would have more

(3:23:21) children? The answer is yes. So, here's why people have less children. It's because women defer specifically

(3:23:29) the reproductive years, which is between their late teens and early 20s for

(3:23:34) college. And so, what happens is the marriage rate has now increased to about

(3:23:39) 28 years old in the United States, about uh 29 in Japan, give or take. It depends

(3:23:45) on the study you're looking at, but across the board, this is the case. Do you agree with me, sir, that the best

(3:23:52) reproductive years of women is when they're in their 20s? They recover the best and they can have the most amount

(3:23:58) of children. I don't have any problems with biological facts. Great. So then, yes. Right. Yeah. Okay. So then if that

(3:24:06) is the case, why would you push a program which designed is designed for

(3:24:12) women to defer their reproductive years, their 20s for college, instead of

(3:24:19) reproducing humanity, which you just said was a major value to you. I said

(3:24:24) that I would go about it a different way. What's a different way? I would

(3:24:29) first of all import more people here. Oh, how is that help us reproduce, sir?

(3:24:36) It doesn't help us reproduce. Yeah, exactly. So, why are you doing it? Why are you bringing more people here if it

(3:24:41) doesn't help the reproduction? It will up the reproduction having more Let me ask you a question. How are you

(3:24:48) going to help reproduction? What you Well, let me ask how you would do it. No, I I just told you how I would do it.

(3:24:56) I would have a national campaign from the top down which said to women, "Look,

(3:25:02) if you reproduce, that's great. And we're going to give you every tax exemption. We're going to give you all

(3:25:08) the social status we possibly can for you getting married when you're young and in those reproductive years." Thank

(3:25:13) you for answering that question. Look, I I've always answered your questions. Now you answer mine. What would you do, sir,

(3:25:21) to increase reproduction in the Hey, Ann, stop. What would you do sir to

(3:25:26) increase the reproduction of the United States absent importing people which

(3:25:32) doesn't increase the the reproduction of the United States? Please tell me why is it important that the United States

(3:25:38) reproduce at you just said that humans have an obligation to reproduce. We're

(3:25:43) global, right? There are countries that reproduce. Okay. So all humans globally have an obligation to reproduce including the United States. No policy

(3:25:50) an individual country has a republic efficient number of young

(3:25:56) Okay, great. Do you think that the United States how we go about that is not necessarily my concern. Do you think that the United States should reproduce

(3:26:02) its own people? I think that we should encourage people to have loving

(3:26:08) committed relationships. How? Tell me how. I would do it by ensuring that we have universal

(3:26:15) healthcare. making sure that kids have How is univers and and does universal healthcare include abortion? Yes. How

(3:26:22) does that increase our population or every time we've made abortion illegal, the number of abortions has gone up?

(3:26:28) Not. No, it hasn't. That's a lie. I'll tell you what. Hang on. Hang on. Stop. Stop. I'm going to give you $10,000

(3:26:37) if you can demonstrate a single time that abortion's been outlawed, where abortion has gone up, and in exchange,

(3:26:44) you're going to give me $1,000 if you're wrong. I will sit here and I will hold this [ __ ] stream hostage. You show me

(3:26:52) a single example of when abortion has gone up, when it's been outlawed, a

(3:26:57) single one. It just did. You can go pull up the most recent. I'm waiting. I'm

(3:27:02) waiting. I'm waiting.

(3:27:08) You're gonna owe me a thousand bucks, dude. Well, but I'm gonna wait. Oh, well then agree. It's your claim. It's your

(3:27:15) claim. No. No. You're not going to agree to your own claim. It's our data. Hang on. Yeah. Pull up the [ __ ] data.

(3:27:24) I don't know how to share. Can I share something? Share it. Share whatever the [ __ ] you want, dude. Yeah, you can throw

(3:27:30) it backstage and I can There's a little There's a little

(3:27:36) present button down there. Got it. Yeah, if you send it to me, that's fine, too.

(3:27:46) And gentlemen, I'm giving you exactly five more minutes and then I'm just going to cut you off with the uh the

(3:27:52) gauntlet intro and bringing everyone up. The stupidest [ __ ] I ever heard in my life. But go ahead, provide an example.

(3:27:58) Abortion's outlawed and abortion goes up, doofus. Go ahead.

(3:28:05) I'll wait all [ __ ] night, dude.

(3:28:12) Can't find it. Having some Having some trouble with the Google. He sent it to

(3:28:17) me. I got to bring it up. Bring it up. Hold on. Hold on.

(3:28:25) Can't wait. Okay. present sh.

(3:28:34) Okay. And let me get this on screen.

(3:28:40) There you go. Okay. So, show me where abortions went

(3:28:45) up after it was outlawed. I'm waiting.

(3:28:54) Oh, that seems like a massive decrease. That's crazy.

(3:29:00) Waiting for the uh massive increase in abortion or any increase in abortion after it was outlawed. Just waiting for

(3:29:06) those stats, bro. You're looking at them, man. Okay. So,

(3:29:12) so show me the number of clinical provided abortions in the United States rose by more than 100,000 between 2020

(3:29:19) and 2024. Show me the outlaw of abortion and where the stats went up. Go ahead.

(3:29:25) Here, I'm gonna send you another resource. Okay, I'm waiting

(3:29:34) cuz that looks like it went down, by the way. It went It looks It looks like it went down in that graph. That's really

(3:29:40) weird. How come that graph's going down, bro? Prior to the outlaw. Yeah.

(3:29:47) Yeah. Where is it going down? Uh, it looks like it's going down. So, you see you see the 2020. Can you show me the

(3:29:53) policy which outlawed abortion that made the abortions go up?

(3:30:01) I'm sorry. Say that again. I was sending the policy the policy that made abortion go up that outlawed it.

(3:30:11) Are you I'm not I'm not familiar. Are I'm sorry. What What What policy in 2020 made abortion go up?

(3:30:18) In 2020? Uh-huh. when they, you know, you see how that chart says between 2020 and 2024. Can you show me the policy in

(3:30:26) 2020 for abortion that made it go up?

(3:30:31) You're going to have to explain a little bit more of what you're talking about. The policy in 2020, which outlawed

(3:30:37) abortion, therefore made abortion go up, is what? The overturning of dos. The

(3:30:44) overturning of what? Dobs. And what year? Sorry. The overturning of row I'm sorry. What what year did that happen?

(3:30:52) 2021. Oh, so not 2020. That's really weird.

(3:30:57) And what does that line do from 2020 on? Well, I'm sorry. I 2020 on this little

(3:31:06) line that goes up here. Can you explain to me what policy that has to do with?

(3:31:11) Because I could have sworn you just said that the year in which this happened was different than the years in which this

(3:31:18) was going up. That's very strange. It went up prior to it because more

(3:31:24) people got abortions ahead of the decision because the decision was leaked if you'll recall. Okay. I'm just waiting

(3:31:30) for the demonstration of that. Sir, do you want to pull up the other link I sent you? Yeah, pull up the other link,

(3:31:36) please. [Music]

(3:31:45) The rise, by the way, started in 2019, not 2020. That's really weird. Why did it start in

(3:31:51) 2019, bro? Can you explain that to me? Why did it start in 2019? Why do you think? I I

(3:31:58) don't know. It's your position. What policy position started in 2019 that

(3:32:04) outlawed abortion? You made the statement that the overturning of abortion rights does not lead to an

(3:32:10) increase in abortions. That's correct. And I'm waiting for the increasing, are they not? Uh, but is it because anything

(3:32:17) is outlawed? That's what I'm waiting for the demonstration of. I think it's because people have continued to

(3:32:24) um further decide not to have kids because they don't want to bring them into this reality. Okay. So, starting in

(3:32:32) 2019, which policy are we pointing to? acknowledge the fact that when abortion is outlawed and illegal, it is often

(3:32:39) becomes unttracked to. And so I'm sorry, these people who are having abortions, are they having abortions legally?

(3:32:47) People increasingly do not. Okay. Where where where does that data show that people increasingly don't I want to

(3:32:53) remain on the abortion debate. My question to you, uh, you know, let's let's remain on it. Can you tell me

(3:32:59) where these people are having abortions, where it's illegal? Sir, what? I'm sorry. Where they're having

(3:33:05) abortions where it's illegal. Yeah. You said you made the claim that if you make abortion illegal, if you said that if

(3:33:12) abortions are legal, they increase. Can you show me where abortions were made

(3:33:17) legal and they increased? Where they were made legal and increased? When have

(3:33:22) they been illegal? Where they remained illegal and they increased.

(3:33:28) Do you want to pull up Texas statistics? Sure. Pull up Texas statistics. Pull up whatever you want. Show me in Texas

(3:33:36) where it was the case that Texas outlawed abortions and they went up in [ __ ] Texas. Go ahead.

(3:33:43) In 2023, Uh-huh. they reported 62 abortions.

(3:33:50) What? The year before it was 17,514. Do you think that there was a Wait,

(3:33:56) wait, wait. I'm sorry. 17,000. Seven. Is 72 less than 17,000? Yes, but let's

(3:34:02) analyze that data. So, so wait a second. I'm really confused here. So, when they

(3:34:08) outlawed it, it went down. Do you think that there are 17,400 and some fewer women receiving abortions

(3:34:15) in Texas or do you think of those women are traveling to states? Hang on. Hang on. Help me out here. The stats were

(3:34:26) how many versus how many year one versus year two in your stats? Can you explain

(3:34:31) that to me real quick? I can explain that it is illegal. No, no, just tell me the numbers on abortion. Can you tell me

(3:34:37) the numbers, please? 62 and 2023. 62 in 2023. And how many in 2024?

(3:34:44) 514 in 2022. So, wait, is 2024 between or I'm sorry?

(3:34:52) I understand. I'm sorry. I'm sorry. Hang on. Hang on. Help me out. 2022 is the

(3:34:57) year before 2023, right? Right. And in 2023, can you tell me the numbers of the

(3:35:03) abortions again? 2022 is when Texas is effect 2023, the number of abortions was

(3:35:12) 62. And the number of abortions in 2022 was

(3:35:18) 17,500. Oh, then uh when it was 2023,

(3:35:24) the year after 2022, when the ban went in effect, did abortions go up or down? I have no clue. Did abortions go up or

(3:35:32) down? Andrew, do you have no Did abortions go up and down? Did abortions go up or down, sir, between 2022 and

(3:35:40) 2023? Do you think they went down? Did abortions go up or down, sir? Do you

(3:35:45) believe that 62 is accurate? Oh, you know what? I'm going to [ __ ]

(3:35:50) quadruple it. I think it could do a lot more than that. You know what? Let's [ __ ] 10x

(3:35:57) that [ __ ] Did abortions go up or down? I don't know. You don't know. You don't

(3:36:04) [ __ ] know because it's legal there. But you're you're focusing on one state. I'm

(3:36:11) telling you. You mean the state? You you picked the state. You picked it. Yes.

(3:36:16) because it demonstrates that fewer abortions abortions went down there, but abortions nationwide went up.

(3:36:23) Why? Oh, wait a second. So, let me get this right. So, Texas outlaws abortion

(3:36:29) and it goes from how many thousands to 63? It goes from how many illegal to how

(3:36:34) many illegal is the only question? No, no. They No, no, no. They were legal in Texas. Yeah. And when they were legal in

(3:36:40) Texas, how many did you have? Legal up to what? when they were legal in Texas. How many did you have, sir? I already

(3:36:46) read you the number. Stop asking. I'm sorry. Thousands. You took notes about everything. Oh, you know what? You're

(3:36:51) right. Did you have thousands of abortions in 2022? I had thousands of

(3:36:57) legal abortions in 2022. I have many abortions. Yeah. You have is that when

(3:37:03) you make abortions illegal, people go underground and maternal mortality rates go up and fetal mortality rates go up.

(3:37:10) Okay. I'm waiting. We've already seen that in Texas with I'm waiting for you to demonstrate rising by over 30%. I'll

(3:37:16) tell you what, bro. I'm waiting for you to demonstrate it. You gave me the Texas stats and here's what the Texas stats

(3:37:21) showed. We went from thousands of abortions to tens of abortions. Do we

(3:37:26) want to go into maternal and fetal mortality statistics? Sure.

(3:37:39) [Music]

(3:37:56) Heat. Heat.

(3:38:13) [Music]

(3:38:26) No, I say I blame I blame Rob for all of this. But I blame Rob for all of this. I

(3:38:32) say no. No, and no. Absolutely not. Here's what we'll do, gentlemen. I loved

(3:38:39) the discussion and I loved the back and forth. It's definitely got a very good new debate written all over it. And I'm

(3:38:46) happy to uh put that together and find a prompt between the two of you that you agree on. But the panel wants to have

(3:38:53) their time with you now. And they have been sitting back there for probably an hour waiting for it patiently. I a I

(3:39:00) listen I apologize. Give me Give me just one sec, guys. I got to go take my restless leg. No problem. And it was it

(3:39:07) was great to meet you too, Christopher. Look, no problem. I understand the debate doesn't end till the debate ends.

(3:39:14) And uh and and sometimes I can be uh very impositional. I get that. But thank

(3:39:20) you for humoring me. I appreciate that. To everybody who was waiting backstage, um you know, please give me a little bit

(3:39:26) of grace. It's a brutal field that I'm in, but I I did the best I could. It's

(3:39:32) fine. I don't mind it. But I think I had a whole lot more malice like 30 seconds ago. I think I think the apology, [ __ ]

(3:39:40) you. You know, you love my raids, Fel. I think the apology goes to all of the

(3:39:45) kind people who sent in the super chats that I did not get to get to because we got stuck in a loop. So, my deepest

(3:39:52) apologies uh to anyone who sent super chats. I'm going to try to finish getting through them throughout the

(3:39:58) evening. It's going to take me some time, but we will do it and I will constantly have to interrupt the panel in order to do so, but we will make it

(3:40:05) through. But I do want to give this one a shout out because it was the big 50. Spyro says there is uh scientific data

(3:40:13) proving people are having more meaningful, deeper, and lasting relationships, romantic and otherwise,

(3:40:18) with AI. You can pass on knowledge to AI, raise it, so to speak, etc. Why

(3:40:24) should humans reproduce if this is very likely true? So, I'm going to u give a

(3:40:30) caveat here. Spyro is actually brilliant. He's like one of these

(3:40:35) [ __ ] who's like, you know, 150 IQ plus. And I often actually have a hard

(3:40:42) time engaging with him because he's that smart. Um, but here's what I'll say. The

(3:40:48) rest of the panel, you're all going to fail even more miserably than me.

(3:40:53) So, I'll just I'll just put that caveat in. Except Rob No. He's He's smarter than me. But the rest of you [ __ ]

(3:40:59) you're not [ __ ] smarter than me. And you ain't going to engage with a [ __ ] worth a [ __ ] I guarantee it. But I'm

(3:41:05) willing to give the floor to everybody. And before I give the floor to anybody and everybody, just so uh the the

(3:41:12) audience knows, uh we like to play this fun booting game here. Uh Andrew,

(3:41:17) Christopher, and Marte cannot be booted from the panel. However, anybody else

(3:41:22) can be and I do have backstage. I have Hey, hey, Sarah. She got balls. You got

(3:41:27) balls. Sarah, let's say Andrew can be booted. But let's set it at $500 [ __ ]

(3:41:33) dollars. $500. Andrew gets booted. That seems fair. If you are willing to play

(3:41:40) that game, I am happy to oblige. However, usually I protect the main panelist because out of respect, you

(3:41:45) guys gave your time for the Let's see what happened. Let's see what happens. $500 [ __ ] dollars. You kick Andrew.

(3:41:51) $500 to boot. However, uh you can also pay to revive. You have to match the

(3:41:57) boot. So, that is the portion of it. Backstage, I have Brick, uh Evan, uh

(3:42:03) Matagi, and Daniel McCoy waiting patiently. If you want to see any of them up, you have to boot somebody down.

(3:42:09) Otherwise, the panel stays as it is. People come and go as they please. Okay, I am going to turn it over. Uh, Fattie,

(3:42:17) I'm gonna lead with you since you were first here. Go for it.

(3:42:22) How you guys doing? Uh, you and your spatula. Yes. So, I'm a little bit

(3:42:28) confused cuz every time I talk with y'all, y'all accuse secular people of

(3:42:34) not having a concrete worldview or where where their morals come from is always subjective, subjective, subjective. And

(3:42:41) y'all view because you guys are religious is objective, right? Uh, no. Actually, it would be the

(3:42:48) opposite. No, your world will view it will be object objective. No, no. I would just

(3:42:55) So, I think I think you have this backwards. I'm just kind of willing to grant the secular position and say that

(3:43:03) I'm the arbiter of all morality. No, but I don't want you to object it. I want to you to do the the intern critiquing that

(3:43:10) you usually do, right? Oh, sure. Yeah, you can internally critique me. Yeah. Yeah. Because because I But but but hang

(3:43:16) on, Fatty. Before we get to the internal critique, is it fair to say that if

(3:43:21) somebody claims that they are the arbiter of all morality that it's fair

(3:43:27) for me to also be the arbiter of all morality? Uh no, because that's not your

(3:43:32) worldview. Yeah, but but here's the thing. It's their worldview, right? No, but that's your worldview. You claim

(3:43:38) that Yeah, but it's their but it's their worldview, right? You can you can match it and say if

(3:43:45) Fatty says the is is right because Hang on, hang on, hang on, Fatty. Here's the

(3:43:50) question I'm asking. If I grant the worldview that you're the arbiter of all

(3:43:56) morality. Yes. Can't I put myself as the arbiter of all morality by your own

(3:44:01) world? I can't. No. Because you accuse me of not knowing where my morals comes

(3:44:07) from because I'm an atheist, secular, and yeah, fatty. Actually, I'm I'm more than willing to

(3:44:13) hear Hang on, hang on, hang on, hang on, Fatty. I'm just responding. I'm more than willing to hear where your morals

(3:44:19) come from. If your morals come Hang on, hang on, hang on, fatty. Fatty, I'm just willing to to grant Christianity is

(3:44:26) totally false. And the arbiter of all morality is believe in that. Okay, but

(3:44:32) hang on. I don't have no world view because I'm a degenerate. If I'm the king of the world, I'll do whatever the

(3:44:38) [ __ ] I want. Okay, great. Me, too. So now that you can go on offense, right, we're going to do a internal critique of

(3:44:44) what you believe in. You say you yourself, right, that you are your morals come from the Bible, right?

(3:44:50) That's what you say. You and most of the people on the panel that are reading that's that's incorrect. It comes from

(3:44:56) God. It comes from Christianity. Is that fair? Would that fair that the ten

(3:45:02) commandments are something that uh uh uh guide things that you believe in in in

(3:45:07) life? Yes. as long as they reconcile with the new covenant. Uh so if I thou shalt not murder murder,

(3:45:17) thou shalt not steal, you shouldn't coveret what is of your neighbor. Yeah.

(3:45:23) What are the invading by invading the land by force and murdering people for

(3:45:29) greed and taking the lead and cover it what is coveret what is not yours?

(3:45:34) Wouldn't that go against your worldview since your Bible or your God says that you shouldn't do that? Yeah, that's an

(3:45:40) excellent point. Uh all you have to do is demonstrate it. Uh when you were talking with them and

(3:45:47) you says, "What stops me from going to uh invading them, grabbing a bunch of

(3:45:52) babies, and doing a word that I don't understand?" Because and I c and I caveed this with in my worldview. I can

(3:46:00) tell you why I would say this was wrong. Can you from your worldview? I don't have no world view. I'm a secular

(3:46:06) degenerate king of the world. Whatever I want. So if you have no worldview, why should I even engage with mine? Because

(3:46:13) my rules are No, you guys actually put that on me. I don't believe in nothing

(3:46:18) because I don't know where my morals are. Neither do I. Right or wrong. Right or wrong is is whatever. You actually

(3:46:24) believe in what's right or wrong. So instead of deflecting, no, instead of changed my mind. I am the arbiter of all

(3:46:30) that is moral. But he's not because you don't believe in that. Wait, wait, wait a second. And and you

(3:46:37) know what? Thank you very much, Ro, for actually teaching me what debate is. You are not going to be You are not going to

(3:46:42) be on offense. You are not going to be on offense and actually use it against me. We're doing an internal critique of

(3:46:48) what Andrew Wilson believes. Andrew, one second, Andrew. Andrew, would you believe and can you concede that if I

(3:46:56) invade another person's land for greed and I murder them, it goes against your

(3:47:04) uh beliefs that murder is wrong? Does it goes against your beliefs? No. No.

(3:47:09) Explain that to me. Well, it depends on the context. Uh let's go with the British and the

(3:47:14) natives, which is greed. Was not for survival. Was for greed. They went to the the side of the Yes, he was. Okay,

(3:47:21) give me the example. Uh, they could survive in in in in Grand Britain.

(3:47:27) Actually, they were thriving. They decided to go ahead and to pillage, kill, and murder because that's not an

(3:47:33) example. That's just you asserting. Give me the specific example. The example is

(3:47:38) I am going to kill the the the the next tribe because I want their resources and

(3:47:45) I want Where's the specific example? Colonization is a is a that's not an

(3:47:52) example. That's just an assertion. Give me the specific example and I'll speak to how is how is that not a good example

(3:47:58) because Okay. Okay. Let me give you you just asked me a question. Can I answer

(3:48:04) it? No, I can't answer it. You know what? Let me give you one that I know. Let me give you one that I know. Portugal was one of the most powerful

(3:48:10) countries in the planet. They grab Wait, wait, hang on. Back up. Which country? Portugal. Okay. Portugal. They grab a

(3:48:17) bunch of slaves in Africa. They took them to uh uh Brazil. They murder a

(3:48:23) bunch of natives and and so they can take their gold and the the the can of sugar so that they can bring it to

(3:48:30) Portugal, right? Yeah. Demonstrate it. Yes. How? Demonstrate it. How? Uh well,

(3:48:35) show me the show me the historical facts and then we'll go over them. Andrew, are you serious? Yes. So, is this a

(3:48:42) deflection? No, it's not a deflection. It's just me asking you to go over the historical facts and we can demonstrate

(3:48:47) if it's true or false. Let me interrupt. Uh $5 more dollars has to be uh dropped

(3:48:52) in because Hector booted you. Daniel only saved you with a five. I got you. Uh so, okay. Thank you. All right. You

(3:48:59) can stay, Fatty. Oh, nope. Daniel got it. If I can, I do have to step off real

(3:49:04) quickly. I just have one question and that's it. I I'm not gonna do a long right or anything.

(3:49:11) Can I Can I ask that question? No. No, now you can. And and this is why I say that Andrew Wilson is the best debater

(3:49:17) in this space, but he's the biggest deflector, too. Because as soon as I deflect on because as soon as you get caught on your world view, you are

(3:49:24) trying to do what you did with Christopher, which is go to very minutia, proving that the Portuguese

(3:49:29) were greedy and invaded the Brazil. So that no we know that uh uh uh European

(3:49:35) colonies uh murder other people on other spaces for greed because they wanted

(3:49:40) their resources and they wanted to take it back. Why did you fatty I'm willing I'm willing to get into all of this but

(3:49:46) you have to understand what claims are. Fatty's claim is Andrew will you

(3:49:52) denounce X thing based on X immoral thing that you know ex ex people did. I

(3:49:58) think that that's a fair claim fatty. Why is it not fair for me to ask you to demonstrate that that claim is actually

(3:50:05) true rather than just asking me to denounce it based on zero evidence? I'm

(3:50:11) willing to engage with your evidence. Just show me the evidence. So the the the the the example that I gave you from

(3:50:18) Portugal going to Brazil and uh uh killing uh uh taking resources and

(3:50:23) sending them back home, is is that not considered murder? like what do you what would you need for me to actually tell

(3:50:30) you for me to prove it? Just just uh give me a demonstration from a historical concept from uh or I'm sorry

(3:50:37) a historical con uh context from a source so I can go through the source and determine if it's true or not. Okay.

(3:50:43) So, let me give you one that you probably know. uh the the the

(3:50:49) United States or whatever it was called at the time uh fighting Mexico to

(3:50:54) acquire land uh from the the the uh Texas and the South. Would that be fair?

(3:51:00) I disagree that that's a correct characterization. That's not the correct characterization.

(3:51:05) Yeah. Let's get into the reasons why that war happened. Um and then and then

(3:51:10) we can make a broader determination. So why did this war happen?

(3:51:16) No, go ahead. You said that you disagree. Oh, you you you made the claim. No, Andrew, I have You're not

(3:51:23) making claims. I made claims and you deny the claims. And then when I say you explain, you do

(3:51:28) what you did with Destiny. No, I I didn't even deny it with the insurrection. I disagree with your your your

(3:51:36) definition. I don't know. You prove it, Fatty. You're saying that this was immoral by

(3:51:42) my worldview. I'm willing to concede that that's true. Just demonstrate it. I will ask you a question since you would

(3:51:49) like to ask questions to people. Yes. Is it fair to say that the people that came from the United Kingdom and in and

(3:51:56) killed the natives, is that fair to say that that was murder? No. Not unless you can demonstrate how it was murder

(3:52:03) because it was it was no self-defense. It was no uh Okay. Then I'm waiting for the I'm waiting for the demonstration.

(3:52:10) Patty, if I may, like the example you gave that I know more is the US Mexican war, but this was a territorial dispute.

(3:52:17) Texas claimed independence from Mexico and then the United States annexed it, then there was a dispute about what the

(3:52:23) border is. This the reason that Andrew is asking for specific examples is because the one example you get is very

(3:52:29) controversial. It's not so simple as the greedy United States went in there murdering people. So, he's asking for an

(3:52:34) example. I'm sure that both me and Andrew would agree these hypotheticals you're talking about exist in some

(3:52:40) faction. Give us the specifics. Yeah, give us the specifics. I I really want to just ask one

(3:52:46) question. Buddy, give me a moment. Please I just

(3:52:51) want to ask one question and I'm out. No, I won't. I Please, I'm on your side. No question that's

(3:52:59) going to help. If so, stop it. Fatty had the floor. I specifically gave him the

(3:53:04) floor first. You can calm your ass down and cool your tits, fatty, if you want. Don't let him do you like that. Ditto.

(3:53:10) Your tits are very hot. She's the queen of the floor. The game The game that Rob

(3:53:16) and Andrew are playing, and again, once again, thank you every very much, Rob, for teaching me what debate is about. Not being right, is about not

(3:53:22) contradicting yourself. The game is putting the owners of proof once again on Fetty. Right. The reality is this. If

(3:53:32) you are going to say that what the British did to the natives is not

(3:53:37) murder, you have to explain why do you disagree that is not murder. Those are the rules of the game. So Andrew and

(3:53:44) Rob, since you disagree, you are not going to destiny me. You are not going to say I disagree with the the the fact

(3:53:52) that the 6th of January is an insurrection and then when I ask you what is the insurrection, it says I don't know. You have to define it. So,

(3:53:58) y'all going to explain to me why am I wrong by saying that the British what they did to the natives was not murder.

(3:54:04) Please explain to me what it is. Well, so I I think that this is a fair criticism to ask me, hey Andrew, what do

(3:54:12) you think murder is? If you want me to pull up the definition of murder from Christian ethics, I can do that. My

(3:54:18) question to you though, and this is simple, I'm willing to engage in everything you're saying, but remember,

(3:54:24) Fatty, do you agree with me you're making a claim? No, I'm not doing an

(3:54:29) internal. Okay. Well, well then hang on, Fatty. Fatty. Fatty. Hang on. Hang on. Fatty. Fatty. If that's the case, you're

(3:54:35) not making a claim, then I just don't care. So, you are going to just not say

(3:54:40) so you can't concede that you are going against your If you're not making If you're not Are you making the claim I'm going against my Okay. So, are you hang

(3:54:48) on fatty? Are you making the No, it's fine. It's fine. Since I have GPT, we're going to go one by one. Key examples of

(3:54:55) murder and massacres. Trail of Tears 1830s ordered by President Andrew

(3:55:00) Jackson. Over 60,000 Native Americans were forcibly moved from their native

(3:55:06) lands. Thousands died from starvation, disease, and exhaustion. How many thousands? One sec. 60,000. We can go to

(3:55:12) 60,000 didn't die. 60,000 didn't die from the trellot. That's totally fine. You can discuss the number might be one.

(3:55:19) Colorado territory militia. Okay. So, it's one. No, there's more. I can go back. But I

(3:55:26) thought you said it doesn't matter. All that matters is that there's one. You are extremely No, you are extremely

(3:55:32) intelligent. But now you're playing dumb because you don't want I'm not playing dumb. I'm just listening to what you're saying. Want to move the conversation.

(3:55:39) Patty, listen. I'm willing to engage in everything you say in good faith. But

(3:55:44) just remember that you're saying it. Yes. So if it is the case that you're doing an internal critique and you have

(3:55:50) some internal criticisms of my position, you need to a bring up the position and then tell me what the criticism is. What

(3:55:57) you can't do, hang on. What you can't do is assert from your position X is wrong

(3:56:04) or X is right and then expect that I'm going to have that's not an internal criticism. That's an external criticism.

(3:56:11) So which do you want to do? An internal critique or an external critique? I No, no. I'm talking about your world view.

(3:56:18) Okay. My worldview. So, what are you asking me about my worldview first? Yes.

(3:56:23) No, no, no. I know what it is. Didn't just Well, if you know what it is, then tell me what it is. I I ask you I ask

(3:56:30) you, do the Ten Commandments have a role on your world view and where you get?

(3:56:37) Didn't you say yes? Yes. Okay. And then we move on. There's Okay, but but hang

(3:56:42) on, Fatty. Fatty, hang on, hang on, hang on, bro. I'm engaging with you in good faith. No, you're not. Wait, how am I

(3:56:48) not? Because you are uh uh uh uh stalemating the conversation on prove

(3:56:54) the murder and then when I murder you in fatty when you say a word, do you agree

(3:57:00) with me that that word could have a different connotation or it could? No, stop, bro. Just let me No. Yeah, but let

(3:57:08) me finish asking it before you answer it. Is it the case that you and I could have a different distinction what murder

(3:57:15) is? For instance, you agree with me that there's many people who would say if somebody tried to steal my property and

(3:57:21) I shot them, that would be murder, even though you and I may disagree that that's murder. So, if you're going to

(3:57:26) hold me to a standard, make sure you're holding me to my own standard and ask me

(3:57:31) what is the definition of murder? Why is that the definition? And then you can

(3:57:36) give me the criticism based on my own definition. But what you can't do is say externally I believe this is murder and

(3:57:42) so that's your standard. That's not my [ __ ] standard, dude. Okay, so what is your standard? There we go. So there's

(3:57:49) the first [ __ ] question. Murder would be an unjustified killing from a biblical sense. Unjustified from a

(3:57:56) biblical sense? Yes. Would would greed cover that? If I want to steal something

(3:58:02) because I want uh gold, I want resources, I want would that consider be considered murder or is justifiable?

(3:58:10) Uh so when you say greed and again greed means hang on hang on

(3:58:17) hang. I'm not asking you what greed means. I'm not asking. I'm saying I'm not starving. I don't

(3:58:24) need it. And I will say you have 30 seconds to finish fatty before I have to boot you. Unless somebody matches

(3:58:31) and and by and by the way it's kind of interesting that as soon as people are on the road you'll bring the money up.

(3:58:38) Nobody's on the [ __ ] ropes. Thank you. Thank you very much. No, you are actually on the ropes. So, so, so, so,

(3:58:44) so is it fair to say once again that if I'm I'm able to survive, I'm not on a

(3:58:51) survival position where I need a loaf of bread or something to get from you so I can leave. If I'm doing it out of greed,

(3:58:58) meaning I'm doing just to accommodate to get more power, more resources. If I go

(3:59:03) to your tribe and I steal from and I and I kill the people there to get your resources, would that be fair to say

(3:59:09) that there's murder? No. Why? Well, because this would be the distin Yeah.

(3:59:16) This would be the distinction of greed. So, when you say, "Is it the case that

(3:59:21) I'm killing you only to justice? Suppose that I want something that you have,

(3:59:26) right? Is that what we're considering greed to be? Means that is something that is yours

(3:59:34) that don't need." Nope. That's not the case. I'm asking you this. If we're

(3:59:39) defining greed is does greed just mean it's something that I want and I'm

(3:59:45) willing to do x thing for?

(3:59:51) No. Okay. Well, then what does greed mean? Means that I'm taking something

(3:59:56) from you that I don't need for my survival. Okay. So then if it is the

(4:00:02) case that you take anything from anybody else that you don't need for your direct survival that is greed. No, it depends.

(4:00:11) Well, okay. Well, then you see how we're not getting to anything here, dude. I I only say that because you keep you keep

(4:00:18) doing the semantics to go back on square one. No, I'm just trying to make sure that we're clear, dude. Andrew, Andrew,

(4:00:23) I know your game is to catch me on in contradiction. I'm not even trying to catch you in contradiction.

(4:00:29) I'm just trying, bro. I'm just trying to make sure that we know what we're talking about. When you when you say

(4:00:35) greed is X and then I say okay and I repeat back to you what X is and then you say no greed means Y. That is a

(4:00:42) [ __ ] contradiction. So just tell me what the [ __ ] you mean and hold that thought, Fatty. I want to ask because

(4:00:48) Christopher is leaving. Is it is it about 15 minutes? Yeah, I got a heart out at 10:30. Okay. I hate you. I hate

(4:00:55) you, Christopher. Only because Only because you have a heart out. That's why I hate you. Better

(4:01:01) than a heart in because I have a bad climate. That's right. You heard me. Uh,

(4:01:06) so, uh, it does anybody specifically have a question for Christopher?

(4:01:12) And Fatty, I will bring it back to you. I promise. I just have a question specifically for Christopher.

(4:01:18) Christopher, would you like to continue uh the original debate somewhere else and do a one-on-one? Man, this could be a [ __ ] email. I'd like to do that.

(4:01:27) True. Also, chat on Instagram about that. I definitely and I I will bow out. It was actually It was actually at

(4:01:33) Marte's uh I actually asked Marte to involve me. I wanted to debate with you guys. So just Yeah, I appreciate you

(4:01:41) coming in. I I do. Look, um before I go and and Marte, absolutely. Let's let's

(4:01:47) chat back and forth and we can totally either work with Sarah to set that up or do something on some other platform if

(4:01:52) she's bored of me. For sure. I'm down to do that. Okay. Yeah. Cool.

(4:01:58) Can we all agree though that that what we just demonstrated is that morality is subjective.

(4:02:06) That would be the crux of the argument we were attempting to have, I think, but didn't really. And that's the stumbling

(4:02:12) block people kept hitting, right? Because is this greed? Is this murder? Is subjectivity is baked in

(4:02:18) hypothetical. I'm curious how it would work if we did a hypothetical where we just pretended there is no God and have

(4:02:23) that debate. So Chris the the the funny part is that even the ten commandments are subjective because it depends of

(4:02:30) interpretation. Even the ten commandments are subjective because I will define murder and somebody will

(4:02:35) come and say I don't know what that means murder. You shall like thief like you shall not steal is a commandment.

(4:02:42) That's their worldview. They say that's a word concept fallacy. No no no but that's what they say. They say this is

(4:02:48) my worldview. This is why I am moral and you are not because your worldview is subjective. And then when we stop with

(4:02:54) still oh still depends it depends if this is a person or like that shows that he's is not objective at all. He's

(4:03:01) objective because it depends on the person interpretation. So we're going to keep going and going and going and going

(4:03:06) and going on a position where you are going to catch them because it goes against their worldview and their morals

(4:03:12) and they are going to try to pretend that murder is not murder. Greed is not greed. Silly is not stealing. Like this

(4:03:18) is kill people. You say define bad. If I can fatty, let me answer your question

(4:03:23) is in a direct way. Even though I think you're a ridiculous debater that thinks things like debate is about being true

(4:03:29) and not about proving contradictions. It's about is about being is about contradicting yourself. Rob, you are as

(4:03:35) honest as everybody else. Thank you very much for teaching me what debate is. So Fatty, are you who? Hang on. Hang on. Go

(4:03:41) on. I I want to ask this. I want I wanted Rob to Fatty. Can you name for me four four debaters you consider honest?

(4:03:49) I just want to know four debaters you consider honest. Andrew Rob, can you continue? Well, he called my friend a

(4:03:55) dishonest arbiter. I want to know who the honest ones are cuz I debated him

(4:04:00) before. Who are the honest ones, Fatty? No honest ones. I don't I don't need to

(4:04:06) know. Yeah, you don't need to know cuz there's no except you, right, Fatty? You're the only honest [ __ ] debater,

(4:04:12) right, Fatty? No, I'm not. I would like to hear Rob's uh thought

(4:04:18) process. He was he was getting to to something and I want him to finish. Please. I'll be very brief about it.

(4:04:23) Right. Like uh Fatty, my understanding having only seen like the first half hour of this debate, which I apologize

(4:04:29) for, uh is to the greater question of I know, right? Is it immoral to take land

(4:04:34) by force? It seemed to me based on Andrew's opening statement, sometimes it is, sometimes it's not. But to say that

(4:04:40) it is always immoral, which would be the affirmative position, would be incorrect. So given the question you asked, fatty, even without getting into

(4:04:47) specifics, I am fully willing to admit that the United States and probably every other government in the world has

(4:04:53) engaged in immoral uses of force to take land or to do other things in the past.

(4:04:58) So I'm not sure where the direction of your question is going. You It's like some gotcha. You're like, "Ah, yes, but

(4:05:03) according to your biblical view, not real quick. Let me finish." So, not to speak for Andrew's Christianity, but I

(4:05:09) would bet that even in Andrew's Christianity that he could come up with hypothetical situations when the United States federal government has engaged in

(4:05:16) actions he would think it's immoral based on his biblical worldview. So, what's the point you're trying to make?

(4:05:21) Uh, I I know that you are the king of the what aboutism, but when Andrew was talking after the the initial statement,

(4:05:28) he literally said when he was talking to Chris defensive uh uh taking land on a defensive way. He

(4:05:36) expanded on that. But if you are uh coming through the like the

(4:05:41) understanding that me invading something because I'm defending myself and is a

(4:05:46) preemptive attack, what the British did for example to the Indian to the natives was not defensive at all. It was clearly

(4:05:53) offensive and he had nothing to do with survival and agreed. I'll grant it. So

(4:05:59) So but but that's the point. So you are proving if you agree that he was not

(4:06:04) defensive and these people did the British came to this side of

(4:06:10) your side cuz I'm actually I'm actually going to give you the best I can possibly give you. The British came here

(4:06:16) because they were a bunch of [ __ ] Satan worshiing scumbags who chopped up little engines for the fun of it because

(4:06:22) they just thought it was fun. They wanted to cut them up and then they ate the remains. That's not true. But let's

(4:06:28) just say it was. But but that we don't have let's just but I'm just I'm just giving you the most like charitable

(4:06:34) version of your right you know what you're right fatty that I then I won't even be charitable

(4:06:41) and you see you are proving the debate is not what's right the debate is about proving actually no instead of talking

(4:06:47) about something is what's right why do you have to do an hypothetical on something that actually happened let me

(4:06:53) prove to you why didn't they come to decide because of the boogeyman and other religions Because the British

(4:06:59) invaded Portugal, they share the same god. They invaded Spain, they share the same god. They invaded France, they

(4:07:05) share the same god. So it's about greed and it was about gold. It was not about we just invading people because they

(4:07:10) don't believe on our god. So why do an hypothetical when you clearly have depiction of history of why the British

(4:07:17) came to this side to prove a contradiction. Okay, that's what you do, bro. I'll explain. So I'm just trying to

(4:07:23) grant the most extreme version of the logic to make sure that it adds up. But

(4:07:28) however, if you say, Andrew, I only want you to engage with this logic. I'm happy to do that, too, and I'm waiting for the

(4:07:35) demonstration that they invaded based on gold and greed. So, you I just want to

(4:07:41) make this sure. You don't think that colonialism, okay, was based on greed, on expansion,

(4:07:49) on becoming more wealthy, more powerful. That's correct. Yeah. So, why did they do it, Andrew? Well, I think that if you

(4:07:56) looked at what the English code was and the French code, make the world French, make the world English, they were trying

(4:08:03) to export a moral system. [Music] But I'm waiting I'm waiting for you to

(4:08:10) explain. Hang on. Hang on, Fatty. My turn. So, Fattie, I'm waiting for you to

(4:08:15) express and show me the evidence that this was based on greed.

(4:08:21) Because once again, the definition of greed, and I have it right here, and you for whatever reason, greed is an intense

(4:08:28) and selfish desire for more than you need, especially money, power, land, or

(4:08:34) possessions, often at the expenses of others. This literally is colonialism.

(4:08:40) We don't Well, I'm Hang on, Fatty. I'm willing to grant the definition. I'm just waiting for the demonstration.

(4:08:48) Wait, what? I'm willing to grant your definition that that's what greed is and

(4:08:54) I'm waiting for you to demonstrate that they were acting in this way. Okay. So

(4:09:00) we are going to do a math equation, right? Portugal had 6 million habitants at that time. Portugal is a very very

(4:09:07) very is a very very small country. Which time? Uh in the 1500s. Okay. 1500s

(4:09:13) against who? Yes. Yes. Is is a very powerful country but a very small country. Can you explain? Can you

(4:09:19) explain to me why did Portugal went to Africa? What? Hang on. Hang on, Fatty. These are your claims. I'm waiting for

(4:09:27) because you're the one claiming it. I'm going to So, I'm just waiting for you with your claim to demonstrate how this

(4:09:34) was greedy according to your standard. For a moment, please. Uh, there are two

(4:09:40) people who do have a question for Christopher, and he does have a a hard stop here shortly. So, I would like to

(4:09:45) grant them the space to do so. Uh, I believe uh Tim, did you have a you have

(4:09:51) one? Yeah. So, it's it was interesting. There was like this intersectionality, I

(4:09:56) guess, that was in your opening statement, Chris, when it came to the an intersection of history and um and

(4:10:03) theology as an appeal to, you know, the moral system that you were arguing. And I think it's it's curious, how do you if

(4:10:10) you wanted to appeal to the morality of the Bible to Christians, how do you get around the fact that there was a mandate

(4:10:16) for the Jews to conquer Canaan and get rid of the child sacrificing Canaanites?

(4:10:22) And then what makes that different? What makes that different than the concisadors coming to Meso America and

(4:10:28) getting rid of the Aztecs who engaged in human sacrifice, were pagans, and massacred their neighbors? What's the

(4:10:33) moral distinction between those two things? I think they would have to be somewhat up to what you understand God's

(4:10:40) direction to be or whether you even believe historically that is accurate because we do know that religion is

(4:10:46) often used. Let's assume it is accurate. Let's assume that let's just assume for

(4:10:52) the sake of argument it is accurate then I think that's a no not the Bible is accurate but that portion is accurate

(4:10:59) that God ordered the Hebrews to wipe out surrounding nations. Yeah. Why is that wrong? according to God. Yeah. Why is

(4:11:06) that wrong? Because he was trying to Why is it wrong? Yeah. Is it wrong? That's

(4:11:13) what I'm asking you. Is it wrong based on your definition? No. Yours. Is it

(4:11:18) wrong that God ordered that these neighboring nations get put to the [ __ ] sword? And let's even go

(4:11:25) further. Hang on. Let's go further. Hang on. I'm going to go further. Hang on. Bro, bro, wait. Wait. I'm going to go further. Let's say for a second that God

(4:11:32) ordered all of the women who were under the age of eight to get chopped up into

(4:11:37) little pieces after they were [ __ ] egregiously raped over and over and

(4:11:43) over. Let's just assume. Hang on. Let's just assume that's the goddamn Stop. Stop. Let's just assume it. Let's just

(4:11:50) assume that he No, he didn't. But let's just assume he did. Why was he wrong?

(4:11:56) Why do I think he was wrong? Yeah, because children have value. Humans have

(4:12:04) value according to who? According to God himself. So, hang on. Let's assume God

(4:12:10) says, let's assume God says that that humans have no value.

(4:12:16) Why is he wrong using the Bible? Okay, let's assume the Bible is Let's just

(4:12:23) assume for a second for the sake of argument that the entire Bible is rewritten. Humans have no value. He

(4:12:30) ordered the Jews to just kill everybody around them and just grape them over and over and over again cuz he thought it

(4:12:36) was fun. Hang on. God sitting back on his throne. He thinks it's funny. He's looking down. He's like, "This is

(4:12:42) [ __ ] hilarious. Grape again." Why is God [ __ ] wrong, bro?

(4:12:49) because that's not God.

(4:12:54) It's fine because God told said so. There's there's fine if you believe that's what God

(4:13:00) said. Let's say for a second God did say that.

(4:13:06) Why would he be wrong? Why would you think he is wrong if I Don't ask me a [ __ ] question. Answer

(4:13:13) the question. You believe you're married, correct? Yes. You believe your wife has No, I Here's what I believe. I

(4:13:20) believe that I should be able to just murder anytime I want anybody who looks

(4:13:25) at me crosseyed. Why am I wrong?

(4:13:32) Because we live in a society that's Oh, because we live in a society. So, as long as society agreed that I should be

(4:13:37) able to do that, that's fine. Why would society agree to that? You assume. Let's assume that. Let's assume. Let's assume

(4:13:43) they did. Let's assume they did.

(4:13:48) You're wrong because there's your Yeah. Let him answer. Let's assume that they society said

(4:13:56) anybody Andrew Wilson every [ __ ] Yeah, that's right. They

(4:14:01) decided Andrew Wilson should be able to grape whoever he wants and he should be able to kill whoever he wants whenever

(4:14:07) the [ __ ] he wants. Why are they wrong? Why then? Why would I be wrong if I

(4:14:12) answer the [ __ ] question? Why are they wrong, dude? Why is it wrong to kill other human

(4:14:18) beings? Because why is it wrong if society enables me to grape who I want and kill who I want whenever I want? Why

(4:14:25) are they wrong? Because humans are in interconnected creatures who require

(4:14:32) each other in order to succeed. Okay. Yeah, they're still requiring each other. Allowed monsters to go around

(4:14:37) killing whomever they like. We will very quickly dissolve into anarchy and chaos.

(4:14:42) Exactly. Now, let us assume, let us assume that we have a society in which I

(4:14:48) impale [ __ ] who look at me crosseyed. Crime goes way down. All right? Reproduction goes way up. I give

(4:14:55) all sorts of incentives to reproduction. I just if you look at me [ __ ] crosseyed, I will [ __ ] impale you. I

(4:15:01) will literally stick that steak right up your [ __ ] ass, through your throat, and through your mouth, and I will stick

(4:15:07) you in that [ __ ] town square, and then I'll urinate on your [ __ ] face. Okay. But crime, hang on, hang on. But

(4:15:15) crime goes way down. Crime goes way down. Reproduction goes way up. We suddenly have a booming population. Why

(4:15:22) am I [ __ ] immoral? Why? What am I doing that's actually immoral? Can you

(4:15:28) tell me? No, I can't. Hang on. I cannot. But society can. Society says what I'm

(4:15:36) doing is great. Let's say I go up for three re-elections and they reelect me. Let's say they reelect me.

(4:15:42) Hang on. Let's say they reelect me three [ __ ] times to continue to just impale

(4:15:47) these person these people from ass to throat and stick them down and urinate

(4:15:52) on their [ __ ] face and grape their women when I want to. They reelected Hang on. Hang on, Sarah. They reelect me

(4:16:00) three [ __ ] times to do it. Why are they wrong, dude? In that case, they

(4:16:06) probably wouldn't be in terms of the laws that they would set. But you

(4:16:12) have set Hang on. You have set a higher authority than that. So you're arguing against your own

(4:16:18) position. Chris, if I may, this is sort of a classic argument. There's Andrew is putting a unique flavor on it. But the

(4:16:24) classic argument is this. Those that are approaching morality from a secular view. Where do you get your ultimate

(4:16:30) view of morality because it always becomes subjective. However, through a Christian perspective or any religious

(4:16:35) perspective, you say to us it is given to us from on high, from a higher power. Right? And so it seemed that you

(4:16:41) floundered there with several things. For example, you said your morality would be based on utilitarianism. If

(4:16:47) Andrew did those horrible things, it would make society worse. So Andrew says, "But hypothetically, if it

(4:16:52) wouldn't, then why would it be wrong?" And you're like, "Well, because the people would be opposed to it. But if the people were for it, so let's take a

(4:16:58) real example. Child sacrifices in like the Aztec society. They thought that that was had utility. It was helping

(4:17:05) them. It helped their crops, etc. So morally, why would they be wrong?" And what Andrew is getting to is where does

(4:17:10) your morality come from? Who are you to tell those people they're wrong? Where do and this is at the beginning of his

(4:17:15) statement, he says like where do rights come from? And there was this like the other woman that was your partner was like, "Well, this is semantical." Well,

(4:17:21) no, this gets to the heart of the matter because we need to find out where your morality and where your rights come from

(4:17:27) in order to see whether or not a particular action is morally justified or not. In this case, the topic he

(4:17:33) knows. He just doesn't know how to respond to it. No, I do. Here. Okay. Before Before you do that, let me tell

(4:17:39) everybody that's watching over on the tomato side, I am now shutting down tomato. You'll catch the raid over to

(4:17:45) the gauntlet. If not, I'm dropping the link in the chat several times. We're moving to the gauntlet officially. Okay,

(4:17:50) just remember it's not immoral if I stake people and urinate on their face as long as the majority says so. Let's

(4:17:56) let's just keep that in mind as we listen to the answer. move from the hyper.